import streamlit as st
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# --- Configuraci√≥n de la P√°gina ---
st.set_page_config(
    page_title="AI Fairness Playbooks",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

#======================================================================
# --- FUNCIONES DE SIMULACI√ìN ---
#======================================================================

def plot_simulation(df, title, x_label="Puntuaci√≥n del Modelo", y_label="Densidad"):
    """Funci√≥n auxiliar para graficar distribuciones."""
    fig, ax = plt.subplots()
    for group in df['Grupo'].unique():
        df[df['Grupo'] == group]['Puntuaci√≥n'].plot(kind='density', ax=ax, label=group)
    ax.set_title(title)
    ax.set_xlabel(x_label)
    ax.set_ylabel(y_label)
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.6)
    st.pyplot(fig)

def run_threshold_simulation():
    """Simulaci√≥n para optimizaci√≥n de umbrales en post-procesamiento."""
    st.markdown("#### Simulaci√≥n de Optimizaci√≥n de Umbrales")
    st.write("Ajusta los umbrales de decisi√≥n para dos grupos y observa c√≥mo cambian las tasas de error para lograr la **Igualdad de Oportunidades** (tasas de verdaderos positivos iguales).")

    # Generar datos simulados
    np.random.seed(42)
    scores_a_pos = np.random.normal(0.7, 0.15, 80)
    scores_a_neg = np.random.normal(0.4, 0.15, 120)
    scores_b_pos = np.random.normal(0.6, 0.15, 50)
    scores_b_neg = np.random.normal(0.3, 0.15, 150)

    df_a = pd.DataFrame({'Puntuaci√≥n': np.concatenate([scores_a_pos, scores_a_neg]), 'Real': [1]*80 + [0]*120, 'Grupo': 'Grupo A'})
    df_b = pd.DataFrame({'Puntuaci√≥n': np.concatenate([scores_b_pos, scores_b_neg]), 'Real': [1]*50 + [0]*150, 'Grupo': 'Grupo B'})
    
    col1, col2 = st.columns(2)
    with col1:
        threshold_a = st.slider("Umbral para Grupo A", 0.0, 1.0, 0.5, key="sim_thresh_a")
    with col2:
        threshold_b = st.slider("Umbral para Grupo B", 0.0, 1.0, 0.5, key="sim_thresh_b")

    # Calcular m√©tricas
    tpr_a = np.mean(df_a[df_a['Real'] == 1]['Puntuaci√≥n'] >= threshold_a)
    fpr_a = np.mean(df_a[df_a['Real'] == 0]['Puntuaci√≥n'] >= threshold_a)
    
    tpr_b = np.mean(df_b[df_b['Real'] == 1]['Puntuaci√≥n'] >= threshold_b)
    fpr_b = np.mean(df_b[df_b['Real'] == 0]['Puntuaci√≥n'] >= threshold_b)

    st.markdown("##### Resultados")
    res_col1, res_col2 = st.columns(2)
    with res_col1:
        st.metric(label="Tasa de Verdaderos Positivos (Grupo A)", value=f"{tpr_a:.2%}")
        st.metric(label="Tasa de Falsos Positivos (Grupo A)", value=f"{fpr_a:.2%}")
    with res_col2:
        st.metric(label="Tasa de Verdaderos Positivos (Grupo B)", value=f"{tpr_b:.2%}")
        st.metric(label="Tasa de Falsos Positivos (Grupo B)", value=f"{fpr_b:.2%}")

    if abs(tpr_a - tpr_b) < 0.02:
        st.success(f"¬°Casi has logrado la Igualdad de Oportunidades! La diferencia en TPR es de solo {abs(tpr_a - tpr_b):.2%}.")
    else:
        st.warning(f"Ajusta los umbrales para igualar las Tasas de Verdaderos Positivos. Diferencia actual: {abs(tpr_a - tpr_b):.2%}")

def run_matching_simulation():
    st.markdown("#### Simulaci√≥n de Emparejamiento (Matching)")
    st.write("Compara dos grupos para estimar un efecto. El emparejamiento busca individuos 'similares' en ambos grupos para hacer una comparaci√≥n m√°s justa.")
    np.random.seed(0)
    # Grupo de Tratamiento
    x_treat = np.random.normal(5, 1.5, 50)
    y_treat = 2 * x_treat + 5 + np.random.normal(0, 2, 50)
    # Grupo de Control
    x_control = np.random.normal(3.5, 1.5, 50)
    y_control = 2 * x_control + np.random.normal(0, 2, 50)

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharey=True)
    ax1.scatter(x_treat, y_treat, c='red', label='Tratamiento', alpha=0.7)
    ax1.scatter(x_control, y_control, c='blue', label='Control', alpha=0.7)
    ax1.set_title("Antes del Emparejamiento")
    ax1.set_xlabel("Caracter√≠stica (ej. Gasto previo)")
    ax1.set_ylabel("Resultado (ej. Compras)")
    ax1.legend()
    ax1.grid(True, linestyle='--', alpha=0.5)

    # Simular emparejamiento (encontrar puntos cercanos en X)
    matched_indices = [np.argmin(np.abs(x_c - x_treat)) for x_c in x_control]
    x_treat_matched = x_treat[matched_indices]
    y_treat_matched = y_treat[matched_indices]

    ax2.scatter(x_treat_matched, y_treat_matched, c='red', label='Tratamiento (Emparejado)', alpha=0.7)
    ax2.scatter(x_control, y_control, c='blue', label='Control', alpha=0.7)
    ax2.set_title("Despu√©s del Emparejamiento")
    ax2.set_xlabel("Caracter√≠stica (ej. Gasto previo)")
    ax2.legend()
    ax2.grid(True, linestyle='--', alpha=0.5)
    
    st.pyplot(fig)
    st.info("A la izquierda, los grupos no son directamente comparables. A la derecha, hemos seleccionado un subconjunto del grupo de tratamiento que es 'similar' al de control, permitiendo una estimaci√≥n m√°s justa del efecto del tratamiento.")

def run_rd_simulation():
    st.markdown("#### Simulaci√≥n de Regresi√≥n por Discontinuidad (RD)")
    st.write("La RD se usa cuando un tratamiento se asigna basado en un umbral (ej. una calificaci√≥n m√≠nima para una beca). Se compara a los individuos justo por encima y por debajo del umbral para estimar el efecto del tratamiento.")
    np.random.seed(42)
    cutoff = st.slider("Valor del Umbral (Cutoff)", 40, 60, 50)
    
    x = np.linspace(0, 100, 200)
    y = 10 + 0.5 * x + np.random.normal(0, 5, 200)
    # Efecto del tratamiento
    treatment_effect = 15
    y[x >= cutoff] += treatment_effect

    fig, ax = plt.subplots()
    ax.scatter(x[x < cutoff], y[x < cutoff], c='blue', label='Control (No recibi√≥ tratamiento)')
    ax.scatter(x[x >= cutoff], y[x >= cutoff], c='red', label='Tratamiento')
    ax.axvline(x=cutoff, color='gray', linestyle='--', label=f'Umbral en {cutoff}')
    ax.set_title("Efecto del Tratamiento en el Umbral")
    ax.set_xlabel("Variable de asignaci√≥n (ej. Calificaci√≥n de examen)")
    ax.set_ylabel("Resultado (ej. Ingreso futuro)")
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.5)
    st.pyplot(fig)
    st.info(f"El 'salto' o discontinuidad en la l√≠nea de resultados en el punto del umbral ({cutoff}) es una estimaci√≥n del efecto causal del tratamiento. Aqu√≠, el efecto es de aproximadamente **{treatment_effect}** unidades.")

def run_did_simulation():
    st.markdown("#### Simulaci√≥n de Diferencia en Diferencias (DiD)")
    st.write("DiD compara el cambio en los resultados a lo largo del tiempo entre un grupo que recibe un tratamiento y uno que no. Asume que ambos grupos habr√≠an seguido 'tendencias paralelas' sin el tratamiento.")
    
    time = ['Antes', 'Despu√©s']
    # Grupo de Control: sin tratamiento
    control_outcomes = [20, 25] 
    # Grupo de Tratamiento: recibe tratamiento en el per√≠odo 'Despu√©s'
    treat_outcomes = [15, 28]

    fig, ax = plt.subplots()
    ax.plot(time, control_outcomes, 'bo-', label='Grupo de Control (Observado)')
    ax.plot(time, treat_outcomes, 'ro-', label='Grupo de Tratamiento (Observado)')
    
    # L√≠nea contrafactual: qu√© le habr√≠a pasado al grupo de tratamiento sin tratamiento
    counterfactual = [treat_outcomes[0], treat_outcomes[0] + (control_outcomes[1] - control_outcomes[0])]
    ax.plot(time, counterfactual, 'r--', label='Grupo de Tratamiento (Contrafactual)')
    
    ax.set_title("Estimaci√≥n del Efecto del Tratamiento con DiD")
    ax.set_ylabel("Resultado")
    ax.set_ylim(10, 35)
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.5)
    st.pyplot(fig)
    
    effect = treat_outcomes[1] - counterfactual[1]
    st.info(f"La l√≠nea punteada muestra la 'tendencia paralela' que el grupo de tratamiento habr√≠a seguido sin la intervenci√≥n. La diferencia vertical entre la l√≠nea roja s√≥lida y la punteada en el per√≠odo 'Despu√©s' es el efecto del tratamiento, estimado en **{effect}** unidades.")


#======================================================================
# --- FAIRNESS INTERVENTION PLAYBOOK ---
#======================================================================

def causal_fairness_toolkit():
    st.header("üõ°Ô∏è Toolkit de Equidad Causal")
    
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **An√°lisis Causal** va m√°s all√° de las correlaciones para entender el *porqu√©* de las disparidades. Es como ser un detective que no solo ve que dos eventos ocurren juntos, sino que reconstruye la cadena de causa y efecto que los conecta. Esto nos ayuda a aplicar soluciones que atacan la ra√≠z del problema, en lugar de solo maquillar los s√≠ntomas.
        """)
    
    # Inicializar session_state para el reporte
    if 'causal_report' not in st.session_state:
        st.session_state.causal_report = {}

    tab1, tab2, tab3, tab4 = st.tabs(["Identificaci√≥n", "An√°lisis Contrafactual", "Diagrama Causal", "Inferencia Causal"])

    with tab1:
        st.subheader("Marco de Identificaci√≥n de Mecanismos de Discriminaci√≥n")
        st.info("Identifica las posibles causas ra√≠z del sesgo en tu aplicaci√≥n.")
        
        with st.expander("Definici√≥n de Discriminaci√≥n Directa"):
            st.write("Ocurre cuando un atributo protegido (como la raza o el g√©nero) es usado expl√≠citamente para tomar una decisi√≥n. Es el tipo de sesgo m√°s obvio.")
        st.text_area("1. ¬øEl atributo protegido influye directamente en la decisi√≥n?", placeholder="Ejemplo: Un modelo de contrataci√≥n que asigna una puntuaci√≥n menor a las candidatas mujeres de forma expl√≠cita.", key="causal_q1")
        
        with st.expander("Definici√≥n de Discriminaci√≥n Indirecta"):
            st.write("Ocurre cuando un atributo protegido afecta a un factor intermedio que s√≠ es leg√≠timo para la decisi√≥n. El sesgo se transmite a trav√©s de esta variable mediadora.")
        st.text_area("2. ¬øEl atributo protegido afecta a factores intermedios leg√≠timos?", placeholder="Ejemplo: El g√©nero puede influir en tener 'pausas en la carrera' (para el cuidado de hijos), y el modelo penaliza estas pausas, afectando indirectamente a las mujeres.", key="causal_q2")

        with st.expander("Definici√≥n de Discriminaci√≥n por Proxy"):
            st.write("Ocurre cuando una variable aparentemente neutral est√° tan correlacionada con un atributo protegido que funciona como un sustituto (un 'proxy') de este.")
        st.text_area("3. ¬øLas decisiones dependen de variables correlacionadas con atributos protegidos?", placeholder="Ejemplo: En un modelo de cr√©dito, usar el c√≥digo postal como predictor puede ser un proxy de la raza debido a la segregaci√≥n residencial hist√≥rica.", key="causal_q3")

    with tab2:
        st.subheader("Metodolog√≠a Pr√°ctica de Equidad Contrafactual")
        st.info("Analiza, cuantifica y mitiga el sesgo contrafactual en tu modelo.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n Contrafactual"):
            st.write("Observa c√≥mo un cambio en un atributo protegido puede alterar la decisi√≥n de un modelo, revelando un sesgo causal.")
            puntaje_base = 650
            decision_base = "Rechazado"
            st.write(f"**Caso Base:** Solicitante del **Grupo B** con un puntaje de **{puntaje_base}**. Decisi√≥n del modelo: **{decision_base}**.")
            if st.button("Ver Contrafactual (Cambiar a Grupo A)", key="cf_button"):
                puntaje_cf = 710
                decision_cf = "Aprobado"
                st.info(f"**Escenario Contrafactual:** Mismo solicitante, pero del **Grupo A**. El modelo ahora predice un puntaje de **{puntaje_cf}** y la decisi√≥n es: **{decision_cf}**.")
                st.warning("**An√°lisis:** El cambio en el atributo protegido alter√≥ la decisi√≥n, lo que sugiere que el modelo ha aprendido una dependencia causal problem√°tica.")
        
        with st.container(border=True):
            st.markdown("##### Paso 1: An√°lisis de Equidad Contrafactual")
            st.text_area("1.1 Formular Consultas Contrafactuales", placeholder="Ejemplo: Para un solicitante de pr√©stamo rechazado, ¬øcu√°l habr√≠a sido el resultado si su raza fuera diferente, manteniendo constantes los ingresos y el historial crediticio?", key="causal_q4")
            st.text_area("1.2 Identificar Rutas Causales (Justas vs. Injustas)", placeholder="Ejemplo: La ruta Raza ‚Üí C√≥digo Postal ‚Üí Decisi√≥n de Pr√©stamo es injusta porque el c√≥digo postal es un proxy. La ruta Nivel Educativo ‚Üí Ingresos ‚Üí Decisi√≥n de Pr√©stamo es considerada justa.", key="causal_q5")
            st.text_area("1.3 Medir Disparidades y Documentar", placeholder="Ejemplo: El 15% de los solicitantes del grupo desfavorecido habr√≠an sido aprobados en el escenario contrafactual. Esto indica una violaci√≥n de equidad contrafactual.", key="causal_q6")
        with st.container(border=True):
            st.markdown("##### Paso 2: An√°lisis Espec√≠fico de Rutas")
            st.text_area("2.1 Descomponer y Clasificar Rutas", placeholder="Ejemplo: Ruta 1 (proxy de c√≥digo postal) clasificada como INJUSTA. Ruta 2 (mediada por ingresos) clasificada como JUSTA.", key="causal_q7")
            st.text_area("2.2 Cuantificar Contribuci√≥n y Documentar", placeholder="Ejemplo: La ruta del c√≥digo postal representa el 60% de la disparidad observada. Raz√≥n: Refleja sesgos hist√≥ricos de segregaci√≥n residencial.", key="causal_q8")
        with st.container(border=True):
            st.markdown("##### Paso 3: Dise√±o de Intervenci√≥n")
            st.selectbox("3.1 Seleccionar Enfoque de Intervenci√≥n", ["Nivel de Datos", "Nivel de Modelo", "Post-procesamiento"], key="causal_q9")
            st.text_area("3.2 Implementar y Monitorear", placeholder="Ejemplo: Se aplic√≥ una transformaci√≥n a la caracter√≠stica de c√≥digo postal. La disparidad contrafactual se redujo en un 50%.", key="causal_q10")

    with tab3:
        st.subheader("Enfoque de Diagrama Causal Inicial")
        st.info("Esboza diagramas para visualizar las relaciones causales y documentar tus supuestos.")
        with st.expander("üí° Simulador de Diagrama Causal"):
            st.write("Construye un diagrama causal simple seleccionando las relaciones entre variables. Esto te ayuda a visualizar tus hip√≥tesis sobre c√≥mo funciona el sesgo.")
            
            nodos = ["G√©nero", "Educaci√≥n", "Ingresos", "Decisi√≥n_Pr√©stamo"]
            relaciones_posibles = [
                ("G√©nero", "Educaci√≥n"), ("G√©nero", "Ingresos"),
                ("Educaci√≥n", "Ingresos"), ("Ingresos", "Decisi√≥n_Pr√©stamo"),
                ("Educaci√≥n", "Decisi√≥n_Pr√©stamo"), ("G√©nero", "Decisi√≥n_Pr√©stamo")
            ]
            
            st.multiselect(
                "Selecciona las relaciones causales (Causa ‚Üí Efecto):",
                options=[f"{causa} ‚Üí {efecto}" for causa, efecto in relaciones_posibles],
                key="causal_q11_relations"
            )
            
            if st.session_state.causal_q11_relations:
                dot_string = "digraph { rankdir=LR; "
                for rel in st.session_state.causal_q11_relations:
                    causa, efecto = rel.split(" ‚Üí ")
                    dot_string += f'"{causa}" -> "{efecto}"; '
                dot_string += "}"
                st.graphviz_chart(dot_string)

        st.markdown("""
        **Convenciones de Anotaci√≥n:**
        - **Nodos (variables):** Atributos Protegidos, Caracter√≠sticas, Resultados.
        - **Flechas Causales (‚Üí):** Relaci√≥n causal asumida.
        - **Flechas de Correlaci√≥n (<-->):** Correlaci√≥n sin causalidad directa conocida.
        - **Incertidumbre (?):** Relaci√≥n causal hipot√©tica o d√©bil.
        - **Ruta Problem√°tica (!):** Ruta que consideras una fuente de inequidad.
        """)
        st.text_area("Documentaci√≥n de Supuestos y Rutas", placeholder="Ruta (!): Raza -> Nivel de Ingresos -> Decisi√≥n.\nSupuesto: Las disparidades hist√≥ricas de ingresos vinculadas a la raza afectan la capacidad de pr√©stamo.", height=200, key="causal_q11")

    with tab4:
        st.subheader("Inferencia Causal con Datos Limitados")
        st.info("M√©todos pr√°cticos para estimar efectos causales cuando los datos son imperfectos.")
        
        with st.expander("üîç Definici√≥n: Emparejamiento (Matching)"):
            st.write("Compara individuos de un grupo de 'tratamiento' con individuos muy similares de un grupo de 'control'. Al comparar 'gemelos' estad√≠sticos, se a√≠sla el efecto del tratamiento. En equidad, el 'tratamiento' puede ser pertenecer a un grupo demogr√°fico.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de Emparejamiento"):
            run_matching_simulation()

        with st.expander("üîç Definici√≥n: Variables Instrumentales (IV)"):
            st.write("Usa una variable 'instrumento' que afecta al tratamiento, pero no directamente al resultado, para desenredar la correlaci√≥n de la causalidad. Es como encontrar un interruptor que solo enciende una luz espec√≠fica en un panel complicado, permiti√©ndote saber qu√© hace exactamente esa luz.")
            st.graphviz_chart("""
            digraph {
                rankdir=LR;
                Z [label="Instrumento (Z)"];
                A [label="Atributo Protegido (A)"];
                Y [label="Resultado (Y)"];
                U [label="Factor de Confusi√≥n No Observado (U)", style=dashed];
                Z -> A;
                A -> Y;
                U -> A [style=dashed];
                U -> Y [style=dashed];
            }
            """)
            st.write("**Ejemplo:** Para medir el efecto causal de la educaci√≥n (A) en los ingresos (Y), se puede usar la proximidad a una universidad (Z) como instrumento. La proximidad afecta la educaci√≥n, pero no directamente a los ingresos (excepto a trav√©s de la educaci√≥n).")

        with st.expander("üîç Definici√≥n: Regresi√≥n por Discontinuidad (RD)"):
            st.write("Aprovecha un umbral o punto de corte en la asignaci√≥n de un tratamiento. Al comparar a quienes est√°n justo por encima y por debajo del umbral, se puede estimar el efecto causal del tratamiento, asumiendo que estos individuos son muy similares en otros aspectos.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de RD"):
            run_rd_simulation()

        with st.expander("üîç Definici√≥n: Diferencia en Diferencias (DiD)"):
            st.write("Compara el cambio en los resultados a lo largo del tiempo entre un grupo de tratamiento y un grupo de control. La 'diferencia en diferencias' entre los grupos antes y despu√©s del tratamiento estima el efecto causal.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de DiD"):
            run_did_simulation()

    # --- Secci√≥n de Reporte ---
    st.markdown("---")
    st.header("Generar Reporte del Toolkit Causal")
    if st.button("Generar Reporte Causal", key="gen_causal_report"):
        # Recopilar datos del session_state
        report_data = {
            "Identificaci√≥n de Mecanismos": {
                "Discriminaci√≥n Directa": st.session_state.get('causal_q1', 'No completado'),
                "Discriminaci√≥n Indirecta": st.session_state.get('causal_q2', 'No completado'),
                "Discriminaci√≥n por Proxy": st.session_state.get('causal_q3', 'No completado'),
            },
            "An√°lisis Contrafactual": {
                "Consultas Contrafactuales": st.session_state.get('causal_q4', 'No completado'),
                "Identificaci√≥n de Rutas Causales": st.session_state.get('causal_q5', 'No completado'),
                "Medici√≥n de Disparidades": st.session_state.get('causal_q6', 'No completado'),
                "Descomposici√≥n de Rutas": st.session_state.get('causal_q7', 'No completado'),
                "Cuantificaci√≥n de Contribuci√≥n": st.session_state.get('causal_q8', 'No completado'),
                "Enfoque de Intervenci√≥n Seleccionado": st.session_state.get('causal_q9', 'No completado'),
                "Plan de Implementaci√≥n y Monitoreo": st.session_state.get('causal_q10', 'No completado'),
            },
            "Diagrama Causal": {
                "Relaciones Seleccionadas": ", ".join(st.session_state.get('causal_q11_relations', [])),
                "Documentaci√≥n de Supuestos": st.session_state.get('causal_q11', 'No completado'),
            }
        }

        # Formatear reporte en Markdown
        report_md = "# Reporte del Toolkit de Equidad Causal\n\n"
        for section, content in report_data.items():
            report_md += f"## {section}\n"
            for key, value in content.items():
                report_md += f"**{key}:**\n{value}\n\n"
        
        st.session_state.causal_report_md = report_md
        st.success("¬°Reporte generado exitosamente! Puedes verlo a continuaci√≥n y descargarlo.")

    if 'causal_report_md' in st.session_state and st.session_state.causal_report_md:
        st.subheader("Vista Previa del Reporte")
        st.markdown(st.session_state.causal_report_md)
        st.download_button(
            label="Descargar Reporte Causal",
            data=st.session_state.causal_report_md,
            file_name="reporte_equidad_causal.md",
            mime="text/markdown"
        )


def preprocessing_fairness_toolkit():
    st.header("üß™ Toolkit de Equidad en Pre-procesamiento")
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **Pre-procesamiento** consiste en "limpiar" los datos *antes* de que el modelo aprenda de ellos. Es como preparar los ingredientes para una receta: si sabes que algunos ingredientes est√°n sesgados (por ejemplo, demasiado salados), los ajustas antes de cocinar para asegurar que el plato final sea equilibrado.
        """)
    
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["An√°lisis de Representaci√≥n", "Detecci√≥n de Correlaci√≥n", "Calidad de Etiquetas", "Re-ponderaci√≥n y Re-muestreo", "Transformaci√≥n", "Generaci√≥n de Datos"])

    with tab1:
        st.subheader("An√°lisis de Representaci√≥n Multidimensional")
        st.info("Examina las distribuciones demogr√°ficas para identificar brechas de representaci√≥n.")
        st.text_area("1. Comparaci√≥n con Poblaci√≥n de Referencia", placeholder="Ej: Nuestro conjunto de datos tiene un 20% de mujeres en roles t√©cnicos, mientras que el mercado laboral es del 35%.", key="p1")
        st.text_area("2. An√°lisis de Representaci√≥n Interseccional", placeholder="Ej: Las mujeres de minor√≠as raciales constituyen solo el 3% de los datos.", key="p2")
        st.text_area("3. Representaci√≥n a trav√©s de Categor√≠as de Resultados", placeholder="Ej: El grupo A constituye el 30% de las solicitudes pero solo el 10% de las aprobadas.", key="p3")

    with tab2:
        st.subheader("Detecci√≥n de Patrones de Correlaci√≥n")
        st.info("Identifica asociaciones problem√°ticas que podr√≠an permitir la discriminaci√≥n por proxy.")
        st.text_area("1. Correlaciones Directas (Atributo Protegido ‚Üî Resultado)", placeholder="Ej: El g√©nero tiene una correlaci√≥n de 0.3 con la decisi√≥n de contrataci√≥n.", key="p4")
        st.text_area("2. Identificaci√≥n de Variables Proxy (Atributo Protegido ‚Üî Caracter√≠stica)", placeholder="Ej: La caracter√≠stica 'asistencia a un club de ajedrez' est√° altamente correlacionada con el g√©nero masculino.", key="p5")

    with tab3:
        st.subheader("Evaluaci√≥n de la Calidad de las Etiquetas")
        st.info("Eval√∫a los sesgos potenciales en las etiquetas de entrenamiento.")
        st.text_area("1. Sesgo Hist√≥rico en las Decisiones", placeholder="Ej: Las etiquetas de 'promocionado' provienen de un per√≠odo con pol√≠ticas de promoci√≥n sesgadas.", key="p6")
        st.text_area("2. Sesgo del Anotador", placeholder="Ej: Los anotadores masculinos calificaron los mismos comentarios como 't√≥xicos' con menos frecuencia que las anotadoras femeninas.", key="p7")
    
    with tab4:
        st.subheader("T√©cnicas de Re-ponderaci√≥n y Re-muestreo")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de Sobremuestreo"):
            st.write("Observa c√≥mo el sobremuestreo (resampling) puede equilibrar un conjunto de datos con representaci√≥n desigual.")
            np.random.seed(0)
            data_a = np.random.multivariate_normal([2, 2], [[1, .5], [.5, 1]], 100)
            data_b = np.random.multivariate_normal([4, 4], [[1, .5], [.5, 1]], 20)
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
            
            # Gr√°fico Original
            ax1.scatter(data_a[:, 0], data_a[:, 1], c='blue', label='Grupo A (n=100)', alpha=0.6)
            ax1.scatter(data_b[:, 0], data_b[:, 1], c='red', label='Grupo B (n=20)', alpha=0.6)
            ax1.set_title("Datos Originales (Desequilibrados)")
            ax1.legend()
            ax1.grid(True, linestyle='--', alpha=0.5)

            # Gr√°fico con Sobremuestreo
            oversample_indices = np.random.choice(range(20), 80, replace=True)
            data_b_oversampled = np.vstack([data_b, data_b[oversample_indices]])
            ax2.scatter(data_a[:, 0], data_a[:, 1], c='blue', label='Grupo A (n=100)', alpha=0.6)
            ax2.scatter(data_b_oversampled[:, 0], data_b_oversampled[:, 1], c='red', label='Grupo B (n=100)', alpha=0.6, marker='x')
            ax2.set_title("Datos con Sobremuestreo del Grupo B")
            ax2.legend()
            ax2.grid(True, linestyle='--', alpha=0.5)
            
            st.pyplot(fig)
            st.info("El gr√°fico de la derecha muestra c√≥mo se han a√±adido nuevas muestras (marcadas con 'x') del Grupo B para igualar en n√∫mero al Grupo A, lo que ayuda al modelo a aprender mejor sus patrones.")
        st.info("Aborda las disparidades de representaci√≥n ajustando la influencia de las instancias de entrenamiento.")
        st.markdown("**Re-ponderaci√≥n:** Asigna pesos a las muestras para dar m√°s importancia a los grupos subrepresentados.")
        st.markdown("**Re-muestreo:** Modifica f√≠sicamente el conjunto de datos (sobre-muestreo o sub-muestreo).")
        st.text_area("Criterios de Decisi√≥n: ¬øRe-ponderar o Re-muestrear?", placeholder="Basado en mi auditor√≠a y mi modelo, la mejor estrategia es...", key="p8")
        st.text_area("Consideraci√≥n de Interseccionalidad", placeholder="Mi plan para la interseccionalidad es...", key="p9")

    with tab5:
        st.subheader("Enfoques de Transformaci√≥n de Distribuci√≥n")
        st.info("Modifica el espacio de caracter√≠sticas para mitigar el sesgo.")
        st.text_area("1. Eliminaci√≥n de Impacto Dispar", placeholder="Ej: 'Reparar' la caracter√≠stica 'c√≥digo postal' para que su distribuci√≥n sea la misma en todos los grupos raciales.", key="p10")
        st.text_area("2. Representaciones Justas (LFR, LAFTR)", placeholder="Ej: Usar un autoencoder adversario para aprender una representaci√≥n que no contenga informaci√≥n de g√©nero.", key="p11")
        st.text_area("3. Consideraciones de Interseccionalidad", placeholder="Mi estrategia de transformaci√≥n se centrar√° en las intersecciones de g√©nero y etnia...", key="p12")

    with tab6:
        st.subheader("Generaci√≥n de Datos con Conciencia de Equidad")
        st.info("Crea datos sint√©ticos para mitigar patrones de sesgo.")
        st.markdown("**¬øCu√°ndo Generar Datos?:** Cuando hay subrepresentaci√≥n severa o se necesitan ejemplos contrafactuales.")
        st.markdown("**Estrategias:** Generaci√≥n Condicional, Aumentaci√≥n Contrafactual.")
        st.text_area("Consideraciones de Interseccionalidad", placeholder="Mi modelo generativo ser√° condicionado en la intersecci√≥n de edad y g√©nero para...", key="p13")

def inprocessing_fairness_toolkit():
    st.header("‚öôÔ∏è Toolkit de Equidad en In-procesamiento")
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **In-procesamiento** implica modificar el algoritmo de aprendizaje del modelo para que la equidad sea uno de sus objetivos, junto con la precisi√≥n. Es como ense√±arle a un chef a cocinar no solo para que la comida sea deliciosa, sino tambi√©n para que sea nutricionalmente equilibrada, haciendo de la nutrici√≥n una parte central de la receta.
        """)
    
    tab1, tab2, tab3, tab4 = st.tabs(["Objetivos y Restricciones", "Debiasing Adversario", "Optimizaci√≥n Multiobjetivo", "Patrones de C√≥digo"])

    with tab1:
        st.subheader("Objetivos y Restricciones de Equidad")
        st.info("Incorpora la equidad directamente en la optimizaci√≥n del modelo.")
        st.markdown("**M√©todos Lagrangianos:** Transforma restricciones duras en penalizaciones suaves en la funci√≥n de p√©rdida.")
        st.latex(r''' \mathcal{L}(\theta, \lambda) = L(\theta) + \sum_{i=1}^{k} \lambda_i C_i(\theta) ''')
        st.markdown("**Viabilidad y Compensaciones:** Entiende la tensi√≥n entre equidad y rendimiento.")
        st.markdown("**Interseccionalidad:** Las restricciones deben considerar combinaciones de atributos.")

    with tab2:
        st.subheader("Enfoques de Debiasing Adversario")
        st.info("Usa aprendizaje adversario para que los modelos 'desaprendan' patrones discriminatorios.")
        st.markdown("**Arquitectura:** Un **Predictor** compite contra un **Adversario**. El predictor aprende a enga√±ar al adversario, creando representaciones sin informaci√≥n del atributo protegido.")
        st.markdown("**Optimizaci√≥n:** El entrenamiento puede ser inestable. Requiere equilibrio de componentes, inversi√≥n de gradiente y entrenamiento progresivo.")
    
    with tab3:
        st.subheader("Optimizaci√≥n Multiobjetivo para la Equidad")
        with st.expander("üí° Ejemplo Interactivo: Frontera de Pareto"):
            st.write("Explora la **frontera de Pareto**, que visualiza la compensaci√≥n (trade-off) entre la precisi√≥n de un modelo y su equidad. No se puede mejorar uno sin empeorar el otro.")
            
            # Datos simulados para la frontera
            np.random.seed(10)
            accuracy = np.linspace(0.80, 0.95, 20)
            fairness_score = 1 - np.sqrt(accuracy - 0.79) + np.random.normal(0, 0.02, 20)
            fairness_score = np.clip(fairness_score, 0.5, 1.0)
            
            fig, ax = plt.subplots()
            ax.scatter(accuracy, fairness_score, c=accuracy, cmap='viridis', label='Modelos Posibles')
            ax.set_title("Frontera de Pareto: Equidad vs. Precisi√≥n")
            ax.set_xlabel("Precisi√≥n del Modelo")
            ax.set_ylabel("Puntuaci√≥n de Equidad")
            ax.grid(True, linestyle='--', alpha=0.6)
            st.pyplot(fig)
            st.info("Cada punto representa un modelo diferente. Los modelos en el borde superior derecho son '√≥ptimos': no puedes encontrar un modelo m√°s justo sin sacrificar precisi√≥n, y viceversa. La elecci√≥n de qu√© punto usar depende de las prioridades de tu proyecto.")
        st.info("Navega sistem√°ticamente las tensiones entre equidad y rendimiento.")
        st.text_area("An√°lisis y Definici√≥n de Objetivos", placeholder="Define tus m√©tricas de rendimiento y criterios de equidad aqu√≠.", key="i1")

    with tab4:
        st.subheader("Cat√°logo de Patrones de Implementaci√≥n")
        st.code("""
def fairness_regularized_loss(original_loss, predictions, protected_attribute):
  fairness_penalty = calculate_disparity(predictions, protected_attribute)
  return original_loss + lambda * fairness_penalty
        """, language="python")

def postprocessing_fairness_toolkit():
    st.header("üìä Toolkit de Equidad en Post-procesamiento")
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **Post-procesamiento** consiste en ajustar las predicciones de un modelo *despu√©s* de que ya ha sido entrenado. Es como un editor que revisa un texto ya escrito para corregir sesgos o errores. El modelo original no cambia, solo se ajusta su resultado final para que sea m√°s justo.
        """)
    
    tab1, tab2, tab3, tab4 = st.tabs(["Optimizaci√≥n de Umbrales", "Calibraci√≥n", "Transformaci√≥n de Predicci√≥n", "Clasificaci√≥n con Rechazo"])

    with tab1:
        st.subheader("T√©cnicas de Optimizaci√≥n de Umbrales")
        with st.expander("üí° Ejemplo Interactivo"):
             run_threshold_simulation()
        st.info("Ajusta los umbrales de clasificaci√≥n despu√©s del entrenamiento para satisfacer definiciones de equidad espec√≠ficas.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Seleccionar Criterio de Equidad (ej. igualdad de oportunidades)\n2. Calcular Umbrales en datos de validaci√≥n\n3. Analizar Compensaciones y Desplegar", key="po1")

    with tab2:
        st.subheader("Gu√≠a Pr√°ctica de Calibraci√≥n para la Equidad")
        st.info("Garantiza que las probabilidades predichas tengan un significado consistente en todos los grupos.")
        st.markdown("**Fundamentos:** Una mala calibraci√≥n significa que la misma puntuaci√≥n de riesgo representa diferentes niveles de riesgo real para diferentes grupos.")
        st.markdown("**T√©cnicas:** Platt Scaling, Regresi√≥n Isot√≥nica.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Evaluar Calibraci√≥n (con ECE, MCE)\n2. Seleccionar M√©todo\n3. Implementar y Validar", key="po2")

    with tab3:
        st.subheader("M√©todos de Transformaci√≥n de Predicci√≥n")
        st.info("Modifica las salidas del modelo para satisfacer restricciones de equidad complejas.")
        st.markdown("**Conceptos Clave:** Funciones de Transformaci√≥n Aprendidas, Alineaci√≥n de Distribuci√≥n, Transformaciones de Puntuaci√≥n Justas.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Dise√±ar Transformaci√≥n\n2. Aprender y Evaluar\n3. Considerar Interseccionalidad", key="po3")

    with tab4:
        st.subheader("Clasificaci√≥n con Opci√≥n de Rechazo")
        st.info("Identifica predicciones inciertas y las difiere a juicio humano.")
        st.markdown("**Fundamentos:** Umbrales de rechazo basados en confianza, clasificaci√≥n selectiva, modelos de colaboraci√≥n Humano-IA.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Estimar Confianza\n2. Optimizar Umbral de Rechazo\n3. Dise√±ar Flujo de Trabajo Humano-IA", key="po4")

def intervention_playbook():
    st.sidebar.title("Navegaci√≥n del Playbook de Intervenci√≥n")
    selection = st.sidebar.radio(
        "Ir a:",
        ["Playbook Principal", "Toolkit Causal", "Toolkit de Pre-procesamiento", "Toolkit de In-procesamiento", "Toolkit de Post-procesamiento"],
        key="intervention_nav"
    )
    
    if selection == "Playbook Principal":
        st.header("üìñ Playbook de Intervenci√≥n de Equidad")
        st.info("Este playbook integra los cuatro toolkits en un flujo de trabajo cohesivo, guiando a los desarrolladores desde la identificaci√≥n del sesgo hasta la implementaci√≥n de soluciones efectivas.")
        with st.expander("Gu√≠a de Implementaci√≥n"):
            st.write("Explica c√≥mo usar el playbook, con comentarios sobre puntos de decisi√≥n clave, evidencia de apoyo y riesgos identificados.")
        with st.expander("Estudio de Caso"):
            st.write("Demuestra la aplicaci√≥n del playbook a un problema de equidad t√≠pico, mostrando c√≥mo los resultados de cada componente informan al siguiente.")
        with st.expander("Marco de Validaci√≥n"):
            st.write("Proporciona orientaci√≥n sobre c√≥mo los equipos de implementaci√≥n pueden verificar la efectividad de su proceso de auditor√≠a.")
        with st.expander("Equidad Interseccional"):
            st.write("Consideraci√≥n expl√≠cita de la equidad interseccional en cada componente del playbook.")
    elif selection == "Toolkit Causal":
        causal_fairness_toolkit()
    elif selection == "Toolkit de Pre-procesamiento":
        preprocessing_fairness_toolkit()
    elif selection == "Toolkit de In-procesamiento":
        inprocessing_fairness_toolkit()
    elif selection == "Toolkit de Post-procesamiento":
        postprocessing_fairness_toolkit()

#======================================================================
# --- FAIRNESS AUDIT PLAYBOOK ---
#======================================================================

def audit_playbook():
    st.sidebar.title("Navegaci√≥n del Playbook de Auditor√≠a")
    page = st.sidebar.radio("Ir a", [
        "C√≥mo Navegar este Playbook",
        "Evaluaci√≥n del Contexto Hist√≥rico",
        "Selecci√≥n de Definici√≥n de Equidad",
        "Identificaci√≥n de Fuentes de Sesgo",
        "M√©tricas Comprensivas de Equidad"
    ], key="audit_nav")

    if page == "C√≥mo Navegar este Playbook":
        st.header("C√≥mo Navegar Este Playbook")
        st.markdown("""
        **El Marco de Cuatro Componentes** ‚Äì Sigue secuencialmente a trav√©s de:
        
        1. **Evaluaci√≥n del Contexto Hist√≥rico (HCA)** ‚Äì Descubre sesgos sist√©micos y desequilibrios de poder en tu dominio.
        
        2. **Selecci√≥n de Definici√≥n de Equidad (FDS)**
         ‚Äì Elige las definiciones de equidad apropiadas basadas en tu contexto y objetivos.
        
        3. **Identificaci√≥n de Fuentes de Sesgo (BSI)** ‚Äì Identifica y prioriza las formas en que el sesgo puede entrar en tu sistema.
        
        4. **M√©tricas Comprensivas de Equidad (CFM)**
         ‚Äì Implementa m√©tricas cuantitativas para el monitoreo y la presentaci√≥n de informes.

        **Consejos:**
        - Avanza por las secciones en orden, pero si√©ntete libre de retroceder si surgen nuevas ideas.
        - Usa los botones de **Guardar Resumen** en cada herramienta para registrar tus hallazgos.
        - Consulta los ejemplos incrustados en cada secci√≥n para ver c√≥mo otros han aplicado estas herramientas.
        """)
    elif page == "Evaluaci√≥n del Contexto Hist√≥rico":
        st.header("Herramienta de Evaluaci√≥n del Contexto Hist√≥rico")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("""
            El **Contexto Hist√≥rico** es el trasfondo social y cultural en el que se utilizar√° tu IA. Es importante porque los sesgos no nacen en los algoritmos, sino en la sociedad. Entender la historia de la discriminaci√≥n en √°reas como la banca o la contrataci√≥n nos ayuda a anticipar d√≥nde nuestra IA podr√≠a fallar y perpetuar injusticias pasadas.
            """)
        st.subheader("1. Cuestionario Estructurado")
        st.markdown("Esta secci√≥n te ayuda a descubrir patrones relevantes de discriminaci√≥n hist√≥rica.")
        
        q1 = st.text_area("¬øEn qu√© dominio espec√≠fico operar√° este sistema (ej. pr√©stamos, contrataci√≥n, salud)?")
        q2 = st.text_area("¬øCu√°l es la funci√≥n espec√≠fica del sistema o caso de uso dentro de ese dominio?")
        q3 = st.text_area("¬øCu√°les son los patrones de discriminaci√≥n hist√≥rica documentados en este dominio?")
        q4 = st.text_area("¬øQu√© fuentes de datos hist√≥ricos se utilizan o se referencian en este sistema?")
        q5 = st.text_area("¬øC√≥mo se definieron hist√≥ricamente las categor√≠as clave (ej. g√©nero, riesgo crediticio) y han evolucionado?")
        q6 = st.text_area("¬øC√≥mo se midieron hist√≥ricamente las variables (ej. ingresos, educaci√≥n)? ¬øPodr√≠an codificar sesgos?")
        q7 = st.text_area("¬øHan servido otras tecnolog√≠as para roles similares en este dominio? ¬øDesafiaron o reforzaron las desigualdades?")
        q8 = st.text_area("¬øC√≥mo podr√≠a la automatizaci√≥n amplificar los sesgos pasados o introducir nuevos riesgos en este dominio?")

        st.subheader("2. Matriz de Clasificaci√≥n de Riesgos")
        st.markdown("""
        Para cada patr√≥n hist√≥rico identificado, estima:
        - **Severidad**: Alto = impacta derechos/resultados de vida, Medio = afecta oportunidades/acceso a recursos, Bajo = impacto material limitado.
        - **Probabilidad**: Alta = probable que aparezca en sistemas similares, Media = posible, Baja = raro.
        - **Relevancia**: Alta = directamente relacionado con tu sistema, Media = afecta partes, Baja = perif√©rico.
        """)
        matrix = st.text_area("Matriz de Clasificaci√≥n de Riesgos (tabla Markdown)", height=200, placeholder="| Patr√≥n | Severidad | Probabilidad | Relevancia | Puntuaci√≥n (S√óP√óR) | Prioridad |\n|---|---|---|---|---|---|")

        if st.button("Guardar Resumen HCA"):
            summary = {
                "Cuestionario Estructurado": {
                    "Dominio": q1, "Funci√≥n": q2, "Patrones Hist√≥ricos": q3, "Fuentes de Datos": q4,
                    "Definiciones de Categor√≠a": q5, "Riesgos de Medici√≥n": q6, "Sistemas Anteriores": q7, "Riesgos de Automatizaci√≥n": q8
                },
                "Matriz de Riesgos": matrix
            }
            summary_md = "# Resumen de Evaluaci√≥n del Contexto Hist√≥rico\n"
            for section, answers in summary.items():
                summary_md += f"## {section}\n"
                if isinstance(answers, dict):
                    for k, v in answers.items():
                        summary_md += f"**{k}:** {v}\n\n"
                else:
                    summary_md += f"{answers}\n"
            
            st.subheader("Vista Previa del Resumen HCA")
            st.markdown(summary_md)
            st.download_button("Descargar Resumen HCA", summary_md, "HCA_summary.md", "text/markdown")
            st.success("Resumen de Evaluaci√≥n del Contexto Hist√≥rico guardado.")

    elif page == "Selecci√≥n de Definici√≥n de Equidad":
        st.header("Herramienta de Selecci√≥n de Definici√≥n de Equidad")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("""
            No existe una √∫nica "receta" para la equidad. Diferentes situaciones requieren diferentes tipos de justicia. Esta secci√≥n te ayuda a elegir la **definici√≥n de equidad** m√°s adecuada para tu proyecto, como un m√©dico que elige el tratamiento correcto para una enfermedad espec√≠fica. Algunas definiciones buscan igualdad de resultados, otras igualdad de oportunidades, y la elecci√≥n correcta depende de tu objetivo y del da√±o que intentas evitar.
            """)
        st.subheader("1. Cat√°logo de Definiciones de Equidad")
        st.markdown("""
        | Definici√≥n | F√≥rmula | Cu√°ndo Usar | Ejemplo |
        |---|---|---|---|
        | Paridad Demogr√°fica | P(≈∂=1|A=a) = P(≈∂=1|A=b) | Asegurar tasas de positivos iguales entre grupos. | Anuncios de universidad mostrados por igual a todos los g√©neros. |
        | Igualdad de Oportunidades | P(≈∂=1|Y=1,A=a) = P(≈∂=1|Y=1,A=b) | Minimizar falsos negativos entre individuos calificados. | Sensibilidad de prueba m√©dica igual entre razas. |
        | Probabilidades Igualadas | P(≈∂=1|Y=y,A=a) = P(≈∂=1|Y=y,A=b) ‚àÄ y | Equilibrar falsos positivos y negativos entre grupos. | Predicciones de reincidencia con tasas de error iguales. |
        | Calibraci√≥n | P(Y=1|≈ù=s,A=a) = s | Cuando las puntuaciones predichas se exponen a los usuarios. | Puntuaciones de cr√©dito calibradas para diferentes demograf√≠as. |
        | Equidad Contrafactual | ≈∂(x) = ≈∂(x') si A cambia | Requerir eliminaci√≥n de sesgo causal relativo a rasgos sensibles. | Resultado sin cambios si solo cambia la raza en el perfil. |
        """)
        st.subheader("2. √Årbol de Decisi√≥n para Selecci√≥n")
        exclusion = st.radio("¬øEl HCA revel√≥ exclusi√≥n sist√©mica de grupos protegidos?", ("S√≠", "No"), key="fds1")
        error_harm = st.radio("¬øQu√© tipo de error es m√°s da√±ino en tu contexto?", ("Falsos Negativos", "Falsos Positivos", "Ambos por igual"), key="fds2")
        score_usage = st.checkbox("¬øSe usar√°n las salidas como puntuaciones (ej. riesgo, ranking)?", key="fds3")
        
        st.subheader("Definiciones Recomendadas")
        definitions = []
        if exclusion == "S√≠": definitions.append("Paridad Demogr√°fica")
        if error_harm == "Falsos Negativos": definitions.append("Igualdad de Oportunidades")
        elif error_harm == "Falsos Positivos": definitions.append("Igualdad Predictiva")
        elif error_harm == "Ambos por igual": definitions.append("Probabilidades Igualadas")
        if score_usage: definitions.append("Calibraci√≥n")
        
        for d in definitions: st.markdown(f"- **{d}**")

    # (El resto de las secciones del Audit Playbook se pueden a√±adir aqu√≠ de manera similar)
    elif page == "Identificaci√≥n de Fuentes de Sesgo":
        st.header("Herramienta de Identificaci√≥n de Fuentes de Sesgo")
        # (Contenido de esta secci√≥n)
    elif page == "M√©tricas Comprensivas de Equidad":
        st.header("M√©tricas Comprensivas de Equidad (CFM)")
        # (Contenido de esta secci√≥n)


# --- NAVEGACI√ìN PRINCIPAL ---
st.sidebar.title("Selecci√≥n de Playbook")
playbook_choice = st.sidebar.selectbox(
    "Elige el playbook que quieres usar:",
    ["Fairness Audit Playbook", "Fairness Intervention Playbook"]
)

st.title(playbook_choice)

if playbook_choice == "Fairness Audit Playbook":
    audit_playbook() 
else:
    intervention_playbook()
