import streamlit as st
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# --- Configuraci√≥n de la P√°gina ---
st.set_page_config(
    page_title="AI Fairness Playbooks",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

#======================================================================
# --- FUNCIONES DE SIMULACI√ìN ---
#======================================================================

def plot_simulation(df, title, x_label="Puntuaci√≥n del Modelo", y_label="Densidad"):
    """Funci√≥n auxiliar para graficar distribuciones."""
    fig, ax = plt.subplots()
    for group in df['Grupo'].unique():
        df[df['Grupo'] == group]['Puntuaci√≥n'].plot(kind='density', ax=ax, label=group)
    ax.set_title(title)
    ax.set_xlabel(x_label)
    ax.set_ylabel(y_label)
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.6)
    st.pyplot(fig)

def run_threshold_simulation():
    """Simulaci√≥n para optimizaci√≥n de umbrales en post-procesamiento."""
    st.markdown("#### Simulaci√≥n de Optimizaci√≥n de Umbrales")
    st.write("Ajusta los umbrales de decisi√≥n para dos grupos y observa c√≥mo cambian las tasas de error para lograr la **Igualdad de Oportunidades** (tasas de verdaderos positivos iguales).")

    # Generar datos simulados
    np.random.seed(42)
    scores_a_pos = np.random.normal(0.7, 0.15, 80)
    scores_a_neg = np.random.normal(0.4, 0.15, 120)
    scores_b_pos = np.random.normal(0.6, 0.15, 50)
    scores_b_neg = np.random.normal(0.3, 0.15, 150)

    df_a = pd.DataFrame({'Puntuaci√≥n': np.concatenate([scores_a_pos, scores_a_neg]), 'Real': [1]*80 + [0]*120, 'Grupo': 'Grupo A'})
    df_b = pd.DataFrame({'Puntuaci√≥n': np.concatenate([scores_b_pos, scores_b_neg]), 'Real': [1]*50 + [0]*150, 'Grupo': 'Grupo B'})
    
    col1, col2 = st.columns(2)
    with col1:
        threshold_a = st.slider("Umbral para Grupo A", 0.0, 1.0, 0.5, key="sim_thresh_a")
    with col2:
        threshold_b = st.slider("Umbral para Grupo B", 0.0, 1.0, 0.5, key="sim_thresh_b")

    # Calcular m√©tricas
    tpr_a = np.mean(df_a[df_a['Real'] == 1]['Puntuaci√≥n'] >= threshold_a)
    fpr_a = np.mean(df_a[df_a['Real'] == 0]['Puntuaci√≥n'] >= threshold_a)
    
    tpr_b = np.mean(df_b[df_b['Real'] == 1]['Puntuaci√≥n'] >= threshold_b)
    fpr_b = np.mean(df_b[df_b['Real'] == 0]['Puntuaci√≥n'] >= threshold_b)

    st.markdown("##### Resultados")
    res_col1, res_col2 = st.columns(2)
    with res_col1:
        st.metric(label="Tasa de Verdaderos Positivos (Grupo A)", value=f"{tpr_a:.2%}")
        st.metric(label="Tasa de Falsos Positivos (Grupo A)", value=f"{fpr_a:.2%}")
    with res_col2:
        st.metric(label="Tasa de Verdaderos Positivos (Grupo B)", value=f"{tpr_b:.2%}")
        st.metric(label="Tasa de Falsos Positivos (Grupo B)", value=f"{fpr_b:.2%}")

    if abs(tpr_a - tpr_b) < 0.02:
        st.success(f"¬°Casi has logrado la Igualdad de Oportunidades! La diferencia en TPR es de solo {abs(tpr_a - tpr_b):.2%}.")
    else:
        st.warning(f"Ajusta los umbrales para igualar las Tasas de Verdaderos Positivos. Diferencia actual: {abs(tpr_a - tpr_b):.2%}")

def run_matching_simulation():
    st.markdown("#### Simulaci√≥n de Emparejamiento (Matching)")
    st.write("Compara dos grupos para estimar un efecto. El emparejamiento busca individuos 'similares' en ambos grupos para hacer una comparaci√≥n m√°s justa.")
    np.random.seed(0)
    # Grupo de Tratamiento
    x_treat = np.random.normal(5, 1.5, 50)
    y_treat = 2 * x_treat + 5 + np.random.normal(0, 2, 50)
    # Grupo de Control
    x_control = np.random.normal(3.5, 1.5, 50)
    y_control = 2 * x_control + np.random.normal(0, 2, 50)

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharey=True)
    ax1.scatter(x_treat, y_treat, c='red', label='Tratamiento', alpha=0.7)
    ax1.scatter(x_control, y_control, c='blue', label='Control', alpha=0.7)
    ax1.set_title("Antes del Emparejamiento")
    ax1.set_xlabel("Caracter√≠stica (ej. Gasto previo)")
    ax1.set_ylabel("Resultado (ej. Compras)")
    ax1.legend()
    ax1.grid(True, linestyle='--', alpha=0.5)

    # Simular emparejamiento (encontrar puntos cercanos en X)
    matched_indices = [np.argmin(np.abs(x_c - x_treat)) for x_c in x_control]
    x_treat_matched = x_treat[matched_indices]
    y_treat_matched = y_treat[matched_indices]

    ax2.scatter(x_treat_matched, y_treat_matched, c='red', label='Tratamiento (Emparejado)', alpha=0.7)
    ax2.scatter(x_control, y_control, c='blue', label='Control', alpha=0.7)
    ax2.set_title("Despu√©s del Emparejamiento")
    ax2.set_xlabel("Caracter√≠stica (ej. Gasto previo)")
    ax2.legend()
    ax2.grid(True, linestyle='--', alpha=0.5)
    
    st.pyplot(fig)
    st.info("A la izquierda, los grupos no son directamente comparables. A la derecha, hemos seleccionado un subconjunto del grupo de tratamiento que es 'similar' al de control, permitiendo una estimaci√≥n m√°s justa del efecto del tratamiento.")

def run_rd_simulation():
    st.markdown("#### Simulaci√≥n de Regresi√≥n por Discontinuidad (RD)")
    st.write("La RD se usa cuando un tratamiento se asigna basado en un umbral (ej. una calificaci√≥n m√≠nima para una beca). Se compara a los individuos justo por encima y por debajo del umbral para estimar el efecto del tratamiento.")
    np.random.seed(42)
    cutoff = st.slider("Valor del Umbral (Cutoff)", 40, 60, 50)
    
    x = np.linspace(0, 100, 200)
    y = 10 + 0.5 * x + np.random.normal(0, 5, 200)
    # Efecto del tratamiento
    treatment_effect = 15
    y[x >= cutoff] += treatment_effect

    fig, ax = plt.subplots()
    ax.scatter(x[x < cutoff], y[x < cutoff], c='blue', label='Control (No recibi√≥ tratamiento)')
    ax.scatter(x[x >= cutoff], y[x >= cutoff], c='red', label='Tratamiento')
    ax.axvline(x=cutoff, color='gray', linestyle='--', label=f'Umbral en {cutoff}')
    ax.set_title("Efecto del Tratamiento en el Umbral")
    ax.set_xlabel("Variable de asignaci√≥n (ej. Calificaci√≥n de examen)")
    ax.set_ylabel("Resultado (ej. Ingreso futuro)")
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.5)
    st.pyplot(fig)
    st.info(f"El 'salto' o discontinuidad en la l√≠nea de resultados en el punto del umbral ({cutoff}) es una estimaci√≥n del efecto causal del tratamiento. Aqu√≠, el efecto es de aproximadamente **{treatment_effect}** unidades.")

def run_did_simulation():
    st.markdown("#### Simulaci√≥n de Diferencia en Diferencias (DiD)")
    st.write("DiD compara el cambio en los resultados a lo largo del tiempo entre un grupo que recibe un tratamiento y uno que no. Asume que ambos grupos habr√≠an seguido 'tendencias paralelas' sin el tratamiento.")
    
    time = ['Antes', 'Despu√©s']
    # Grupo de Control: sin tratamiento
    control_outcomes = [20, 25] 
    # Grupo de Tratamiento: recibe tratamiento en el per√≠odo 'Despu√©s'
    treat_outcomes = [15, 28]

    fig, ax = plt.subplots()
    ax.plot(time, control_outcomes, 'bo-', label='Grupo de Control (Observado)')
    ax.plot(time, treat_outcomes, 'ro-', label='Grupo de Tratamiento (Observado)')
    
    # L√≠nea contrafactual: qu√© le habr√≠a pasado al grupo de tratamiento sin tratamiento
    counterfactual = [treat_outcomes[0], treat_outcomes[0] + (control_outcomes[1] - control_outcomes[0])]
    ax.plot(time, counterfactual, 'r--', label='Grupo de Tratamiento (Contrafactual)')
    
    ax.set_title("Estimaci√≥n del Efecto del Tratamiento con DiD")
    ax.set_ylabel("Resultado")
    ax.set_ylim(10, 35)
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.5)
    st.pyplot(fig)
    
    effect = treat_outcomes[1] - counterfactual[1]
    st.info(f"La l√≠nea punteada muestra la 'tendencia paralela' que el grupo de tratamiento habr√≠a seguido sin la intervenci√≥n. La diferencia vertical entre la l√≠nea roja s√≥lida y la punteada en el per√≠odo 'Despu√©s' es el efecto del tratamiento, estimado en **{effect}** unidades.")


#======================================================================
# --- FAIRNESS INTERVENTION PLAYBOOK ---
#======================================================================

def causal_fairness_toolkit():
    st.header("üõ°Ô∏è Toolkit de Equidad Causal")
    
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **An√°lisis Causal** va m√°s all√° de las correlaciones para entender el *porqu√©* de las disparidades. Es como ser un detective que no solo ve que dos eventos ocurren juntos, sino que reconstruye la cadena de causa y efecto que los conecta. Esto nos ayuda a aplicar soluciones que atacan la ra√≠z del problema, en lugar de solo maquillar los s√≠ntomas.
        """)
    
    # Inicializar session_state para el reporte
    if 'causal_report' not in st.session_state:
        st.session_state.causal_report = {}

    tab1, tab2, tab3, tab4 = st.tabs(["Identificaci√≥n", "An√°lisis Contrafactual", "Diagrama Causal", "Inferencia Causal"])

    with tab1:
        st.subheader("Marco de Identificaci√≥n de Mecanismos de Discriminaci√≥n")
        st.info("Identifica las posibles causas ra√≠z del sesgo en tu aplicaci√≥n.")
        
        with st.expander("Definici√≥n de Discriminaci√≥n Directa"):
            st.write("Ocurre cuando un atributo protegido (como la raza o el g√©nero) es usado expl√≠citamente para tomar una decisi√≥n. Es el tipo de sesgo m√°s obvio.")
        st.text_area("1. ¬øEl atributo protegido influye directamente en la decisi√≥n?", placeholder="Ejemplo: Un modelo de contrataci√≥n que asigna una puntuaci√≥n menor a las candidatas mujeres de forma expl√≠cita.", key="causal_q1")
        
        with st.expander("Definici√≥n de Discriminaci√≥n Indirecta"):
            st.write("Ocurre cuando un atributo protegido afecta a un factor intermedio que s√≠ es leg√≠timo para la decisi√≥n. El sesgo se transmite a trav√©s de esta variable mediadora.")
        st.text_area("2. ¬øEl atributo protegido afecta a factores intermedios leg√≠timos?", placeholder="Ejemplo: El g√©nero puede influir en tener 'pausas en la carrera' (para el cuidado de hijos), y el modelo penaliza estas pausas, afectando indirectamente a las mujeres.", key="causal_q2")

        with st.expander("Definici√≥n de Discriminaci√≥n por Proxy"):
            st.write("Ocurre cuando una variable aparentemente neutral est√° tan correlacionada con un atributo protegido que funciona como un sustituto (un 'proxy') de este.")
        st.text_area("3. ¬øLas decisiones dependen de variables correlacionadas con atributos protegidos?", placeholder="Ejemplo: En un modelo de cr√©dito, usar el c√≥digo postal como predictor puede ser un proxy de la raza debido a la segregaci√≥n residencial hist√≥rica.", key="causal_q3")

    with tab2:
        st.subheader("Metodolog√≠a Pr√°ctica de Equidad Contrafactual")
        st.info("Analiza, cuantifica y mitiga el sesgo contrafactual en tu modelo.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n Contrafactual"):
            st.write("Observa c√≥mo un cambio en un atributo protegido puede alterar la decisi√≥n de un modelo, revelando un sesgo causal.")
            puntaje_base = 650
            decision_base = "Rechazado"
            st.write(f"**Caso Base:** Solicitante del **Grupo B** con un puntaje de **{puntaje_base}**. Decisi√≥n del modelo: **{decision_base}**.")
            if st.button("Ver Contrafactual (Cambiar a Grupo A)", key="cf_button"):
                puntaje_cf = 710
                decision_cf = "Aprobado"
                st.info(f"**Escenario Contrafactual:** Mismo solicitante, pero del **Grupo A**. El modelo ahora predice un puntaje de **{puntaje_cf}** y la decisi√≥n es: **{decision_cf}**.")
                st.warning("**An√°lisis:** El cambio en el atributo protegido alter√≥ la decisi√≥n, lo que sugiere que el modelo ha aprendido una dependencia causal problem√°tica.")
        
        with st.container(border=True):
            st.markdown("##### Paso 1: An√°lisis de Equidad Contrafactual")
            st.text_area("1.1 Formular Consultas Contrafactuales", placeholder="Ejemplo: Para un solicitante de pr√©stamo rechazado, ¬øcu√°l habr√≠a sido el resultado si su raza fuera diferente, manteniendo constantes los ingresos y el historial crediticio?", key="causal_q4")
            st.text_area("1.2 Identificar Rutas Causales (Justas vs. Injustas)", placeholder="Ejemplo: La ruta Raza ‚Üí C√≥digo Postal ‚Üí Decisi√≥n de Pr√©stamo es injusta porque el c√≥digo postal es un proxy. La ruta Nivel Educativo ‚Üí Ingresos ‚Üí Decisi√≥n de Pr√©stamo es considerada justa.", key="causal_q5")
            st.text_area("1.3 Medir Disparidades y Documentar", placeholder="Ejemplo: El 15% de los solicitantes del grupo desfavorecido habr√≠an sido aprobados en el escenario contrafactual. Esto indica una violaci√≥n de equidad contrafactual.", key="causal_q6")
        with st.container(border=True):
            st.markdown("##### Paso 2: An√°lisis Espec√≠fico de Rutas")
            st.text_area("2.1 Descomponer y Clasificar Rutas", placeholder="Ejemplo: Ruta 1 (proxy de c√≥digo postal) clasificada como INJUSTA. Ruta 2 (mediada por ingresos) clasificada como JUSTA.", key="causal_q7")
            st.text_area("2.2 Cuantificar Contribuci√≥n y Documentar", placeholder="Ejemplo: La ruta del c√≥digo postal representa el 60% de la disparidad observada. Raz√≥n: Refleja sesgos hist√≥ricos de segregaci√≥n residencial.", key="causal_q8")
        with st.container(border=True):
            st.markdown("##### Paso 3: Dise√±o de Intervenci√≥n")
            st.selectbox("3.1 Seleccionar Enfoque de Intervenci√≥n", ["Nivel de Datos", "Nivel de Modelo", "Post-procesamiento"], key="causal_q9")
            st.text_area("3.2 Implementar y Monitorear", placeholder="Ejemplo: Se aplic√≥ una transformaci√≥n a la caracter√≠stica de c√≥digo postal. La disparidad contrafactual se redujo en un 50%.", key="causal_q10")

    with tab3:
        st.subheader("Enfoque de Diagrama Causal Inicial")
        st.info("Esboza diagramas para visualizar las relaciones causales y documentar tus supuestos.")
        with st.expander("üí° Simulador de Diagrama Causal"):
            st.write("Construye un diagrama causal simple seleccionando las relaciones entre variables. Esto te ayuda a visualizar tus hip√≥tesis sobre c√≥mo funciona el sesgo.")
            
            nodos = ["G√©nero", "Educaci√≥n", "Ingresos", "Decisi√≥n_Pr√©stamo"]
            relaciones_posibles = [
                ("G√©nero", "Educaci√≥n"), ("G√©nero", "Ingresos"),
                ("Educaci√≥n", "Ingresos"), ("Ingresos", "Decisi√≥n_Pr√©stamo"),
                ("Educaci√≥n", "Decisi√≥n_Pr√©stamo"), ("G√©nero", "Decisi√≥n_Pr√©stamo")
            ]
            
            st.multiselect(
                "Selecciona las relaciones causales (Causa ‚Üí Efecto):",
                options=[f"{causa} ‚Üí {efecto}" for causa, efecto in relaciones_posibles],
                key="causal_q11_relations"
            )
            
            if st.session_state.causal_q11_relations:
                dot_string = "digraph { rankdir=LR; "
                for rel in st.session_state.causal_q11_relations:
                    causa, efecto = rel.split(" ‚Üí ")
                    dot_string += f'"{causa}" -> "{efecto}"; '
                dot_string += "}"
                st.graphviz_chart(dot_string)

        st.markdown("""
        **Convenciones de Anotaci√≥n:**
        - **Nodos (variables):** Atributos Protegidos, Caracter√≠sticas, Resultados.
        - **Flechas Causales (‚Üí):** Relaci√≥n causal asumida.
        - **Flechas de Correlaci√≥n (<-->):** Correlaci√≥n sin causalidad directa conocida.
        - **Incertidumbre (?):** Relaci√≥n causal hipot√©tica o d√©bil.
        - **Ruta Problem√°tica (!):** Ruta que consideras una fuente de inequidad.
        """)
        st.text_area("Documentaci√≥n de Supuestos y Rutas", placeholder="Ruta (!): Raza -> Nivel de Ingresos -> Decisi√≥n.\nSupuesto: Las disparidades hist√≥ricas de ingresos vinculadas a la raza afectan la capacidad de pr√©stamo.", height=200, key="causal_q11")

    with tab4:
        st.subheader("Inferencia Causal con Datos Limitados")
        st.info("M√©todos pr√°cticos para estimar efectos causales cuando los datos son imperfectos.")
        
        with st.expander("üîç Definici√≥n: Emparejamiento (Matching)"):
            st.write("Compara individuos de un grupo de 'tratamiento' con individuos muy similares de un grupo de 'control'. Al comparar 'gemelos' estad√≠sticos, se a√≠sla el efecto del tratamiento. En equidad, el 'tratamiento' puede ser pertenecer a un grupo demogr√°fico.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de Emparejamiento"):
            run_matching_simulation()

        with st.expander("üîç Definici√≥n: Variables Instrumentales (IV)"):
            st.write("Usa una variable 'instrumento' que afecta al tratamiento, pero no directamente al resultado, para desenredar la correlaci√≥n de la causalidad. Es como encontrar un interruptor que solo enciende una luz espec√≠fica en un panel complicado, permiti√©ndote saber qu√© hace exactamente esa luz.")
            st.graphviz_chart("""
            digraph {
                rankdir=LR;
                Z [label="Instrumento (Z)"];
                A [label="Atributo Protegido (A)"];
                Y [label="Resultado (Y)"];
                U [label="Factor de Confusi√≥n No Observado (U)", style=dashed];
                Z -> A;
                A -> Y;
                U -> A [style=dashed];
                U -> Y [style=dashed];
            }
            """)
            st.write("**Ejemplo:** Para medir el efecto causal de la educaci√≥n (A) en los ingresos (Y), se puede usar la proximidad a una universidad (Z) como instrumento. La proximidad afecta la educaci√≥n, pero no directamente a los ingresos (excepto a trav√©s de la educaci√≥n).")

        with st.expander("üîç Definici√≥n: Regresi√≥n por Discontinuidad (RD)"):
            st.write("Aprovecha un umbral o punto de corte en la asignaci√≥n de un tratamiento. Al comparar a quienes est√°n justo por encima y por debajo del umbral, se puede estimar el efecto causal del tratamiento, asumiendo que estos individuos son muy similares en otros aspectos.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de RD"):
            run_rd_simulation()

        with st.expander("üîç Definici√≥n: Diferencia en Diferencias (DiD)"):
            st.write("Compara el cambio en los resultados a lo largo del tiempo entre un grupo de tratamiento y un grupo de control. La 'diferencia en diferencias' entre los grupos antes y despu√©s del tratamiento estima el efecto causal.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de DiD"):
            run_did_simulation()

    # --- Secci√≥n de Reporte ---
    st.markdown("---")
    st.header("Generar Reporte del Toolkit Causal")
    if st.button("Generar Reporte Causal", key="gen_causal_report"):
        # Recopilar datos del session_state
        report_data = {
            "Identificaci√≥n de Mecanismos": {
                "Discriminaci√≥n Directa": st.session_state.get('causal_q1', 'No completado'),
                "Discriminaci√≥n Indirecta": st.session_state.get('causal_q2', 'No completado'),
                "Discriminaci√≥n por Proxy": st.session_state.get('causal_q3', 'No completado'),
            },
            "An√°lisis Contrafactual": {
                "Consultas Contrafactuales": st.session_state.get('causal_q4', 'No completado'),
                "Identificaci√≥n de Rutas Causales": st.session_state.get('causal_q5', 'No completado'),
                "Medici√≥n de Disparidades": st.session_state.get('causal_q6', 'No completado'),
                "Descomposici√≥n de Rutas": st.session_state.get('causal_q7', 'No completado'),
                "Cuantificaci√≥n de Contribuci√≥n": st.session_state.get('causal_q8', 'No completado'),
                "Enfoque de Intervenci√≥n Seleccionado": st.session_state.get('causal_q9', 'No completado'),
                "Plan de Implementaci√≥n y Monitoreo": st.session_state.get('causal_q10', 'No completado'),
            },
            "Diagrama Causal": {
                "Relaciones Seleccionadas": ", ".join(st.session_state.get('causal_q11_relations', [])),
                "Documentaci√≥n de Supuestos": st.session_state.get('causal_q11', 'No completado'),
            }
        }

        # Formatear reporte en Markdown
        report_md = "# Reporte del Toolkit de Equidad Causal\n\n"
        for section, content in report_data.items():
            report_md += f"## {section}\n"
            for key, value in content.items():
                report_md += f"**{key}:**\n{value}\n\n"
        
        st.session_state.causal_report_md = report_md
        st.success("¬°Reporte generado exitosamente! Puedes verlo a continuaci√≥n y descargarlo.")

    if 'causal_report_md' in st.session_state and st.session_state.causal_report_md:
        st.subheader("Vista Previa del Reporte")
        st.markdown(st.session_state.causal_report_md)
        st.download_button(
            label="Descargar Reporte Causal",
            data=st.session_state.causal_report_md,
            file_name="reporte_equidad_causal.md",
            mime="text/markdown"
        )


def preprocessing_fairness_toolkit():
    st.header("üß™ Toolkit de Equidad en Pre-procesamiento")
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **Pre-procesamiento** consiste en "limpiar" los datos *antes* de que el modelo aprenda de ellos. Es como preparar los ingredientes para una receta: si sabes que algunos ingredientes est√°n sesgados (por ejemplo, demasiado salados), los ajustas antes de cocinar para asegurar que el plato final sea equilibrado.
        """)
    
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["An√°lisis de Representaci√≥n", "Detecci√≥n de Correlaci√≥n", "Calidad de Etiquetas", "Re-ponderaci√≥n y Re-muestreo", "Transformaci√≥n", "Generaci√≥n de Datos"])

    with tab1:
        st.subheader("An√°lisis de Representaci√≥n Multidimensional")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Esto significa verificar si todos los grupos demogr√°ficos est√°n representados de manera justa en tus datos. No solo miramos los grupos principales (como hombres y mujeres), sino tambi√©n las intersecciones (como mujeres de una etnia espec√≠fica).")
        
        with st.expander("üí° Ejemplo Interactivo: Brecha de Representaci√≥n"):
            st.write("Compara la representaci√≥n de dos grupos en tu conjunto de datos con su representaci√≥n en una poblaci√≥n de referencia (ej. el censo).")
            pop_a = 50
            pop_b = 50
            
            col1, col2 = st.columns(2)
            with col1:
                data_a = st.slider("Porcentaje del Grupo A en tus datos", 0, 100, 70)
            data_b = 100 - data_a
            
            df = pd.DataFrame({
                'Grupo': ['Grupo A', 'Grupo B'],
                'Poblaci√≥n de Referencia': [pop_a, pop_b],
                'Tus Datos': [data_a, data_b]
            })

            with col2:
                st.write("Comparaci√≥n:")
                st.dataframe(df.set_index('Grupo'))

            if abs(data_a - pop_a) > 10:
                st.warning(f"Hay una brecha de representaci√≥n significativa. El Grupo A est√° sobrerrepresentado en tus datos en {data_a - pop_a} puntos porcentuales.")
            else:
                st.success("La representaci√≥n en tus datos es similar a la poblaci√≥n de referencia.")

        st.text_area("1. Comparaci√≥n con Poblaci√≥n de Referencia", placeholder="Ej: Nuestro conjunto de datos tiene un 70% del Grupo A y 30% del Grupo B, mientras que la poblaci√≥n real es 50/50.", key="p1")
        st.text_area("2. An√°lisis de Representaci√≥n Interseccional", placeholder="Ej: Las mujeres de minor√≠as raciales constituyen solo el 3% de los datos, aunque representan el 10% de la poblaci√≥n.", key="p2")
        st.text_area("3. Representaci√≥n a trav√©s de Categor√≠as de Resultados", placeholder="Ej: El grupo A constituye el 30% de las solicitudes pero solo el 10% de las aprobadas.", key="p3")

    with tab2:
        st.subheader("Detecci√≥n de Patrones de Correlaci√≥n")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Buscamos variables aparentemente neutrales que est√©n fuertemente conectadas a atributos protegidos. Por ejemplo, si un c√≥digo postal se correlaciona fuertemente con la raza, el modelo podr√≠a usar el c√≥digo postal para discriminar indirectamente.")
        
        with st.expander("üí° Ejemplo Interactivo: Detecci√≥n de Proxy"):
            st.write("Visualiza c√≥mo una variable 'Proxy' (ej. C√≥digo Postal) puede estar correlacionada tanto con un Atributo Protegido (ej. Grupo Demogr√°fico) como con el Resultado (ej. Puntuaci√≥n de Cr√©dito).")
            np.random.seed(1)
            grupo = np.random.randint(0, 2, 100) # 0 o 1
            proxy = grupo * 20 + np.random.normal(50, 5, 100)
            resultado = proxy * 5 + np.random.normal(100, 20, 100)
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
            ax1.scatter(grupo, proxy, c=grupo, cmap='coolwarm', alpha=0.7)
            ax1.set_title("Atributo Protegido vs. Variable Proxy")
            ax1.set_xlabel("Grupo Demogr√°fico (0 o 1)")
            ax1.set_ylabel("Valor del Proxy (ej. C√≥digo Postal)")
            ax1.grid(True, linestyle='--', alpha=0.5)

            ax2.scatter(proxy, resultado, c=grupo, cmap='coolwarm', alpha=0.7)
            ax2.set_title("Variable Proxy vs. Resultado")
            ax2.set_xlabel("Valor del Proxy (ej. C√≥digo Postal)")
            ax2.set_ylabel("Resultado (ej. Puntuaci√≥n de Cr√©dito)")
            ax2.grid(True, linestyle='--', alpha=0.5)
            st.pyplot(fig)
            st.info("El gr√°fico de la izquierda muestra que el proxy est√° correlacionado con el grupo. El de la derecha muestra que el proxy predice el resultado. Por lo tanto, el modelo puede usar el proxy para discriminar.")

        st.text_area("1. Correlaciones Directas (Atributo Protegido ‚Üî Resultado)", placeholder="Ej: En los datos hist√≥ricos, el g√©nero tiene una correlaci√≥n de 0.3 con la decisi√≥n de contrataci√≥n.", key="p4")
        st.text_area("2. Identificaci√≥n de Variables Proxy (Atributo Protegido ‚Üî Caracter√≠stica)", placeholder="Ej: La caracter√≠stica 'asistencia a un club de ajedrez' est√° altamente correlacionada con el g√©nero masculino.", key="p5")

    with tab3:
        st.subheader("Evaluaci√≥n de la Calidad de las Etiquetas")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Las 'etiquetas' son las respuestas correctas en tus datos de entrenamiento (ej. 'fue contratado', 'no pag√≥ el pr√©stamo'). Si estas etiquetas provienen de decisiones humanas pasadas que fueron sesgadas, tu modelo aprender√° ese mismo sesgo.")
        st.text_area("1. Sesgo Hist√≥rico en las Decisiones", placeholder="Ejemplo: Las etiquetas de 'promocionado' en nuestro conjunto de datos provienen de un per√≠odo en el que la empresa ten√≠a pol√≠ticas de promoci√≥n sesgadas, por lo que las etiquetas en s√≠ mismas son una fuente de sesgo.", key="p6")
        st.text_area("2. Sesgo del Anotador", placeholder="Ejemplo: El an√°lisis del acuerdo entre anotadores muestra que los anotadores masculinos calificaron los mismos comentarios como 't√≥xicos' con menos frecuencia que las anotadoras femeninas, lo que indica un sesgo en la etiqueta.", key="p7")
    
    with tab4:
        st.subheader("T√©cnicas de Re-ponderaci√≥n y Re-muestreo")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("**Re-ponderaci√≥n:** Le da m√°s 'peso' o importancia a las muestras de grupos subrepresentados. **Re-muestreo:** Cambia f√≠sicamente el conjunto de datos, ya sea duplicando muestras de grupos minoritarios (sobremuestreo) o eliminando muestras de grupos mayoritarios (submuestreo).")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de Sobremuestreo"):
            st.write("Observa c√≥mo el sobremuestreo (resampling) puede equilibrar un conjunto de datos con representaci√≥n desigual.")
            np.random.seed(0)
            data_a = np.random.multivariate_normal([2, 2], [[1, .5], [.5, 1]], 100)
            data_b = np.random.multivariate_normal([4, 4], [[1, .5], [.5, 1]], 20)
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
            
            ax1.scatter(data_a[:, 0], data_a[:, 1], c='blue', label='Grupo A (n=100)', alpha=0.6)
            ax1.scatter(data_b[:, 0], data_b[:, 1], c='red', label='Grupo B (n=20)', alpha=0.6)
            ax1.set_title("Datos Originales (Desequilibrados)")
            ax1.legend()
            ax1.grid(True, linestyle='--', alpha=0.5)

            oversample_indices = np.random.choice(range(20), 80, replace=True)
            data_b_oversampled = np.vstack([data_b, data_b[oversample_indices]])
            ax2.scatter(data_a[:, 0], data_a[:, 1], c='blue', label='Grupo A (n=100)', alpha=0.6)
            ax2.scatter(data_b_oversampled[:, 0], data_b_oversampled[:, 1], c='red', label='Grupo B (n=100)', alpha=0.6, marker='x')
            ax2.set_title("Datos con Sobremuestreo del Grupo B")
            ax2.legend()
            ax2.grid(True, linestyle='--', alpha=0.5)
            
            st.pyplot(fig)
            st.info("El gr√°fico de la derecha muestra c√≥mo se han a√±adido nuevas muestras (marcadas con 'x') del Grupo B para igualar en n√∫mero al Grupo A, lo que ayuda al modelo a aprender mejor sus patrones.")
        st.text_area("Criterios de Decisi√≥n: ¬øRe-ponderar o Re-muestrear?", placeholder="Basado en mi auditor√≠a y mi modelo, la mejor estrategia es...", key="p8")
        st.text_area("Consideraci√≥n de Interseccionalidad", placeholder="Ejemplo: Para abordar la subrepresentaci√≥n de mujeres de minor√≠as, aplicaremos un sobremuestreo estratificado que garantice que este subgrupo espec√≠fico alcance la paridad con otros.", key="p9")

    with tab5:
        st.subheader("Enfoques de Transformaci√≥n de Distribuci√≥n")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Esta t√©cnica modifica directamente los valores de las caracter√≠sticas para romper las correlaciones problem√°ticas con los atributos protegidos. Es como 'recalibrar' una variable para que signifique lo mismo para todos los grupos.")
        st.text_area("1. Eliminaci√≥n de Impacto Dispar", placeholder="Ej: 'Reparar' la caracter√≠stica 'c√≥digo postal' para que su distribuci√≥n sea la misma en todos los grupos raciales, eliminando su uso como proxy.", key="p10")
        st.text_area("2. Representaciones Justas (LFR, LAFTR)", placeholder="Ej: Usar un autoencoder adversario para aprender una representaci√≥n de los perfiles de los solicitantes que no contenga informaci√≥n de g√©nero.", key="p11")
        st.text_area("3. Consideraciones de Interseccionalidad", placeholder="Mi estrategia de transformaci√≥n se centrar√° en las intersecciones de g√©nero y etnia...", key="p12")

    with tab6:
        st.subheader("Generaci√≥n de Datos con Conciencia de Equidad")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Cuando los datos son muy escasos o sesgados, podemos generar datos sint√©ticos (artificiales) para llenar los vac√≠os. Esto es especialmente √∫til para crear ejemplos de grupos interseccionales muy peque√±os o para generar escenarios contrafactuales.")
        st.markdown("**¬øCu√°ndo Generar Datos?:** Cuando hay subrepresentaci√≥n severa o se necesitan ejemplos contrafactuales.")
        st.markdown("**Estrategias:** Generaci√≥n Condicional, Aumentaci√≥n Contrafactual.")
        st.text_area("Consideraciones de Interseccionalidad", placeholder="Ejemplo: Usaremos un modelo generativo condicionado en la intersecci√≥n de edad y g√©nero para crear perfiles sint√©ticos de 'mujeres mayores en tecnolog√≠a', un grupo ausente en nuestros datos.", key="p13")

    # --- Secci√≥n de Reporte ---
    st.markdown("---")
    st.header("Generar Reporte del Toolkit de Pre-procesamiento")
    if st.button("Generar Reporte de Pre-procesamiento", key="gen_preproc_report"):
        report_data = {
            "An√°lisis de Representaci√≥n": {
                "Comparaci√≥n con Poblaci√≥n de Referencia": st.session_state.p1,
                "An√°lisis Interseccional": st.session_state.p2,
                "Representaci√≥n en Resultados": st.session_state.p3,
            },
            "Detecci√≥n de Correlaci√≥n": {
                "Correlaciones Directas": st.session_state.p4,
                "Variables Proxy Identificadas": st.session_state.p5,
            },
            "Calidad de Etiquetas": {
                "Sesgo Hist√≥rico en Etiquetas": st.session_state.p6,
                "Sesgo del Anotador": st.session_state.p7,
            },
            "Re-ponderaci√≥n y Re-muestreo": {
                "Decisi√≥n y Raz√≥n": st.session_state.p8,
                "Plan Interseccional": st.session_state.p9,
            },
            "Transformaci√≥n de Distribuci√≥n": {
                "Plan de Eliminaci√≥n de Impacto Dispar": st.session_state.p10,
                "Plan de Representaciones Justas": st.session_state.p11,
                "Plan Interseccional": st.session_state.p12,
            },
            "Generaci√≥n de Datos": {
                "Plan de Generaci√≥n Interseccional": st.session_state.p13,
            }
        }
        
        report_md = "# Reporte del Toolkit de Equidad en Pre-procesamiento\n\n"
        for section, content in report_data.items():
            report_md += f"## {section}\n"
            for key, value in content.items():
                report_md += f"**{key}:**\n{value}\n\n"
        
        st.session_state.preproc_report_md = report_md
        st.success("¬°Reporte generado exitosamente!")

    if 'preproc_report_md' in st.session_state and st.session_state.preproc_report_md:
        st.subheader("Vista Previa del Reporte")
        st.markdown(st.session_state.preproc_report_md)
        st.download_button(
            label="Descargar Reporte de Pre-procesamiento",
            data=st.session_state.preproc_report_md,
            file_name="reporte_preprocesamiento.md",
            mime="text/markdown"
        )

def inprocessing_fairness_toolkit():
    st.header("‚öôÔ∏è Toolkit de Equidad en In-procesamiento")
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **In-procesamiento** implica modificar el algoritmo de aprendizaje del modelo para que la equidad sea uno de sus objetivos, junto con la precisi√≥n. Es como ense√±arle a un chef a cocinar no solo para que la comida sea deliciosa, sino tambi√©n para que sea nutricionalmente equilibrada, haciendo de la nutrici√≥n una parte central de la receta.
        """)
    
    tab1, tab2, tab3, tab4 = st.tabs(["Objetivos y Restricciones", "Debiasing Adversario", "Optimizaci√≥n Multiobjetivo", "Patrones de C√≥digo"])

    with tab1:
        st.subheader("Objetivos y Restricciones de Equidad")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Esto significa incorporar 'reglas de equidad' directamente en las matem√°ticas que el modelo utiliza para aprender. En lugar de solo buscar la respuesta m√°s precisa, el modelo tambi√©n debe asegurarse de no violar estas reglas.")
        
        st.markdown("**M√©todos Lagrangianos:**")
        with st.expander("üîç Definici√≥n y Ejemplo"):
            st.write("Es una t√©cnica matem√°tica para convertir una 'restricci√≥n dura' (una regla que no se puede romper) en una 'penalizaci√≥n suave'. Imagina que est√°s entrenando a un robot para que sea r√°pido, pero no puede pasar de cierta velocidad. En lugar de un l√≠mite estricto, le das una penalizaci√≥n cada vez que se acerca al l√≠mite. Esto lo anima a mantenerse dentro de los l√≠mites de una manera m√°s flexible.")
        st.latex(r''' \mathcal{L}(\theta, \lambda) = L(\theta) + \sum_{i=1}^{k} \lambda_i C_i(\theta) ''')
        st.text_area("Aplica a tu caso: ¬øQu√© restricci√≥n de equidad (ej. diferencia m√°xima de aprobaci√≥n) quieres implementar?", key="in_q1")

        st.markdown("**Viabilidad y Compensaciones:**")
        with st.expander("üîç Definici√≥n y Ejemplo"):
            st.write("No siempre es posible ser perfectamente justo y perfectamente preciso al mismo tiempo. A menudo, hay una 'compensaci√≥n' (trade-off). Mejorar la equidad puede reducir ligeramente la precisi√≥n general, y viceversa. Es crucial entender este equilibrio.")
            st.write("**Ejemplo de Interseccionalidad:** Forzar la igualdad de resultados para todos los subgrupos (ej. mujeres latinas, hombres asi√°ticos) puede ser matem√°ticamente imposible o requerir un sacrificio de precisi√≥n tan grande que el modelo deja de ser √∫til.")
        st.text_area("Aplica a tu caso: ¬øQu√© compensaci√≥n entre precisi√≥n y equidad est√°s dispuesto a aceptar?", key="in_q2")


    with tab2:
        st.subheader("Enfoques de Debiasing Adversario")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Imagina un juego entre dos IAs: un 'Predictor' que intenta hacer su trabajo (ej. evaluar curr√≠culums) y un 'Adversario' que intenta adivinar el atributo protegido (ej. el g√©nero del candidato) bas√°ndose en las decisiones del Predictor. El Predictor gana si hace buenas evaluaciones Y logra enga√±ar al Adversario. Con el tiempo, el Predictor aprende a tomar decisiones sin basarse en informaci√≥n relacionada con el g√©nero.")
        
        st.markdown("**Arquitectura:**")
        with st.expander("üí° Simulador de Arquitectura Adversaria"):
            st.graphviz_chart("""
            digraph {
                rankdir=LR;
                node [shape=box, style=rounded];
                "Datos de Entrada (X)" -> "Predictor";
                "Predictor" -> "Predicci√≥n (≈∂)";
                "Predictor" -> "Adversario" [label="Intenta enga√±ar"];
                "Adversario" -> "Predicci√≥n de Atributo Protegido (√Ç)";
                "Atributo Protegido (A)" -> "Adversario" [style=dashed, label="Compara para aprender"];
            }
            """)
        st.text_area("Aplica a tu caso: Describe la arquitectura que usar√≠as.", placeholder="Ej: Un predictor basado en BERT para analizar CVs y un adversario de 3 capas para predecir el g√©nero a partir de las representaciones internas.", key="in_q3")

        st.markdown("**Optimizaci√≥n:**")
        with st.expander("üîç Definici√≥n y Ejemplo"):
             st.write("El entrenamiento puede ser inestable porque el Predictor y el Adversario tienen objetivos opuestos. Se necesitan t√©cnicas especiales, como la 'inversi√≥n de gradiente', para que el Predictor aprenda a 'desaprender' el sesgo activamente.")
        st.text_area("Aplica a tu caso: ¬øQu√© desaf√≠os de optimizaci√≥n prev√©s y c√≥mo los abordar√≠as?", placeholder="Ej: El adversario podr√≠a volverse demasiado fuerte al principio. Usaremos un aumento gradual de su peso en la funci√≥n de p√©rdida.", key="in_q4")

    with tab3:
        st.subheader("Optimizaci√≥n Multiobjetivo para la Equidad")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("En lugar de combinar la precisi√≥n y la equidad en una sola meta, este enfoque las trata como dos objetivos separados que deben equilibrarse. El objetivo es encontrar un conjunto de 'soluciones √≥ptimas de Pareto', donde no se puede mejorar la equidad sin sacrificar algo de precisi√≥n, y viceversa.")
        with st.expander("üí° Ejemplo Interactivo: Frontera de Pareto"):
            st.write("Explora la **frontera de Pareto**, que visualiza la compensaci√≥n (trade-off) entre la precisi√≥n de un modelo y su equidad. No se puede mejorar uno sin empeorar el otro.")
            
            np.random.seed(10)
            accuracy = np.linspace(0.80, 0.95, 20)
            fairness_score = 1 - np.sqrt(accuracy - 0.79) + np.random.normal(0, 0.02, 20)
            fairness_score = np.clip(fairness_score, 0.5, 1.0)
            
            fig, ax = plt.subplots()
            ax.scatter(accuracy, fairness_score, c=accuracy, cmap='viridis', label='Modelos Posibles')
            ax.set_title("Frontera de Pareto: Equidad vs. Precisi√≥n")
            ax.set_xlabel("Precisi√≥n del Modelo")
            ax.set_ylabel("Puntuaci√≥n de Equidad")
            ax.grid(True, linestyle='--', alpha=0.6)
            st.pyplot(fig)
            st.info("Cada punto representa un modelo diferente. Los modelos en el borde superior derecho son '√≥ptimos'. La elecci√≥n de qu√© punto usar depende de las prioridades de tu proyecto.")
        st.text_area("Aplica a tu caso: ¬øCu√°les son los m√∫ltiples objetivos que necesitas equilibrar?", placeholder="Ej: 1. Maximizar la precisi√≥n en la predicci√≥n de impago. 2. Minimizar la diferencia en la tasa de aprobaci√≥n entre grupos demogr√°ficos. 3. Minimizar la diferencia en la tasa de falsos negativos.", key="in_q5")

    with tab4:
        st.subheader("Cat√°logo de Patrones de Implementaci√≥n")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Estos son fragmentos de c√≥digo o pseudoc√≥digo que muestran c√≥mo se ven en la pr√°ctica las t√©cnicas de in-procesamiento. Sirven como plantillas reutilizables para implementar la equidad en tu propio c√≥digo.")
        st.code("""
# Ejemplo de una funci√≥n de p√©rdida con regularizaci√≥n de equidad
def fairness_regularized_loss(original_loss, predictions, protected_attribute):
  # Calcula una penalizaci√≥n basada en la disparidad de las predicciones
  fairness_penalty = calculate_disparity(predictions, protected_attribute)
  
  # Combina la p√©rdida original con la penalizaci√≥n de equidad
  # lambda controla la importancia que se le da a la equidad
  return original_loss + lambda * fairness_penalty
        """, language="python")

    # --- Secci√≥n de Reporte ---
    st.markdown("---")
    st.header("Generar Reporte del Toolkit de In-procesamiento")
    if st.button("Generar Reporte de In-procesamiento", key="gen_inproc_report"):
        report_data = {
            "Objetivos y Restricciones": {
                "Restricci√≥n de Equidad": st.session_state.in_q1,
                "An√°lisis de Compensaciones": st.session_state.in_q2,
            },
            "Debiasing Adversario": {
                "Descripci√≥n de la Arquitectura": st.session_state.in_q3,
                "Plan de Optimizaci√≥n": st.session_state.in_q4,
            },
            "Optimizaci√≥n Multiobjetivo": {
                "Objetivos a Equilibrar": st.session_state.in_q5,
            }
        }
        
        report_md = "# Reporte del Toolkit de Equidad en In-procesamiento\n\n"
        for section, content in report_data.items():
            report_md += f"## {section}\n"
            for key, value in content.items():
                report_md += f"**{key}:**\n{value}\n\n"
        
        st.session_state.inproc_report_md = report_md
        st.success("¬°Reporte generado exitosamente!")

    if 'inproc_report_md' in st.session_state and st.session_state.inproc_report_md:
        st.subheader("Vista Previa del Reporte")
        st.markdown(st.session_state.inproc_report_md)
        st.download_button(
            label="Descargar Reporte de In-procesamiento",
            data=st.session_state.inproc_report_md,
            file_name="reporte_inprocesamiento.md",
            mime="text/markdown"
        )

def postprocessing_fairness_toolkit():
    st.header("üìä Toolkit de Equidad en Post-procesamiento")
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **Post-procesamiento** consiste en ajustar las predicciones de un modelo *despu√©s* de que ya ha sido entrenado. Es como un editor que revisa un texto ya escrito para corregir sesgos o errores. El modelo original no cambia, solo se ajusta su resultado final para que sea m√°s justo.
        """)
    
    tab1, tab2, tab3, tab4 = st.tabs(["Optimizaci√≥n de Umbrales", "Calibraci√≥n", "Transformaci√≥n de Predicci√≥n", "Clasificaci√≥n con Rechazo"])

    with tab1:
        st.subheader("T√©cnicas de Optimizaci√≥n de Umbrales")
        with st.expander("üí° Ejemplo Interactivo"):
             run_threshold_simulation()
        st.info("Ajusta los umbrales de clasificaci√≥n despu√©s del entrenamiento para satisfacer definiciones de equidad espec√≠ficas.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Seleccionar Criterio de Equidad (ej. igualdad de oportunidades)\n2. Calcular Umbrales en datos de validaci√≥n\n3. Analizar Compensaciones y Desplegar", key="po1")

    with tab2:
        st.subheader("Gu√≠a Pr√°ctica de Calibraci√≥n para la Equidad")
        st.info("Garantiza que las probabilidades predichas tengan un significado consistente en todos los grupos.")
        st.markdown("**Fundamentos:** Una mala calibraci√≥n significa que la misma puntuaci√≥n de riesgo representa diferentes niveles de riesgo real para diferentes grupos.")
        st.markdown("**T√©cnicas:** Platt Scaling, Regresi√≥n Isot√≥nica.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Evaluar Calibraci√≥n (con ECE, MCE)\n2. Seleccionar M√©todo\n3. Implementar y Validar", key="po2")

    with tab3:
        st.subheader("M√©todos de Transformaci√≥n de Predicci√≥n")
        st.info("Modifica las salidas del modelo para satisfacer restricciones de equidad complejas.")
        st.markdown("**Conceptos Clave:** Funciones de Transformaci√≥n Aprendidas, Alineaci√≥n de Distribuci√≥n, Transformaciones de Puntuaci√≥n Justas.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Dise√±ar Transformaci√≥n\n2. Aprender y Evaluar\n3. Considerar Interseccionalidad", key="po3")

    with tab4:
        st.subheader("Clasificaci√≥n con Opci√≥n de Rechazo")
        st.info("Identifica predicciones inciertas y las difiere a juicio humano.")
        st.markdown("**Fundamentos:** Umbrales de rechazo basados en confianza, clasificaci√≥n selectiva, modelos de colaboraci√≥n Humano-IA.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Estimar Confianza\n2. Optimizar Umbral de Rechazo\n3. Dise√±ar Flujo de Trabajo Humano-IA", key="po4")

def intervention_playbook():
    st.sidebar.title("Navegaci√≥n del Playbook de Intervenci√≥n")
    selection = st.sidebar.radio(
        "Ir a:",
        ["Playbook Principal", "Toolkit Causal", "Toolkit de Pre-procesamiento", "Toolkit de In-procesamiento", "Toolkit de Post-procesamiento"],
        key="intervention_nav"
    )
    
    if selection == "Playbook Principal":
        st.header("üìñ Playbook de Intervenci√≥n de Equidad")
        st.info("Este playbook integra los cuatro toolkits en un flujo de trabajo cohesivo, guiando a los desarrolladores desde la identificaci√≥n del sesgo hasta la implementaci√≥n de soluciones efectivas.")
        with st.expander("Gu√≠a de Implementaci√≥n"):
            st.write("Explica c√≥mo usar el playbook, con comentarios sobre puntos de decisi√≥n clave, evidencia de apoyo y riesgos identificados.")
        with st.expander("Estudio de Caso"):
            st.write("Demuestra la aplicaci√≥n del playbook a un problema de equidad t√≠pico, mostrando c√≥mo los resultados de cada componente informan al siguiente.")
        with st.expander("Marco de Validaci√≥n"):
            st.write("Proporciona orientaci√≥n sobre c√≥mo los equipos de implementaci√≥n pueden verificar la efectividad de su proceso de auditor√≠a.")
        with st.expander("Equidad Interseccional"):
            st.write("Consideraci√≥n expl√≠cita de la equidad interseccional en cada componente del playbook.")
    elif selection == "Toolkit Causal":
        causal_fairness_toolkit()
    elif selection == "Toolkit de Pre-procesamiento":
        preprocessing_fairness_toolkit()
    elif selection == "Toolkit de In-procesamiento":
        inprocessing_fairness_toolkit()
    elif selection == "Toolkit de Post-procesamiento":
        postprocessing_fairness_toolkit()

#======================================================================
# --- FAIRNESS AUDIT PLAYBOOK ---
#======================================================================

def audit_playbook():
    st.sidebar.title("Navegaci√≥n del Playbook de Auditor√≠a")
    page = st.sidebar.radio("Ir a", [
        "C√≥mo Navegar este Playbook",
        "Evaluaci√≥n del Contexto Hist√≥rico",
        "Selecci√≥n de Definici√≥n de Equidad",
        "Identificaci√≥n de Fuentes de Sesgo",
        "M√©tricas Comprensivas de Equidad"
    ], key="audit_nav")

    if page == "C√≥mo Navegar este Playbook":
        st.header("C√≥mo Navegar Este Playbook")
        st.markdown("""
        **El Marco de Cuatro Componentes** ‚Äì Sigue secuencialmente a trav√©s de:
        
        1. **Evaluaci√≥n del Contexto Hist√≥rico (HCA)** ‚Äì Descubre sesgos sist√©micos y desequilibrios de poder en tu dominio.
        
        2. **Selecci√≥n de Definici√≥n de Equidad (FDS)**
         ‚Äì Elige las definiciones de equidad apropiadas basadas en tu contexto y objetivos.
        
        3. **Identificaci√≥n de Fuentes de Sesgo (BSI)** ‚Äì Identifica y prioriza las formas en que el sesgo puede entrar en tu sistema.
        
        4. **M√©tricas Comprensivas de Equidad (CFM)**
         ‚Äì Implementa m√©tricas cuantitativas para el monitoreo y la presentaci√≥n de informes.

        **Consejos:**
        - Avanza por las secciones en orden, pero si√©ntete libre de retroceder si surgen nuevas ideas.
        - Usa los botones de **Guardar Resumen** en cada herramienta para registrar tus hallazgos.
        - Consulta los ejemplos incrustados en cada secci√≥n para ver c√≥mo otros han aplicado estas herramientas.
        """)
    elif page == "Evaluaci√≥n del Contexto Hist√≥rico":
        st.header("Herramienta de Evaluaci√≥n del Contexto Hist√≥rico")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("""
            El **Contexto Hist√≥rico** es el trasfondo social y cultural en el que se utilizar√° tu IA. Es importante porque los sesgos no nacen en los algoritmos, sino en la sociedad. Entender la historia de la discriminaci√≥n en √°reas como la banca o la contrataci√≥n nos ayuda a anticipar d√≥nde nuestra IA podr√≠a fallar y perpetuar injusticias pasadas.
            """)
        st.subheader("1. Cuestionario Estructurado")
        st.markdown("Esta secci√≥n te ayuda a descubrir patrones relevantes de discriminaci√≥n hist√≥rica.")
        
        q1 = st.text_area("¬øEn qu√© dominio espec√≠fico operar√° este sistema (ej. pr√©stamos, contrataci√≥n, salud)?")
        q2 = st.text_area("¬øCu√°l es la funci√≥n espec√≠fica del sistema o caso de uso dentro de ese dominio?")
        q3 = st.text_area("¬øCu√°les son los patrones de discriminaci√≥n hist√≥rica documentados en este dominio?")
        q4 = st.text_area("¬øQu√© fuentes de datos hist√≥ricos se utilizan o se referencian en este sistema?")
        q5 = st.text_area("¬øC√≥mo se definieron hist√≥ricamente las categor√≠as clave (ej. g√©nero, riesgo crediticio) y han evolucionado?")
        q6 = st.text_area("¬øC√≥mo se midieron hist√≥ricamente las variables (ej. ingresos, educaci√≥n)? ¬øPodr√≠an codificar sesgos?")
        q7 = st.text_area("¬øHan servido otras tecnolog√≠as para roles similares en este dominio? ¬øDesafiaron o reforzaron las desigualdades?")
        q8 = st.text_area("¬øC√≥mo podr√≠a la automatizaci√≥n amplificar los sesgos pasados o introducir nuevos riesgos en este dominio?")

        st.subheader("2. Matriz de Clasificaci√≥n de Riesgos")
        st.markdown("""
        Para cada patr√≥n hist√≥rico identificado, estima:
        - **Severidad**: Alto = impacta derechos/resultados de vida, Medio = afecta oportunidades/acceso a recursos, Bajo = impacto material limitado.
        - **Probabilidad**: Alta = probable que aparezca en sistemas similares, Media = posible, Baja = raro.
        - **Relevancia**: Alta = directamente relacionado con tu sistema, Media = afecta partes, Baja = perif√©rico.
        """)
        matrix = st.text_area("Matriz de Clasificaci√≥n de Riesgos (tabla Markdown)", height=200, placeholder="| Patr√≥n | Severidad | Probabilidad | Relevancia | Puntuaci√≥n (S√óP√óR) | Prioridad |\n|---|---|---|---|---|---|")

        if st.button("Guardar Resumen HCA"):
            summary = {
                "Cuestionario Estructurado": {
                    "Dominio": q1, "Funci√≥n": q2, "Patrones Hist√≥ricos": q3, "Fuentes de Datos": q4,
                    "Definiciones de Categor√≠a": q5, "Riesgos de Medici√≥n": q6, "Sistemas Anteriores": q7, "Riesgos de Automatizaci√≥n": q8
                },
                "Matriz de Riesgos": matrix
            }
            summary_md = "# Resumen de Evaluaci√≥n del Contexto Hist√≥rico\n"
            for section, answers in summary.items():
                summary_md += f"## {section}\n"
                if isinstance(answers, dict):
                    for k, v in answers.items():
                        summary_md += f"**{k}:** {v}\n\n"
                else:
                    summary_md += f"{answers}\n"
            
            st.subheader("Vista Previa del Resumen HCA")
            st.markdown(summary_md)
            st.download_button("Descargar Resumen HCA", summary_md, "HCA_summary.md", "text/markdown")
            st.success("Resumen de Evaluaci√≥n del Contexto Hist√≥rico guardado.")

    elif page == "Selecci√≥n de Definici√≥n de Equidad":
        st.header("Herramienta de Selecci√≥n de Definici√≥n de Equidad")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("""
            No existe una √∫nica "receta" para la equidad. Diferentes situaciones requieren diferentes tipos de justicia. Esta secci√≥n te ayuda a elegir la **definici√≥n de equidad** m√°s adecuada para tu proyecto, como un m√©dico que elige el tratamiento correcto para una enfermedad espec√≠fica. Algunas definiciones buscan igualdad de resultados, otras igualdad de oportunidades, y la elecci√≥n correcta depende de tu objetivo y del da√±o que intentas evitar.
            """)
        st.subheader("1. Cat√°logo de Definiciones de Equidad")
        st.markdown("""
        | Definici√≥n | F√≥rmula | Cu√°ndo Usar | Ejemplo |
        |---|---|---|---|
        | Paridad Demogr√°fica | P(≈∂=1|A=a) = P(≈∂=1|A=b) | Asegurar tasas de positivos iguales entre grupos. | Anuncios de universidad mostrados por igual a todos los g√©neros. |
        | Igualdad de Oportunidades | P(≈∂=1|Y=1,A=a) = P(≈∂=1|Y=1,A=b) | Minimizar falsos negativos entre individuos calificados. | Sensibilidad de prueba m√©dica igual entre razas. |
        | Probabilidades Igualadas | P(≈∂=1|Y=y,A=a) = P(≈∂=1|Y=y,A=b) ‚àÄ y | Equilibrar falsos positivos y negativos entre grupos. | Predicciones de reincidencia con tasas de error iguales. |
        | Calibraci√≥n | P(Y=1|≈ù=s,A=a) = s | Cuando las puntuaciones predichas se exponen a los usuarios. | Puntuaciones de cr√©dito calibradas para diferentes demograf√≠as. |
        | Equidad Contrafactual | ≈∂(x) = ≈∂(x') si A cambia | Requerir eliminaci√≥n de sesgo causal relativo a rasgos sensibles. | Resultado sin cambios si solo cambia la raza en el perfil. |
        """)
        st.subheader("2. √Årbol de Decisi√≥n para Selecci√≥n")
        exclusion = st.radio("¬øEl HCA revel√≥ exclusi√≥n sist√©mica de grupos protegidos?", ("S√≠", "No"), key="fds1")
        error_harm = st.radio("¬øQu√© tipo de error es m√°s da√±ino en tu contexto?", ("Falsos Negativos", "Falsos Positivos", "Ambos por igual"), key="fds2")
        score_usage = st.checkbox("¬øSe usar√°n las salidas como puntuaciones (ej. riesgo, ranking)?", key="fds3")
        
        st.subheader("Definiciones Recomendadas")
        definitions = []
        if exclusion == "S√≠": definitions.append("Paridad Demogr√°fica")
        if error_harm == "Falsos Negativos": definitions.append("Igualdad de Oportunidades")
        elif error_harm == "Falsos Positivos": definitions.append("Igualdad Predictiva")
        elif error_harm == "Ambos por igual": definitions.append("Probabilidades Igualadas")
        if score_usage: definitions.append("Calibraci√≥n")
        
        for d in definitions: st.markdown(f"- **{d}**")
    
    # (El resto de las secciones del Audit Playbook se pueden a√±adir aqu√≠ de manera similar)
    elif page == "Identificaci√≥n de Fuentes de Sesgo":
        st.header("Herramienta de Identificaci√≥n de Fuentes de Sesgo")
        # (Contenido de esta secci√≥n)
    elif page == "M√©tricas Comprensivas de Equidad":
        st.header("M√©tricas Comprensivas de Equidad (CFM)")
        # (Contenido de esta secci√≥n)


# --- NAVEGACI√ìN PRINCIPAL ---
st.sidebar.title("Selecci√≥n de Playbook")
playbook_choice = st.sidebar.selectbox(
    "Elige el playbook que quieres usar:",
    ["Fairness Audit Playbook", "Fairness Intervention Playbook"]
)

st.title(playbook_choice)

if playbook_choice == "Fairness Audit Playbook":
    audit_playbook() 
else:
    intervention_playbook()