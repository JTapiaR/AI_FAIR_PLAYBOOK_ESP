import streamlit as st
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.isotonic import IsotonicRegression

# --- Configuraci√≥n de la P√°gina ---
st.set_page_config(
    page_title="AI Fairness Playbooks",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

#======================================================================
# --- FUNCIONES DE SIMULACI√ìN ---
#======================================================================

def run_threshold_simulation():
    """Simulaci√≥n para optimizaci√≥n de umbrales en post-procesamiento."""
    st.markdown("#### Simulaci√≥n de Optimizaci√≥n de Umbrales")
    st.write("Ajusta los umbrales de decisi√≥n para dos grupos y observa c√≥mo cambian las tasas de error para lograr la **Igualdad de Oportunidades** (tasas de verdaderos positivos iguales).")

    np.random.seed(42)
    scores_a_pos = np.random.normal(0.7, 0.15, 80)
    scores_a_neg = np.random.normal(0.4, 0.15, 120)
    scores_b_pos = np.random.normal(0.6, 0.15, 50)
    scores_b_neg = np.random.normal(0.3, 0.15, 150)

    df_a = pd.DataFrame({'Puntuaci√≥n': np.concatenate([scores_a_pos, scores_a_neg]), 'Real': [1]*80 + [0]*120})
    df_b = pd.DataFrame({'Puntuaci√≥n': np.concatenate([scores_b_pos, scores_b_neg]), 'Real': [1]*50 + [0]*150})
    
    col1, col2 = st.columns(2)
    with col1:
        threshold_a = st.slider("Umbral para Grupo A", 0.0, 1.0, 0.5, key="sim_thresh_a")
    with col2:
        threshold_b = st.slider("Umbral para Grupo B", 0.0, 1.0, 0.5, key="sim_thresh_b")

    tpr_a = np.mean(df_a[df_a['Real'] == 1]['Puntuaci√≥n'] >= threshold_a)
    fpr_a = np.mean(df_a[df_a['Real'] == 0]['Puntuaci√≥n'] >= threshold_a)
    tpr_b = np.mean(df_b[df_b['Real'] == 1]['Puntuaci√≥n'] >= threshold_b)
    fpr_b = np.mean(df_b[df_b['Real'] == 0]['Puntuaci√≥n'] >= threshold_b)

    st.markdown("##### Resultados")
    res_col1, res_col2 = st.columns(2)
    with res_col1:
        st.metric(label="Tasa de Verdaderos Positivos (Grupo A)", value=f"{tpr_a:.2%}")
        st.metric(label="Tasa de Falsos Positivos (Grupo A)", value=f"{fpr_a:.2%}")
    with res_col2:
        st.metric(label="Tasa de Verdaderos Positivos (Grupo B)", value=f"{tpr_b:.2%}")
        st.metric(label="Tasa de Falsos Positivos (Grupo B)", value=f"{fpr_b:.2%}")

    if abs(tpr_a - tpr_b) < 0.02:
        st.success(f"¬°Casi has logrado la Igualdad de Oportunidades! La diferencia en TPR es de solo {abs(tpr_a - tpr_b):.2%}.")
    else:
        st.warning(f"Ajusta los umbrales para igualar las Tasas de Verdaderos Positivos. Diferencia actual: {abs(tpr_a - tpr_b):.2%}")

def run_calibration_simulation():
    st.markdown("#### Simulaci√≥n de Calibraci√≥n")
    st.write("Observa c√≥mo las puntuaciones brutas de un modelo (l√≠nea azul) pueden estar mal calibradas y c√≥mo t√©cnicas como **Platt Scaling** (log√≠stica) o **Regresi√≥n Isot√≥nica** las ajustan para que se alineen mejor con la realidad (l√≠nea diagonal perfecta).")
    
    np.random.seed(0)
    # Generar puntuaciones de modelo mal calibradas
    raw_scores = np.sort(np.random.rand(100))
    true_probs = 1 / (1 + np.exp(-(raw_scores * 4 - 2))) # Una curva sigmoide para simular la realidad
    
    # Platt Scaling
    platt = LogisticRegression()
    platt.fit(raw_scores.reshape(-1, 1), (true_probs > 0.5).astype(int))
    calibrated_platt = platt.predict_proba(raw_scores.reshape(-1, 1))[:, 1]

    # Isotonic Regression
    isotonic = IsotonicRegression(out_of_bounds='clip')
    isotonic.fit(raw_scores, true_probs)
    calibrated_isotonic = isotonic.predict(raw_scores)

    fig, ax = plt.subplots()
    ax.plot([0, 1], [0, 1], 'k--', label='Calibraci√≥n Perfecta')
    ax.plot(raw_scores, true_probs, 'b-', label='Puntuaciones Originales (Mal Calibradas)')
    ax.plot(raw_scores, calibrated_platt, 'g:', label='Calibrado con Platt Scaling')
    ax.plot(raw_scores, calibrated_isotonic, 'r-.', label='Calibrado con Regresi√≥n Isot√≥nica')
    ax.set_title("Comparaci√≥n de T√©cnicas de Calibraci√≥n")
    ax.set_xlabel("Probabilidad Predicha")
    ax.set_ylabel("Fracci√≥n Real de Positivos")
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.5)
    st.pyplot(fig)
    st.info("El objetivo es que las l√≠neas de las puntuaciones se acerquen lo m√°s posible a la l√≠nea diagonal punteada, que representa una calibraci√≥n perfecta.")

def run_rejection_simulation():
    st.markdown("#### Simulaci√≥n de Clasificaci√≥n con Rechazo")
    st.write("Establece un umbral de confianza. Las predicciones con una confianza (probabilidad) muy alta o muy baja se automatizan. Las que caen en la 'zona de incertidumbre' se rechazan y se env√≠an a un humano para su revisi√≥n.")

    np.random.seed(1)
    scores = np.random.beta(2, 2, 200) # Probabilidades entre 0 y 1

    low_thresh = st.slider("Umbral de Confianza Inferior", 0.0, 0.5, 0.25)
    high_thresh = st.slider("Umbral de Confianza Superior", 0.5, 1.0, 0.75)

    automated_low = scores[scores <= low_thresh]
    automated_high = scores[scores >= high_thresh]
    rejected = scores[(scores > low_thresh) & (scores < high_thresh)]

    fig, ax = plt.subplots()
    ax.hist(automated_low, bins=10, range=(0,1), color='green', alpha=0.7, label=f'Decisi√≥n Autom√°tica (Baja Prob, n={len(automated_low)})')
    ax.hist(rejected, bins=10, range=(0,1), color='orange', alpha=0.7, label=f'Rechazado a Humano (n={len(rejected)})')
    ax.hist(automated_high, bins=10, range=(0,1), color='blue', alpha=0.7, label=f'Decisi√≥n Autom√°tica (Alta Prob, n={len(automated_high)})')
    ax.set_title("Distribuci√≥n de Decisiones")
    ax.set_xlabel("Puntuaci√≥n de Probabilidad del Modelo")
    ax.set_ylabel("Frecuencia")
    ax.legend()
    st.pyplot(fig)
    
    coverage = (len(automated_low) + len(automated_high)) / len(scores)
    st.metric("Tasa de Cobertura (Automatizaci√≥n)", f"{coverage:.1%}")
    st.info("Ajusta los umbrales para ver c√≥mo cambia la cantidad de casos que se automatizan vs. los que requieren revisi√≥n humana. Un rango de rechazo m√°s amplio aumenta la equidad en casos dif√≠ciles a costa de una menor automatizaci√≥n.")

#======================================================================
# --- FAIRNESS INTERVENTION PLAYBOOK ---
#======================================================================

def causal_fairness_toolkit():
    st.header("üõ°Ô∏è Toolkit de Equidad Causal")
    
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **An√°lisis Causal** va m√°s all√° de las correlaciones para entender el *porqu√©* de las disparidades. Es como ser un detective que no solo ve que dos eventos ocurren juntos, sino que reconstruye la cadena de causa y efecto que los conecta. Esto nos ayuda a aplicar soluciones que atacan la ra√≠z del problema, en lugar de solo maquillar los s√≠ntomas.
        """)
    
    if 'causal_report' not in st.session_state:
        st.session_state.causal_report = {}

    tab1, tab2, tab3, tab4 = st.tabs(["Identificaci√≥n", "An√°lisis Contrafactual", "Diagrama Causal", "Inferencia Causal"])

    with tab1:
        st.subheader("Marco de Identificaci√≥n de Mecanismos de Discriminaci√≥n")
        st.info("Identifica las posibles causas ra√≠z del sesgo en tu aplicaci√≥n.")
        
        with st.expander("Definici√≥n de Discriminaci√≥n Directa"):
            st.write("Ocurre cuando un atributo protegido (como la raza o el g√©nero) es usado expl√≠citamente para tomar una decisi√≥n. Es el tipo de sesgo m√°s obvio.")
        st.text_area("1. ¬øEl atributo protegido influye directamente en la decisi√≥n?", placeholder="Ejemplo: Un modelo de contrataci√≥n que asigna una puntuaci√≥n menor a las candidatas mujeres de forma expl√≠cita.", key="causal_q1")
        
        with st.expander("Definici√≥n de Discriminaci√≥n Indirecta"):
            st.write("Ocurre cuando un atributo protegido afecta a un factor intermedio que s√≠ es leg√≠timo para la decisi√≥n. El sesgo se transmite a trav√©s de esta variable mediadora.")
        st.text_area("2. ¬øEl atributo protegido afecta a factores intermedios leg√≠timos?", placeholder="Ejemplo: El g√©nero puede influir en tener 'pausas en la carrera' (para el cuidado de hijos), y el modelo penaliza estas pausas, afectando indirectamente a las mujeres.", key="causal_q2")

        with st.expander("Definici√≥n de Discriminaci√≥n por Proxy"):
            st.write("Ocurre cuando una variable aparentemente neutral est√° tan correlacionada con un atributo protegido que funciona como un sustituto (un 'proxy') de este.")
        st.text_area("3. ¬øLas decisiones dependen de variables correlacionadas con atributos protegidos?", placeholder="Ejemplo: En un modelo de cr√©dito, usar el c√≥digo postal como predictor puede ser un proxy de la raza debido a la segregaci√≥n residencial hist√≥rica.", key="causal_q3")

    with tab2:
        st.subheader("Metodolog√≠a Pr√°ctica de Equidad Contrafactual")
        st.info("Analiza, cuantifica y mitiga el sesgo contrafactual en tu modelo.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n Contrafactual"):
            st.write("Observa c√≥mo un cambio en un atributo protegido puede alterar la decisi√≥n de un modelo, revelando un sesgo causal.")
            puntaje_base = 650
            decision_base = "Rechazado"
            st.write(f"**Caso Base:** Solicitante del **Grupo B** con un puntaje de **{puntaje_base}**. Decisi√≥n del modelo: **{decision_base}**.")
            if st.button("Ver Contrafactual (Cambiar a Grupo A)", key="cf_button"):
                puntaje_cf = 710
                decision_cf = "Aprobado"
                st.info(f"**Escenario Contrafactual:** Mismo solicitante, pero del **Grupo A**. El modelo ahora predice un puntaje de **{puntaje_cf}** y la decisi√≥n es: **{decision_cf}**.")
                st.warning("**An√°lisis:** El cambio en el atributo protegido alter√≥ la decisi√≥n, lo que sugiere que el modelo ha aprendido una dependencia causal problem√°tica.")
        
        with st.container(border=True):
            st.markdown("##### Paso 1: An√°lisis de Equidad Contrafactual")
            st.text_area("1.1 Formular Consultas Contrafactuales", placeholder="Ejemplo: Para un solicitante de pr√©stamo rechazado, ¬øcu√°l habr√≠a sido el resultado si su raza fuera diferente, manteniendo constantes los ingresos y el historial crediticio?", key="causal_q4")
            st.text_area("1.2 Identificar Rutas Causales (Justas vs. Injustas)", placeholder="Ejemplo: La ruta Raza ‚Üí C√≥digo Postal ‚Üí Decisi√≥n de Pr√©stamo es injusta porque el c√≥digo postal es un proxy. La ruta Nivel Educativo ‚Üí Ingresos ‚Üí Decisi√≥n de Pr√©stamo es considerada justa.", key="causal_q5")
            st.text_area("1.3 Medir Disparidades y Documentar", placeholder="Ejemplo: El 15% de los solicitantes del grupo desfavorecido habr√≠an sido aprobados en el escenario contrafactual. Esto indica una violaci√≥n de equidad contrafactual.", key="causal_q6")
        with st.container(border=True):
            st.markdown("##### Paso 2: An√°lisis Espec√≠fico de Rutas")
            st.text_area("2.1 Descomponer y Clasificar Rutas", placeholder="Ejemplo: Ruta 1 (proxy de c√≥digo postal) clasificada como INJUSTA. Ruta 2 (mediada por ingresos) clasificada como JUSTA.", key="causal_q7")
            st.text_area("2.2 Cuantificar Contribuci√≥n y Documentar", placeholder="Ejemplo: La ruta del c√≥digo postal representa el 60% de la disparidad observada. Raz√≥n: Refleja sesgos hist√≥ricos de segregaci√≥n residencial.", key="causal_q8")
        with st.container(border=True):
            st.markdown("##### Paso 3: Dise√±o de Intervenci√≥n")
            st.selectbox("3.1 Seleccionar Enfoque de Intervenci√≥n", ["Nivel de Datos", "Nivel de Modelo", "Post-procesamiento"], key="causal_q9")
            st.text_area("3.2 Implementar y Monitorear", placeholder="Ejemplo: Se aplic√≥ una transformaci√≥n a la caracter√≠stica de c√≥digo postal. La disparidad contrafactual se redujo en un 50%.", key="causal_q10")

    with tab3:
        st.subheader("Enfoque de Diagrama Causal Inicial")
        st.info("Esboza diagramas para visualizar las relaciones causales y documentar tus supuestos.")
        with st.expander("üí° Simulador de Diagrama Causal"):
            st.write("Construye un diagrama causal simple seleccionando las relaciones entre variables. Esto te ayuda a visualizar tus hip√≥tesis sobre c√≥mo funciona el sesgo.")
            
            nodos = ["G√©nero", "Educaci√≥n", "Ingresos", "Decisi√≥n_Pr√©stamo"]
            relaciones_posibles = [
                ("G√©nero", "Educaci√≥n"), ("G√©nero", "Ingresos"),
                ("Educaci√≥n", "Ingresos"), ("Ingresos", "Decisi√≥n_Pr√©stamo"),
                ("Educaci√≥n", "Decisi√≥n_Pr√©stamo"), ("G√©nero", "Decisi√≥n_Pr√©stamo")
            ]
            
            st.multiselect(
                "Selecciona las relaciones causales (Causa ‚Üí Efecto):",
                options=[f"{causa} ‚Üí {efecto}" for causa, efecto in relaciones_posibles],
                key="causal_q11_relations"
            )
            
            if st.session_state.causal_q11_relations:
                dot_string = "digraph { rankdir=LR; "
                for rel in st.session_state.causal_q11_relations:
                    causa, efecto = rel.split(" ‚Üí ")
                    dot_string += f'"{causa}" -> "{efecto}"; '
                dot_string += "}"
                st.graphviz_chart(dot_string)

        st.markdown("""
        **Convenciones de Anotaci√≥n:**
        - **Nodos (variables):** Atributos Protegidos, Caracter√≠sticas, Resultados.
        - **Flechas Causales (‚Üí):** Relaci√≥n causal asumida.
        - **Flechas de Correlaci√≥n (<-->):** Correlaci√≥n sin causalidad directa conocida.
        - **Incertidumbre (?):** Relaci√≥n causal hipot√©tica o d√©bil.
        - **Ruta Problem√°tica (!):** Ruta que consideras una fuente de inequidad.
        """)
        st.text_area("Documentaci√≥n de Supuestos y Rutas", placeholder="Ruta (!): Raza -> Nivel de Ingresos -> Decisi√≥n.\nSupuesto: Las disparidades hist√≥ricas de ingresos vinculadas a la raza afectan la capacidad de pr√©stamo.", height=200, key="causal_q11")

    with tab4:
        st.subheader("Inferencia Causal con Datos Limitados")
        st.info("M√©todos pr√°cticos para estimar efectos causales cuando los datos son imperfectos.")
        
        with st.expander("üîç Definici√≥n: Emparejamiento (Matching)"):
            st.write("Compara individuos de un grupo de 'tratamiento' con individuos muy similares de un grupo de 'control'. Al comparar 'gemelos' estad√≠sticos, se a√≠sla el efecto del tratamiento. En equidad, el 'tratamiento' puede ser pertenecer a un grupo demogr√°fico.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de Emparejamiento"):
            run_matching_simulation()

        with st.expander("üîç Definici√≥n: Variables Instrumentales (IV)"):
            st.write("Usa una variable 'instrumento' que afecta al tratamiento, pero no directamente al resultado, para desenredar la correlaci√≥n de la causalidad. Es como encontrar un interruptor que solo enciende una luz espec√≠fica en un panel complicado, permiti√©ndote saber qu√© hace exactamente esa luz.")
            st.graphviz_chart("""
            digraph {
                rankdir=LR;
                Z [label="Instrumento (Z)"];
                A [label="Atributo Protegido (A)"];
                Y [label="Resultado (Y)"];
                U [label="Factor de Confusi√≥n No Observado (U)", style=dashed];
                Z -> A;
                A -> Y;
                U -> A [style=dashed];
                U -> Y [style=dashed];
            }
            """)
            st.write("**Ejemplo:** Para medir el efecto causal de la educaci√≥n (A) en los ingresos (Y), se puede usar la proximidad a una universidad (Z) como instrumento. La proximidad afecta la educaci√≥n, pero no directamente a los ingresos (excepto a trav√©s de la educaci√≥n).")

        with st.expander("üîç Definici√≥n: Regresi√≥n por Discontinuidad (RD)"):
            st.write("Aprovecha un umbral o punto de corte en la asignaci√≥n de un tratamiento. Al comparar a quienes est√°n justo por encima y por debajo del umbral, se puede estimar el efecto causal del tratamiento, asumiendo que estos individuos son muy similares en otros aspectos.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de RD"):
            run_rd_simulation()

        with st.expander("üîç Definici√≥n: Diferencia en Diferencias (DiD)"):
            st.write("Compara el cambio en los resultados a lo largo del tiempo entre un grupo de tratamiento y un grupo de control. La 'diferencia en diferencias' entre los grupos antes y despu√©s del tratamiento estima el efecto causal.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de DiD"):
            run_did_simulation()

    # --- Secci√≥n de Reporte ---
    st.markdown("---")
    st.header("Generar Reporte del Toolkit Causal")
    if st.button("Generar Reporte Causal", key="gen_causal_report"):
        # Recopilar datos del session_state
        report_data = {
            "Identificaci√≥n de Mecanismos": {
                "Discriminaci√≥n Directa": st.session_state.get('causal_q1', 'No completado'),
                "Discriminaci√≥n Indirecta": st.session_state.get('causal_q2', 'No completado'),
                "Discriminaci√≥n por Proxy": st.session_state.get('causal_q3', 'No completado'),
            },
            "An√°lisis Contrafactual": {
                "Consultas Contrafactuales": st.session_state.get('causal_q4', 'No completado'),
                "Identificaci√≥n de Rutas Causales": st.session_state.get('causal_q5', 'No completado'),
                "Medici√≥n de Disparidades": st.session_state.get('causal_q6', 'No completado'),
                "Descomposici√≥n de Rutas": st.session_state.get('causal_q7', 'No completado'),
                "Cuantificaci√≥n de Contribuci√≥n": st.session_state.get('causal_q8', 'No completado'),
                "Enfoque de Intervenci√≥n Seleccionado": st.session_state.get('causal_q9', 'No completado'),
                "Plan de Implementaci√≥n y Monitoreo": st.session_state.get('causal_q10', 'No completado'),
            },
            "Diagrama Causal": {
                "Relaciones Seleccionadas": ", ".join(st.session_state.get('causal_q11_relations', [])),
                "Documentaci√≥n de Supuestos": st.session_state.get('causal_q11', 'No completado'),
            }
        }

        # Formatear reporte en Markdown
        report_md = "# Reporte del Toolkit de Equidad Causal\n\n"
        for section, content in report_data.items():
            report_md += f"## {section}\n"
            for key, value in content.items():
                report_md += f"**{key}:**\n{value}\n\n"
        
        st.session_state.causal_report_md = report_md
        st.success("¬°Reporte generado exitosamente! Puedes verlo a continuaci√≥n y descargarlo.")

    if 'causal_report_md' in st.session_state and st.session_state.causal_report_md:
        st.subheader("Vista Previa del Reporte")
        st.markdown(st.session_state.causal_report_md)
        st.download_button(
            label="Descargar Reporte Causal",
            data=st.session_state.causal_report_md,
            file_name="reporte_equidad_causal.md",
            mime="text/markdown"
        )


def preprocessing_fairness_toolkit():
    st.header("üß™ Toolkit de Equidad en Pre-procesamiento")
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **Pre-procesamiento** consiste en "limpiar" los datos *antes* de que el modelo aprenda de ellos. Es como preparar los ingredientes para una receta: si sabes que algunos ingredientes est√°n sesgados (por ejemplo, demasiado salados), los ajustas antes de cocinar para asegurar que el plato final sea equilibrado.
        """)
    
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["An√°lisis de Representaci√≥n", "Detecci√≥n de Correlaci√≥n", "Calidad de Etiquetas", "Re-ponderaci√≥n y Re-muestreo", "Transformaci√≥n", "Generaci√≥n de Datos"])

    with tab1:
        st.subheader("An√°lisis de Representaci√≥n Multidimensional")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Esto significa verificar si todos los grupos demogr√°ficos est√°n representados de manera justa en tus datos. No solo miramos los grupos principales (como hombres y mujeres), sino tambi√©n las intersecciones (como mujeres de una etnia espec√≠fica).")
        
        with st.expander("üí° Ejemplo Interactivo: Brecha de Representaci√≥n"):
            st.write("Compara la representaci√≥n de dos grupos en tu conjunto de datos con su representaci√≥n en una poblaci√≥n de referencia (ej. el censo).")
            pop_a = 50
            pop_b = 50
            
            col1, col2 = st.columns(2)
            with col1:
                data_a = st.slider("Porcentaje del Grupo A en tus datos", 0, 100, 70)
            data_b = 100 - data_a
            
            df = pd.DataFrame({
                'Grupo': ['Grupo A', 'Grupo B'],
                'Poblaci√≥n de Referencia': [pop_a, pop_b],
                'Tus Datos': [data_a, data_b]
            })

            with col2:
                st.write("Comparaci√≥n:")
                st.dataframe(df.set_index('Grupo'))

            if abs(data_a - pop_a) > 10:
                st.warning(f"Hay una brecha de representaci√≥n significativa. El Grupo A est√° sobrerrepresentado en tus datos en {data_a - pop_a} puntos porcentuales.")
            else:
                st.success("La representaci√≥n en tus datos es similar a la poblaci√≥n de referencia.")

        st.text_area("1. Comparaci√≥n con Poblaci√≥n de Referencia", placeholder="Ej: Nuestro conjunto de datos tiene un 70% del Grupo A y 30% del Grupo B, mientras que la poblaci√≥n real es 50/50.", key="p1")
        st.text_area("2. An√°lisis de Representaci√≥n Interseccional", placeholder="Ej: Las mujeres de minor√≠as raciales constituyen solo el 3% de los datos, aunque representan el 10% de la poblaci√≥n.", key="p2")
        st.text_area("3. Representaci√≥n a trav√©s de Categor√≠as de Resultados", placeholder="Ej: El grupo A constituye el 30% de las solicitudes pero solo el 10% de las aprobadas.", key="p3")

    with tab2:
        st.subheader("Detecci√≥n de Patrones de Correlaci√≥n")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Buscamos variables aparentemente neutrales que est√©n fuertemente conectadas a atributos protegidos. Por ejemplo, si un c√≥digo postal se correlaciona fuertemente con la raza, el modelo podr√≠a usar el c√≥digo postal para discriminar indirectamente.")
        
        with st.expander("üí° Ejemplo Interactivo: Detecci√≥n de Proxy"):
            st.write("Visualiza c√≥mo una variable 'Proxy' (ej. C√≥digo Postal) puede estar correlacionada tanto con un Atributo Protegido (ej. Grupo Demogr√°fico) como con el Resultado (ej. Puntuaci√≥n de Cr√©dito).")
            np.random.seed(1)
            grupo = np.random.randint(0, 2, 100) # 0 o 1
            proxy = grupo * 20 + np.random.normal(50, 5, 100)
            resultado = proxy * 5 + np.random.normal(100, 20, 100)
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
            ax1.scatter(grupo, proxy, c=grupo, cmap='coolwarm', alpha=0.7)
            ax1.set_title("Atributo Protegido vs. Variable Proxy")
            ax1.set_xlabel("Grupo Demogr√°fico (0 o 1)")
            ax1.set_ylabel("Valor del Proxy (ej. C√≥digo Postal)")
            ax1.grid(True, linestyle='--', alpha=0.5)

            ax2.scatter(proxy, resultado, c=grupo, cmap='coolwarm', alpha=0.7)
            ax2.set_title("Variable Proxy vs. Resultado")
            ax2.set_xlabel("Valor del Proxy (ej. C√≥digo Postal)")
            ax2.set_ylabel("Resultado (ej. Puntuaci√≥n de Cr√©dito)")
            ax2.grid(True, linestyle='--', alpha=0.5)
            st.pyplot(fig)
            st.info("El gr√°fico de la izquierda muestra que el proxy est√° correlacionado con el grupo. El de la derecha muestra que el proxy predice el resultado. Por lo tanto, el modelo puede usar el proxy para discriminar.")

        st.text_area("1. Correlaciones Directas (Atributo Protegido ‚Üî Resultado)", placeholder="Ej: En los datos hist√≥ricos, el g√©nero tiene una correlaci√≥n de 0.3 con la decisi√≥n de contrataci√≥n.", key="p4")
        st.text_area("2. Identificaci√≥n de Variables Proxy (Atributo Protegido ‚Üî Caracter√≠stica)", placeholder="Ej: La caracter√≠stica 'asistencia a un club de ajedrez' est√° altamente correlacionada con el g√©nero masculino.", key="p5")

    with tab3:
        st.subheader("Evaluaci√≥n de la Calidad de las Etiquetas")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Las 'etiquetas' son las respuestas correctas en tus datos de entrenamiento (ej. 'fue contratado', 'no pag√≥ el pr√©stamo'). Si estas etiquetas provienen de decisiones humanas pasadas que fueron sesgadas, tu modelo aprender√° ese mismo sesgo.")
        st.text_area("1. Sesgo Hist√≥rico en las Decisiones", placeholder="Ejemplo: Las etiquetas de 'promocionado' en nuestro conjunto de datos provienen de un per√≠odo en el que la empresa ten√≠a pol√≠ticas de promoci√≥n sesgadas, por lo que las etiquetas en s√≠ mismas son una fuente de sesgo.", key="p6")
        st.text_area("2. Sesgo del Anotador", placeholder="Ejemplo: El an√°lisis del acuerdo entre anotadores muestra que los anotadores masculinos calificaron los mismos comentarios como 't√≥xicos' con menos frecuencia que las anotadoras femeninas, lo que indica un sesgo en la etiqueta.", key="p7")
    
    with tab4:
        st.subheader("T√©cnicas de Re-ponderaci√≥n y Re-muestreo")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("**Re-ponderaci√≥n:** Le da m√°s 'peso' o importancia a las muestras de grupos subrepresentados. **Re-muestreo:** Cambia f√≠sicamente el conjunto de datos, ya sea duplicando muestras de grupos minoritarios (sobremuestreo) o eliminando muestras de grupos mayoritarios (submuestreo).")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de Sobremuestreo"):
            st.write("Observa c√≥mo el sobremuestreo (resampling) puede equilibrar un conjunto de datos con representaci√≥n desigual.")
            np.random.seed(0)
            data_a = np.random.multivariate_normal([2, 2], [[1, .5], [.5, 1]], 100)
            data_b = np.random.multivariate_normal([4, 4], [[1, .5], [.5, 1]], 20)
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
            
            ax1.scatter(data_a[:, 0], data_a[:, 1], c='blue', label='Grupo A (n=100)', alpha=0.6)
            ax1.scatter(data_b[:, 0], data_b[:, 1], c='red', label='Grupo B (n=20)', alpha=0.6)
            ax1.set_title("Datos Originales (Desequilibrados)")
            ax1.legend()
            ax1.grid(True, linestyle='--', alpha=0.5)

            oversample_indices = np.random.choice(range(20), 80, replace=True)
            data_b_oversampled = np.vstack([data_b, data_b[oversample_indices]])
            ax2.scatter(data_a[:, 0], data_a[:, 1], c='blue', label='Grupo A (n=100)', alpha=0.6)
            ax2.scatter(data_b_oversampled[:, 0], data_b_oversampled[:, 1], c='red', label='Grupo B (n=100)', alpha=0.6, marker='x')
            ax2.set_title("Datos con Sobremuestreo del Grupo B")
            ax2.legend()
            ax2.grid(True, linestyle='--', alpha=0.5)
            
            st.pyplot(fig)
            st.info("El gr√°fico de la derecha muestra c√≥mo se han a√±adido nuevas muestras (marcadas con 'x') del Grupo B para igualar en n√∫mero al Grupo A, lo que ayuda al modelo a aprender mejor sus patrones.")
        st.text_area("Criterios de Decisi√≥n: ¬øRe-ponderar o Re-muestrear?", placeholder="Basado en mi auditor√≠a y mi modelo, la mejor estrategia es...", key="p8")
        st.text_area("Consideraci√≥n de Interseccionalidad", placeholder="Ejemplo: Para abordar la subrepresentaci√≥n de mujeres de minor√≠as, aplicaremos un sobremuestreo estratificado que garantice que este subgrupo espec√≠fico alcance la paridad con otros.", key="p9")

    with tab5:
        st.subheader("Enfoques de Transformaci√≥n de Distribuci√≥n")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Esta t√©cnica modifica directamente los valores de las caracter√≠sticas para romper las correlaciones problem√°ticas con los atributos protegidos. Es como 'recalibrar' una variable para que signifique lo mismo para todos los grupos.")
        st.text_area("1. Eliminaci√≥n de Impacto Dispar", placeholder="Ej: 'Reparar' la caracter√≠stica 'c√≥digo postal' para que su distribuci√≥n sea la misma en todos los grupos raciales, eliminando su uso como proxy.", key="p10")
        st.text_area("2. Representaciones Justas (LFR, LAFTR)", placeholder="Ej: Usar un autoencoder adversario para aprender una representaci√≥n de los perfiles de los solicitantes que no contenga informaci√≥n de g√©nero.", key="p11")
        st.text_area("3. Consideraciones de Interseccionalidad", placeholder="Mi estrategia de transformaci√≥n se centrar√° en las intersecciones de g√©nero y etnia...", key="p12")

    with tab6:
        st.subheader("Generaci√≥n de Datos con Conciencia de Equidad")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Cuando los datos son muy escasos o sesgados, podemos generar datos sint√©ticos (artificiales) para llenar los vac√≠os. Esto es especialmente √∫til para crear ejemplos de grupos interseccionales muy peque√±os o para generar escenarios contrafactuales.")
        st.markdown("**¬øCu√°ndo Generar Datos?:** Cuando hay subrepresentaci√≥n severa o se necesitan ejemplos contrafactuales.")
        st.markdown("**Estrategias:** Generaci√≥n Condicional, Aumentaci√≥n Contrafactual.")
        st.text_area("Consideraciones de Interseccionalidad", placeholder="Ejemplo: Usaremos un modelo generativo condicionado en la intersecci√≥n de edad y g√©nero para crear perfiles sint√©ticos de 'mujeres mayores en tecnolog√≠a', un grupo ausente en nuestros datos.", key="p13")

    # --- Secci√≥n de Reporte ---
    st.markdown("---")
    st.header("Generar Reporte del Toolkit de Pre-procesamiento")
    if st.button("Generar Reporte de Pre-procesamiento", key="gen_preproc_report"):
        report_data = {
            "An√°lisis de Representaci√≥n": {
                "Comparaci√≥n con Poblaci√≥n de Referencia": st.session_state.p1,
                "An√°lisis Interseccional": st.session_state.p2,
                "Representaci√≥n en Resultados": st.session_state.p3,
            },
            "Detecci√≥n de Correlaci√≥n": {
                "Correlaciones Directas": st.session_state.p4,
                "Variables Proxy Identificadas": st.session_state.p5,
            },
            "Calidad de Etiquetas": {
                "Sesgo Hist√≥rico en Etiquetas": st.session_state.p6,
                "Sesgo del Anotador": st.session_state.p7,
            },
            "Re-ponderaci√≥n y Re-muestreo": {
                "Decisi√≥n y Raz√≥n": st.session_state.p8,
                "Plan Interseccional": st.session_state.p9,
            },
            "Transformaci√≥n de Distribuci√≥n": {
                "Plan de Eliminaci√≥n de Impacto Dispar": st.session_state.p10,
                "Plan de Representaciones Justas": st.session_state.p11,
                "Plan Interseccional": st.session_state.p12,
            },
            "Generaci√≥n de Datos": {
                "Plan de Generaci√≥n Interseccional": st.session_state.p13,
            }
        }
        
        report_md = "# Reporte del Toolkit de Equidad en Pre-procesamiento\n\n"
        for section, content in report_data.items():
            report_md += f"## {section}\n"
            for key, value in content.items():
                report_md += f"**{key}:**\n{value}\n\n"
        
        st.session_state.preproc_report_md = report_md
        st.success("¬°Reporte generado exitosamente!")

    if 'preproc_report_md' in st.session_state and st.session_state.preproc_report_md:
        st.subheader("Vista Previa del Reporte")
        st.markdown(st.session_state.preproc_report_md)
        st.download_button(
            label="Descargar Reporte de Pre-procesamiento",
            data=st.session_state.preproc_report_md,
            file_name="reporte_preprocesamiento.md",
            mime="text/markdown"
        )

def inprocessing_fairness_toolkit():
    st.header("‚öôÔ∏è Toolkit de Equidad en In-procesamiento")
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **In-procesamiento** implica modificar el algoritmo de aprendizaje del modelo para que la equidad sea uno de sus objetivos, junto con la precisi√≥n. Es como ense√±arle a un chef a cocinar no solo para que la comida sea deliciosa, sino tambi√©n para que sea nutricionalmente equilibrada, haciendo de la nutrici√≥n una parte central de la receta.
        """)
    
    tab1, tab2, tab3, tab4 = st.tabs(["Objetivos y Restricciones", "Debiasing Adversario", "Optimizaci√≥n Multiobjetivo", "Patrones de C√≥digo"])

    with tab1:
        st.subheader("Objetivos y Restricciones de Equidad")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Esto significa incorporar 'reglas de equidad' directamente en las matem√°ticas que el modelo utiliza para aprender. En lugar de solo buscar la respuesta m√°s precisa, el modelo tambi√©n debe asegurarse de no violar estas reglas.")
        
        st.markdown("**M√©todos Lagrangianos:**")
        with st.expander("üîç Definici√≥n y Ejemplo"):
            st.write("Es una t√©cnica matem√°tica para convertir una 'restricci√≥n dura' (una regla que no se puede romper) en una 'penalizaci√≥n suave'. Imagina que est√°s entrenando a un robot para que sea r√°pido, pero no puede pasar de cierta velocidad. En lugar de un l√≠mite estricto, le das una penalizaci√≥n cada vez que se acerca al l√≠mite. Esto lo anima a mantenerse dentro de los l√≠mites de una manera m√°s flexible.")
        st.latex(r''' \mathcal{L}(\theta, \lambda) = L(\theta) + \sum_{i=1}^{k} \lambda_i C_i(\theta) ''')
        st.text_area("Aplica a tu caso: ¬øQu√© restricci√≥n de equidad (ej. diferencia m√°xima de aprobaci√≥n) quieres implementar?", key="in_q1")

        st.markdown("**Viabilidad y Compensaciones:**")
        with st.expander("üîç Definici√≥n y Ejemplo"):
            st.write("No siempre es posible ser perfectamente justo y perfectamente preciso al mismo tiempo. A menudo, hay una 'compensaci√≥n' (trade-off). Mejorar la equidad puede reducir ligeramente la precisi√≥n general, y viceversa. Es crucial entender este equilibrio.")
            st.write("**Ejemplo de Interseccionalidad:** Forzar la igualdad de resultados para todos los subgrupos (ej. mujeres latinas, hombres asi√°ticos) puede ser matem√°ticamente imposible o requerir un sacrificio de precisi√≥n tan grande que el modelo deja de ser √∫til.")
        st.text_area("Aplica a tu caso: ¬øQu√© compensaci√≥n entre precisi√≥n y equidad est√°s dispuesto a aceptar?", key="in_q2")


    with tab2:
        st.subheader("Enfoques de Debiasing Adversario")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Imagina un juego entre dos IAs: un 'Predictor' que intenta hacer su trabajo (ej. evaluar curr√≠culums) y un 'Adversario' que intenta adivinar el atributo protegido (ej. el g√©nero del candidato) bas√°ndose en las decisiones del Predictor. El Predictor gana si hace buenas evaluaciones Y logra enga√±ar al Adversario. Con el tiempo, el Predictor aprende a tomar decisiones sin basarse en informaci√≥n relacionada con el g√©nero.")
        
        st.markdown("**Arquitectura:**")
        with st.expander("üí° Simulador de Arquitectura Adversaria"):
            st.graphviz_chart("""
            digraph {
                rankdir=LR;
                node [shape=box, style=rounded];
                "Datos de Entrada (X)" -> "Predictor";
                "Predictor" -> "Predicci√≥n (≈∂)";
                "Predictor" -> "Adversario" [label="Intenta enga√±ar"];
                "Adversario" -> "Predicci√≥n de Atributo Protegido (√Ç)";
                "Atributo Protegido (A)" -> "Adversario" [style=dashed, label="Compara para aprender"];
            }
            """)
        st.text_area("Aplica a tu caso: Describe la arquitectura que usar√≠as.", placeholder="Ej: Un predictor basado en BERT para analizar CVs y un adversario de 3 capas para predecir el g√©nero a partir de las representaciones internas.", key="in_q3")

        st.markdown("**Optimizaci√≥n:**")
        with st.expander("üîç Definici√≥n y Ejemplo"):
             st.write("El entrenamiento puede ser inestable porque el Predictor y el Adversario tienen objetivos opuestos. Se necesitan t√©cnicas especiales, como la 'inversi√≥n de gradiente', para que el Predictor aprenda a 'desaprender' el sesgo activamente.")
        st.text_area("Aplica a tu caso: ¬øQu√© desaf√≠os de optimizaci√≥n prev√©s y c√≥mo los abordar√≠as?", placeholder="Ej: El adversario podr√≠a volverse demasiado fuerte al principio. Usaremos un aumento gradual de su peso en la funci√≥n de p√©rdida.", key="in_q4")

    with tab3:
        st.subheader("Optimizaci√≥n Multiobjetivo para la Equidad")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("En lugar de combinar la precisi√≥n y la equidad en una sola meta, este enfoque las trata como dos objetivos separados que deben equilibrarse. El objetivo es encontrar un conjunto de 'soluciones √≥ptimas de Pareto', donde no se puede mejorar la equidad sin sacrificar algo de precisi√≥n, y viceversa.")
        with st.expander("üí° Ejemplo Interactivo: Frontera de Pareto"):
            st.write("Explora la **frontera de Pareto**, que visualiza la compensaci√≥n (trade-off) entre la precisi√≥n de un modelo y su equidad. No se puede mejorar uno sin empeorar el otro.")
            
            np.random.seed(10)
            accuracy = np.linspace(0.80, 0.95, 20)
            fairness_score = 1 - np.sqrt(accuracy - 0.79) + np.random.normal(0, 0.02, 20)
            fairness_score = np.clip(fairness_score, 0.5, 1.0)
            
            fig, ax = plt.subplots()
            ax.scatter(accuracy, fairness_score, c=accuracy, cmap='viridis', label='Modelos Posibles')
            ax.set_title("Frontera de Pareto: Equidad vs. Precisi√≥n")
            ax.set_xlabel("Precisi√≥n del Modelo")
            ax.set_ylabel("Puntuaci√≥n de Equidad")
            ax.grid(True, linestyle='--', alpha=0.6)
            st.pyplot(fig)
            st.info("Cada punto representa un modelo diferente. Los modelos en el borde superior derecho son '√≥ptimos'. La elecci√≥n de qu√© punto usar depende de las prioridades de tu proyecto.")
        st.text_area("Aplica a tu caso: ¬øCu√°les son los m√∫ltiples objetivos que necesitas equilibrar?", placeholder="Ej: 1. Maximizar la precisi√≥n en la predicci√≥n de impago. 2. Minimizar la diferencia en la tasa de aprobaci√≥n entre grupos demogr√°ficos. 3. Minimizar la diferencia en la tasa de falsos negativos.", key="in_q5")

    with tab4:
        st.subheader("Cat√°logo de Patrones de Implementaci√≥n")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Estos son fragmentos de c√≥digo o pseudoc√≥digo que muestran c√≥mo se ven en la pr√°ctica las t√©cnicas de in-procesamiento. Sirven como plantillas reutilizables para implementar la equidad en tu propio c√≥digo.")
        st.code("""
# Ejemplo de una funci√≥n de p√©rdida con regularizaci√≥n de equidad
def fairness_regularized_loss(original_loss, predictions, protected_attribute):
  # Calcula una penalizaci√≥n basada en la disparidad de las predicciones
  fairness_penalty = calculate_disparity(predictions, protected_attribute)
  
  # Combina la p√©rdida original con la penalizaci√≥n de equidad
  # lambda controla la importancia que se le da a la equidad
  return original_loss + lambda * fairness_penalty
        """, language="python")

    # --- Secci√≥n de Reporte ---
    st.markdown("---")
    st.header("Generar Reporte del Toolkit de In-procesamiento")
    if st.button("Generar Reporte de In-procesamiento", key="gen_inproc_report"):
        report_data = {
            "Objetivos y Restricciones": {
                "Restricci√≥n de Equidad": st.session_state.in_q1,
                "An√°lisis de Compensaciones": st.session_state.in_q2,
            },
            "Debiasing Adversario": {
                "Descripci√≥n de la Arquitectura": st.session_state.in_q3,
                "Plan de Optimizaci√≥n": st.session_state.in_q4,
            },
            "Optimizaci√≥n Multiobjetivo": {
                "Objetivos a Equilibrar": st.session_state.in_q5,
            }
        }
        
        report_md = "# Reporte del Toolkit de Equidad en In-procesamiento\n\n"
        for section, content in report_data.items():
            report_md += f"## {section}\n"
            for key, value in content.items():
                report_md += f"**{key}:**\n{value}\n\n"
        
        st.session_state.inproc_report_md = report_md
        st.success("¬°Reporte generado exitosamente!")

    if 'inproc_report_md' in st.session_state and st.session_state.inproc_report_md:
        st.subheader("Vista Previa del Reporte")
        st.markdown(st.session_state.inproc_report_md)
        st.download_button(
            label="Descargar Reporte de In-procesamiento",
            data=st.session_state.inproc_report_md,
            file_name="reporte_inprocesamiento.md",
            mime="text/markdown"
        )

def postprocessing_fairness_toolkit():
    st.header("üìä Toolkit de Equidad en Post-procesamiento")
    with st.expander("üîç Definici√≥n Amigable"):
        st.write("""
        El **Post-procesamiento** consiste en ajustar las predicciones de un modelo *despu√©s* de que ya ha sido entrenado. Es como un editor que revisa un texto ya escrito para corregir sesgos o errores. El modelo original no cambia, solo se ajusta su resultado final para que sea m√°s justo.
        """)
    
    tab1, tab2, tab3, tab4 = st.tabs(["Optimizaci√≥n de Umbrales", "Calibraci√≥n", "Transformaci√≥n de Predicci√≥n", "Clasificaci√≥n con Rechazo"])

    with tab1:
        st.subheader("T√©cnicas de Optimizaci√≥n de Umbrales")
        with st.expander("üí° Ejemplo Interactivo"):
             run_threshold_simulation()
        st.info("Ajusta los umbrales de clasificaci√≥n despu√©s del entrenamiento para satisfacer definiciones de equidad espec√≠ficas.")
        st.text_area("Aplica a tu caso: ¬øQu√© criterio de equidad usar√°s y c√≥mo planeas analizar las compensaciones?", placeholder="1. Criterio: Igualdad de Oportunidades.\n2. C√°lculo: Encontraremos umbrales que igualen la TPR en un set de validaci√≥n.\n3. Despliegue: Usaremos un proxy del grupo demogr√°fico ya que no podemos usar el atributo protegido en producci√≥n.", key="po_q1")

    with tab2:
        st.subheader("Gu√≠a Pr√°ctica de Calibraci√≥n para la Equidad")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("La **calibraci√≥n** asegura que una predicci√≥n de '80% de probabilidad' signifique lo mismo para todos los grupos demogr√°ficos. Si para un grupo significa un 95% de probabilidad real y para otro un 70%, el modelo est√° mal calibrado y es injusto.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de Calibraci√≥n"):
            run_calibration_simulation()
        
        with st.expander("Definici√≥n: Platt Scaling y Regresi√≥n Isot√≥nica"):
            st.write("**Platt Scaling:** Es una t√©cnica simple que usa un modelo log√≠stico para 'reajustar' las puntuaciones de tu modelo y convertirlas en probabilidades bien calibradas. Es como aplicar una curva de correcci√≥n suave.")
            st.write("**Regresi√≥n Isot√≥nica:** Es un m√©todo m√°s flexible y no param√©trico que ajusta las puntuaciones a trav√©s de una funci√≥n escalonada. Es potente pero puede sobreajustarse si no se tiene suficientes datos.")
        st.text_area("Aplica a tu caso: ¬øC√≥mo evaluar√°s y corregir√°s la calibraci√≥n?", placeholder="1. Evaluaci√≥n: Usaremos diagramas de fiabilidad y la m√©trica ECE por grupo.\n2. M√©todo: Probaremos con Platt Scaling por grupo, ya que es robusto y f√°cil de implementar.", key="po_q2")

    with tab3:
        st.subheader("M√©todos de Transformaci√≥n de Predicci√≥n")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("Estas son t√©cnicas m√°s avanzadas que la simple optimizaci√≥n de umbrales. Modifican las puntuaciones del modelo de formas m√°s complejas para cumplir con criterios de equidad, especialmente cuando no se puede re-entrenar el modelo.")
        
        with st.expander("Definici√≥n: Funciones de Transformaci√≥n Aprendidas"):
            st.write("En lugar de un ajuste simple, se 'aprende' una funci√≥n matem√°tica √≥ptima que transforma las puntuaciones sesgadas en puntuaciones justas, minimizando la p√©rdida de informaci√≥n √∫til.")
        with st.expander("Definici√≥n: Alineaci√≥n de Distribuci√≥n"):
            st.write("Asegura que la distribuci√≥n de las puntuaciones (el 'histograma' de las predicciones) sea similar para todos los grupos demogr√°ficos. Esto es √∫til para lograr la paridad estad√≠stica.")
        with st.expander("Definici√≥n: Transformaciones de Puntuaci√≥n Justas"):
            st.write("Modifica las puntuaciones para cumplir con la equidad, pero con una regla importante: el orden relativo de los individuos dentro de un mismo grupo debe mantenerse. Si la persona A era mejor que B en un grupo, debe seguir si√©ndolo despu√©s de la transformaci√≥n.")
        
        st.text_area("Aplica a tu caso: ¬øQu√© m√©todo de transformaci√≥n es m√°s adecuado y por qu√©?", placeholder="Ejemplo: Usaremos alineaci√≥n de distribuci√≥n mediante mapeo de cuantiles para asegurar que las distribuciones de riesgo de cr√©dito sean comparables entre grupos, ya que nuestro objetivo es la paridad demogr√°fica.", key="po_q3")

    with tab4:
        st.subheader("Clasificaci√≥n con Opci√≥n de Rechazo")
        with st.expander("üîç Definici√≥n Amigable"):
            st.write("En lugar de forzar al modelo a tomar una decisi√≥n en casos dif√≠ciles o ambiguos (donde es m√°s probable que cometa errores injustos), esta t√©cnica identifica esos casos y los 'rechaza', envi√°ndolos a un experto humano para que tome la decisi√≥n final.")
        with st.expander("üí° Ejemplo Interactivo: Simulaci√≥n de Rechazo"):
            run_rejection_simulation()
            
        with st.expander("Definici√≥n: Umbrales de rechazo basados en confianza"):
            st.write("Se definen 'zonas de confianza'. Si la probabilidad predicha por el modelo es muy alta (ej. >90%) o muy baja (ej. <10%), la decisi√≥n se automatiza. Si cae en el medio, se rechaza para revisi√≥n humana.")
        with st.expander("Definici√≥n: Clasificaci√≥n selectiva"):
            st.write("Es el marco formal para decidir qu√© porcentaje de casos automatizar. Permite optimizar el equilibrio entre la 'cobertura' (cu√°ntos casos se deciden autom√°ticamente) y la equidad.")
        with st.expander("Definici√≥n: Modelos de colaboraci√≥n Humano-IA"):
            st.write("No basta con rechazar un caso. Es crucial dise√±ar c√≥mo se presenta la informaci√≥n al humano para no introducir nuevos sesgos. El objetivo es una colaboraci√≥n donde la IA y el humano juntos tomen decisiones m√°s justas que por separado.")
        
        st.text_area("Aplica a tu caso: ¬øC√≥mo dise√±ar√≠as un sistema de rechazo?", placeholder="Ejemplo: Rechazaremos las solicitudes de pr√©stamo con probabilidades entre 40% y 60% para revisi√≥n manual. La interfaz para el revisor mostrar√° los datos clave sin revelar el grupo demogr√°fico para evitar sesgos humanos.", key="po_q4")

    # --- Secci√≥n de Reporte ---
    st.markdown("---")
    st.header("Generar Reporte del Toolkit de Post-procesamiento")
    if st.button("Generar Reporte de Post-procesamiento", key="gen_postproc_report"):
        report_data = {
            "Optimizaci√≥n de Umbrales": {"Plan de Implementaci√≥n": st.session_state.po_q1},
            "Calibraci√≥n": {"Plan de Calibraci√≥n": st.session_state.po_q2},
            "Transformaci√≥n de Predicci√≥n": {"M√©todo de Transformaci√≥n Seleccionado": st.session_state.po_q3},
            "Clasificaci√≥n con Rechazo": {"Dise√±o del Sistema de Rechazo": st.session_state.po_q4}
        }
        
        report_md = "# Reporte del Toolkit de Equidad en Post-procesamiento\n\n"
        for section, content in report_data.items():
            report_md += f"## {section}\n"
            for key, value in content.items():
                report_md += f"**{key}:**\n{value}\n\n"
        
        st.session_state.postproc_report_md = report_md
        st.success("¬°Reporte generado exitosamente!")

    if 'postproc_report_md' in st.session_state and st.session_state.postproc_report_md:
        st.subheader("Vista Previa del Reporte")
        st.markdown(st.session_state.postproc_report_md)
        st.download_button(
            label="Descargar Reporte de Post-procesamiento",
            data=st.session_state.postproc_report_md,
            file_name="reporte_postprocesamiento.md",
            mime="text/markdown"
        )


def intervention_playbook():
    st.sidebar.title("Navegaci√≥n del Playbook de Intervenci√≥n")
    selection = st.sidebar.radio(
        "Ir a:",
        ["Playbook Principal", "Toolkit Causal", "Toolkit de Pre-procesamiento", "Toolkit de In-procesamiento", "Toolkit de Post-procesamiento"],
        key="intervention_nav"
    )
    
    if selection == "Playbook Principal":
        st.header("üìñ Playbook de Intervenci√≥n de Equidad")
        st.info("Este playbook integra los cuatro toolkits en un flujo de trabajo cohesivo, guiando a los desarrolladores desde la identificaci√≥n del sesgo hasta la implementaci√≥n de soluciones efectivas.")
        with st.expander("Gu√≠a de Implementaci√≥n"):
            st.write("Explica c√≥mo usar el playbook, con comentarios sobre puntos de decisi√≥n clave, evidencia de apoyo y riesgos identificados.")
        with st.expander("Estudio de Caso"):
            st.write("Demuestra la aplicaci√≥n del playbook a un problema de equidad t√≠pico, mostrando c√≥mo los resultados de cada componente informan al siguiente.")
        with st.expander("Marco de Validaci√≥n"):
            st.write("Proporciona orientaci√≥n sobre c√≥mo los equipos de implementaci√≥n pueden verificar la efectividad de su proceso de auditor√≠a.")
        with st.expander("Equidad Interseccional"):
            st.write("Consideraci√≥n expl√≠cita de la equidad interseccional en cada componente del playbook.")
    elif selection == "Toolkit Causal":
        causal_fairness_toolkit()
    elif selection == "Toolkit de Pre-procesamiento":
        preprocessing_fairness_toolkit()
    elif selection == "Toolkit de In-procesamiento":
        inprocessing_fairness_toolkit()
    elif selection == "Toolkit de Post-procesamiento":
        postprocessing_fairness_toolkit()

#======================================================================
# --- FAIRNESS AUDIT PLAYBOOK ---
#======================================================================

def audit_playbook():
    st.sidebar.title("Navegaci√≥n del Playbook de Auditor√≠a")
    page = st.sidebar.radio("Ir a", [
        "C√≥mo Navegar este Playbook",
        "Evaluaci√≥n del Contexto Hist√≥rico",
        "Selecci√≥n de Definici√≥n de Equidad",
        "Identificaci√≥n de Fuentes de Sesgo",
        "M√©tricas Comprensivas de Equidad"
    ], key="audit_nav")

    if page == "C√≥mo Navegar este Playbook":
        st.header("C√≥mo Navegar Este Playbook")
        # ... (Contenido original) ...
    elif page == "Evaluaci√≥n del Contexto Hist√≥rico":
        st.header("Herramienta de Evaluaci√≥n del Contexto Hist√≥rico")
        # ... (Contenido original) ...
    elif page == "Selecci√≥n de Definici√≥n de Equidad":
        st.header("Herramienta de Selecci√≥n de Definici√≥n de Equidad")
        # ... (Contenido original) ...
    elif page == "Identificaci√≥n de Fuentes de Sesgo":
        st.header("Herramienta de Identificaci√≥n de Fuentes de Sesgo")
        # ... (Contenido de esta secci√≥n) ...
    elif page == "M√©tricas Comprensivas de Equidad":
        st.header("M√©tricas Comprensivas de Equidad (CFM)")
        # ... (Contenido de esta secci√≥n) ...


# --- NAVEGACI√ìN PRINCIPAL ---
st.sidebar.title("Selecci√≥n de Playbook")
playbook_choice = st.sidebar.selectbox(
    "Elige el playbook que quieres usar:",
    ["Fairness Audit Playbook", "Fairness Intervention Playbook"]
)

st.title(playbook_choice)

if playbook_choice == "Fairness Audit Playbook":
    audit_playbook() 
else:
    intervention_playbook()
