<<<<<<< HEAD
import streamlit as st
import json

# --- Configuraci√≥n de la P√°gina ---
st.set_page_config(
    page_title="AI Fairness Playbooks",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

#======================================================================
# --- FAIRNESS INTERVENTION PLAYBOOK ---
#======================================================================

def causal_fairness_toolkit():
    st.header("üõ°Ô∏è Toolkit de Equidad Causal")
    
    tab1, tab2, tab3, tab4 = st.tabs(["Identificaci√≥n", "An√°lisis Contrafactual", "Diagrama Causal", "Inferencia Causal"])

    with tab1:
        st.subheader("Marco de Identificaci√≥n de Mecanismos de Discriminaci√≥n")
        st.info("Identifica las posibles causas ra√≠z del sesgo en tu aplicaci√≥n.")
        st.text_area("1. Discriminaci√≥n Directa: ¬øEl atributo protegido influye directamente en la decisi√≥n?", placeholder="Ej: ¬øSe utiliza expl√≠citamente el 'g√©nero' como una caracter√≠stica en el modelo?", key="c1")
        st.text_area("2. Discriminaci√≥n Indirecta: ¬øEl atributo protegido afecta a factores intermedios leg√≠timos?", placeholder="Ej: ¬øEl 'g√©nero' afecta a los 'a√±os de experiencia' debido a pausas en la carrera?", key="c2")
        st.text_area("3. Discriminaci√≥n por Proxy: ¬øLas decisiones dependen de variables correlacionadas con atributos protegidos?", placeholder="Ej: ¬øEl 'c√≥digo postal' se correlaciona con la 'raza' y se utiliza para predecir el riesgo?", key="c3")

    with tab2:
        st.subheader("Metodolog√≠a Pr√°ctica de Equidad Contrafactual")
        st.info("Analiza, cuantifica y mitiga el sesgo contrafactual en tu modelo.")
        with st.container(border=True):
            st.markdown("##### Paso 1: An√°lisis de Equidad Contrafactual")
            st.text_area("1.1 Formular Consultas Contrafactuales", placeholder="Ej: Para un solicitante rechazado, ¬øcu√°l habr√≠a sido el resultado si su raza fuera diferente, manteniendo constantes los ingresos?", key="c4")
            st.text_area("1.2 Identificar Rutas Causales (Justas vs. Injustas)", placeholder="Ej: La ruta Raza -> C√≥digo Postal -> Decisi√≥n es injusta.", key="c5")
            st.text_area("1.3 Medir Disparidades y Documentar", placeholder="Ej: El 15% de los solicitantes del grupo desfavorecido habr√≠an sido aprobados en el escenario contrafactual.", key="c6")
        with st.container(border=True):
            st.markdown("##### Paso 2: An√°lisis Espec√≠fico de Rutas")
            st.text_area("2.1 Descomponer y Clasificar Rutas", placeholder="Ej: Ruta 1 (proxy de c√≥digo postal) clasificada como INJUSTA.", key="c7")
            st.text_area("2.2 Cuantificar Contribuci√≥n y Documentar", placeholder="Ej: La ruta del c√≥digo postal representa el 60% de la disparidad observada.", key="c8")
        with st.container(border=True):
            st.markdown("##### Paso 3: Dise√±o de Intervenci√≥n")
            st.selectbox("3.1 Seleccionar Enfoque de Intervenci√≥n", ["Nivel de Datos", "Nivel de Modelo", "Post-procesamiento"], key="c9")
            st.text_area("3.2 Implementar y Monitorear", placeholder="Ej: Se aplic√≥ una transformaci√≥n a la caracter√≠stica de c√≥digo postal. La disparidad se redujo en un 50%.", key="c10")

    with tab3:
        st.subheader("Enfoque de Diagrama Causal Inicial")
        st.info("Esboza diagramas para visualizar las relaciones causales y documentar tus supuestos.")
        st.markdown("""
        **Convenciones de Anotaci√≥n:**
        - **Nodos (variables):** Atributos Protegidos, Caracter√≠sticas, Resultados.
        - **Flechas Causales (‚Üí):** Relaci√≥n causal asumida.
        - **Flechas de Correlaci√≥n (<-->):** Correlaci√≥n sin causalidad directa conocida.
        - **Incertidumbre (?):** Relaci√≥n causal hipot√©tica o d√©bil.
        - **Ruta Problem√°tica (!):** Ruta que consideras una fuente de inequidad.
        """)
        st.text_area("Documentaci√≥n de Supuestos y Rutas", placeholder="Ruta (!): Raza -> Nivel de Ingresos -> Decisi√≥n.\nSupuesto: Las disparidades hist√≥ricas de ingresos vinculadas a la raza afectan la capacidad de pr√©stamo.", height=200, key="c11")

    with tab4:
        st.subheader("Inferencia Causal con Datos Limitados")
        st.info("M√©todos pr√°cticos para estimar efectos causales cuando los datos son imperfectos.")
        st.markdown("""
        **M√©todos de Inferencia Observacional:**
        - **Matching (Emparejamiento):** Compara individuos similares de diferentes grupos.
        - **Variables Instrumentales (IV):** Usa una variable externa para aislar el efecto causal.
        - **Regresi√≥n por Discontinuidad:** Aprovecha umbrales naturales en los datos.
        - **Diferencia en Diferencias:** Compara cambios en el tiempo entre grupos.
        """)
        st.text_area("An√°lisis de Sensibilidad", placeholder="¬øQu√© tan fuerte tendr√≠a que ser una variable de confusi√≥n no medida para anular el efecto de sesgo que has encontrado?", key="c12")

def preprocessing_fairness_toolkit():
    st.header("üß™ Toolkit de Equidad en Pre-procesamiento")
    
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["An√°lisis de Representaci√≥n", "Detecci√≥n de Correlaci√≥n", "Calidad de Etiquetas", "Re-ponderaci√≥n y Re-muestreo", "Transformaci√≥n", "Generaci√≥n de Datos"])

    with tab1:
        st.subheader("An√°lisis de Representaci√≥n Multidimensional")
        st.info("Examina las distribuciones demogr√°ficas para identificar brechas de representaci√≥n.")
        st.text_area("1. Comparaci√≥n con Poblaci√≥n de Referencia", placeholder="Ej: Nuestro conjunto de datos tiene un 20% de mujeres en roles t√©cnicos, mientras que el mercado laboral es del 35%.", key="p1")
        st.text_area("2. An√°lisis de Representaci√≥n Interseccional", placeholder="Ej: Las mujeres de minor√≠as raciales constituyen solo el 3% de los datos.", key="p2")
        st.text_area("3. Representaci√≥n a trav√©s de Categor√≠as de Resultados", placeholder="Ej: El grupo A constituye el 30% de las solicitudes pero solo el 10% de las aprobadas.", key="p3")

    with tab2:
        st.subheader("Detecci√≥n de Patrones de Correlaci√≥n")
        st.info("Identifica asociaciones problem√°ticas que podr√≠an permitir la discriminaci√≥n por proxy.")
        st.text_area("1. Correlaciones Directas (Atributo Protegido ‚Üî Resultado)", placeholder="Ej: El g√©nero tiene una correlaci√≥n de 0.3 con la decisi√≥n de contrataci√≥n.", key="p4")
        st.text_area("2. Identificaci√≥n de Variables Proxy (Atributo Protegido ‚Üî Caracter√≠stica)", placeholder="Ej: La caracter√≠stica 'asistencia a un club de ajedrez' est√° altamente correlacionada con el g√©nero masculino.", key="p5")

    with tab3:
        st.subheader("Evaluaci√≥n de la Calidad de las Etiquetas")
        st.info("Eval√∫a los sesgos potenciales en las etiquetas de entrenamiento.")
        st.text_area("1. Sesgo Hist√≥rico en las Decisiones", placeholder="Ej: Las etiquetas de 'promocionado' provienen de un per√≠odo con pol√≠ticas de promoci√≥n sesgadas.", key="p6")
        st.text_area("2. Sesgo del Anotador", placeholder="Ej: Los anotadores masculinos calificaron los mismos comentarios como 't√≥xicos' con menos frecuencia que las anotadoras femeninas.", key="p7")
    
    with tab4:
        st.subheader("T√©cnicas de Re-ponderaci√≥n y Re-muestreo")
        st.info("Aborda las disparidades de representaci√≥n ajustando la influencia de las instancias de entrenamiento.")
        st.markdown("**Re-ponderaci√≥n:** Asigna pesos a las muestras para dar m√°s importancia a los grupos subrepresentados.")
        st.markdown("**Re-muestreo:** Modifica f√≠sicamente el conjunto de datos (sobre-muestreo o sub-muestreo).")
        st.text_area("Criterios de Decisi√≥n: ¬øRe-ponderar o Re-muestrear?", placeholder="Basado en mi auditor√≠a y mi modelo, la mejor estrategia es...", key="p8")
        st.text_area("Consideraci√≥n de Interseccionalidad", placeholder="Mi plan para la interseccionalidad es...", key="p9")

    with tab5:
        st.subheader("Enfoques de Transformaci√≥n de Distribuci√≥n")
        st.info("Modifica el espacio de caracter√≠sticas para mitigar el sesgo.")
        st.text_area("1. Eliminaci√≥n de Impacto Dispar", placeholder="Ej: 'Reparar' la caracter√≠stica 'c√≥digo postal' para que su distribuci√≥n sea la misma en todos los grupos raciales.", key="p10")
        st.text_area("2. Representaciones Justas (LFR, LAFTR)", placeholder="Ej: Usar un autoencoder adversario para aprender una representaci√≥n que no contenga informaci√≥n de g√©nero.", key="p11")
        st.text_area("3. Consideraciones de Interseccionalidad", placeholder="Mi estrategia de transformaci√≥n se centrar√° en las intersecciones de g√©nero y etnia...", key="p12")

    with tab6:
        st.subheader("Generaci√≥n de Datos con Conciencia de Equidad")
        st.info("Crea datos sint√©ticos para mitigar patrones de sesgo.")
        st.markdown("**¬øCu√°ndo Generar Datos?:** Cuando hay subrepresentaci√≥n severa o se necesitan ejemplos contrafactuales.")
        st.markdown("**Estrategias:** Generaci√≥n Condicional, Aumentaci√≥n Contrafactual.")
        st.text_area("Consideraciones de Interseccionalidad", placeholder="Mi modelo generativo ser√° condicionado en la intersecci√≥n de edad y g√©nero para...", key="p13")

def inprocessing_fairness_toolkit():
    st.header("‚öôÔ∏è Toolkit de Equidad en In-procesamiento")
    
    tab1, tab2, tab3, tab4 = st.tabs(["Objetivos y Restricciones", "Debiasing Adversario", "Optimizaci√≥n Multiobjetivo", "Patrones de C√≥digo"])

    with tab1:
        st.subheader("Objetivos y Restricciones de Equidad")
        st.info("Incorpora la equidad directamente en la optimizaci√≥n del modelo.")
        st.markdown("**M√©todos Lagrangianos:** Transforma restricciones duras en penalizaciones suaves en la funci√≥n de p√©rdida.")
        st.latex(r''' \mathcal{L}(\theta, \lambda) = L(\theta) + \sum_{i=1}^{k} \lambda_i C_i(\theta) ''')
        st.markdown("**Viabilidad y Compensaciones:** Entiende la tensi√≥n entre equidad y rendimiento.")
        st.markdown("**Interseccionalidad:** Las restricciones deben considerar combinaciones de atributos.")

    with tab2:
        st.subheader("Enfoques de Debiasing Adversario")
        st.info("Usa aprendizaje adversario para que los modelos 'desaprendan' patrones discriminatorios.")
        st.markdown("**Arquitectura:** Un **Predictor** compite contra un **Adversario**. El predictor aprende a enga√±ar al adversario, creando representaciones sin informaci√≥n del atributo protegido.")
        st.markdown("**Optimizaci√≥n:** El entrenamiento puede ser inestable. Requiere equilibrio de componentes, inversi√≥n de gradiente y entrenamiento progresivo.")
    
    with tab3:
        st.subheader("Optimizaci√≥n Multiobjetivo para la Equidad")
        st.info("Navega sistem√°ticamente las tensiones entre equidad y rendimiento.")
        st.markdown("**Optimalidad de Pareto:** Identifica soluciones donde no se puede mejorar un objetivo sin degradar otro (la 'frontera de Pareto').")
        st.markdown("**M√©todos de Escalarizaci√≥n:** Combina objetivos en una sola funci√≥n ponderada para explorar la frontera de Pareto.")
        st.text_area("An√°lisis y Definici√≥n de Objetivos", placeholder="Define tus m√©tricas de rendimiento y criterios de equidad aqu√≠.", key="i1")

    with tab4:
        st.subheader("Cat√°logo de Patrones de Implementaci√≥n")
        st.code("""
def fairness_regularized_loss(original_loss, predictions, protected_attribute):
  fairness_penalty = calculate_disparity(predictions, protected_attribute)
  return original_loss + lambda * fairness_penalty
        """, language="python")

def postprocessing_fairness_toolkit():
    st.header("üìä Toolkit de Equidad en Post-procesamiento")
    
    tab1, tab2, tab3, tab4 = st.tabs(["Optimizaci√≥n de Umbrales", "Calibraci√≥n", "Transformaci√≥n de Predicci√≥n", "Clasificaci√≥n con Rechazo"])

    with tab1:
        st.subheader("T√©cnicas de Optimizaci√≥n de Umbrales")
        st.info("Ajusta los umbrales de clasificaci√≥n despu√©s del entrenamiento para satisfacer definiciones de equidad espec√≠ficas.")
        st.markdown("**Fundamentos:** El ajuste de umbrales espec√≠ficos por grupo influye directamente en las tasas de error y, por lo tanto, en las m√©tricas de equidad.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Seleccionar Criterio de Equidad (ej. igualdad de oportunidades)\n2. Calcular Umbrales en datos de validaci√≥n\n3. Analizar Compensaciones y Desplegar", key="po1")

    with tab2:
        st.subheader("Gu√≠a Pr√°ctica de Calibraci√≥n para la Equidad")
        st.info("Garantiza que las probabilidades predichas tengan un significado consistente en todos los grupos.")
        st.markdown("**Fundamentos:** Una mala calibraci√≥n significa que la misma puntuaci√≥n de riesgo representa diferentes niveles de riesgo real para diferentes grupos.")
        st.markdown("**T√©cnicas:** Platt Scaling, Regresi√≥n Isot√≥nica.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Evaluar Calibraci√≥n (con ECE, MCE)\n2. Seleccionar M√©todo\n3. Implementar y Validar", key="po2")

    with tab3:
        st.subheader("M√©todos de Transformaci√≥n de Predicci√≥n")
        st.info("Modifica las salidas del modelo para satisfacer restricciones de equidad complejas.")
        st.markdown("**Conceptos Clave:** Funciones de Transformaci√≥n Aprendidas, Alineaci√≥n de Distribuci√≥n, Transformaciones de Puntuaci√≥n Justas.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Dise√±ar Transformaci√≥n\n2. Aprender y Evaluar\n3. Considerar Interseccionalidad", key="po3")

    with tab4:
        st.subheader("Clasificaci√≥n con Opci√≥n de Rechazo")
        st.info("Identifica predicciones inciertas y las difiere a juicio humano.")
        st.markdown("**Fundamentos:** Umbrales de rechazo basados en confianza, clasificaci√≥n selectiva, modelos de colaboraci√≥n Humano-IA.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Estimar Confianza\n2. Optimizar Umbral de Rechazo\n3. Dise√±ar Flujo de Trabajo Humano-IA", key="po4")

def intervention_playbook():
    st.sidebar.title("Navegaci√≥n del Playbook de Intervenci√≥n")
    selection = st.sidebar.radio(
        "Ir a:",
        ["Playbook Principal", "Toolkit Causal", "Toolkit de Pre-procesamiento", "Toolkit de In-procesamiento", "Toolkit de Post-procesamiento"],
        key="intervention_nav"
    )
    
    if selection == "Playbook Principal":
        st.header("üìñ Playbook de Intervenci√≥n de Equidad")
        st.info("Este playbook integra los cuatro toolkits en un flujo de trabajo cohesivo, guiando a los desarrolladores desde la identificaci√≥n del sesgo hasta la implementaci√≥n de soluciones efectivas.")
        with st.expander("Gu√≠a de Implementaci√≥n"):
            st.write("Explica c√≥mo usar el playbook, con comentarios sobre puntos de decisi√≥n clave, evidencia de apoyo y riesgos identificados.")
        with st.expander("Estudio de Caso"):
            st.write("Demuestra la aplicaci√≥n del playbook a un problema de equidad t√≠pico, mostrando c√≥mo los resultados de cada componente informan al siguiente.")
        with st.expander("Marco de Validaci√≥n"):
            st.write("Proporciona orientaci√≥n sobre c√≥mo los equipos de implementaci√≥n pueden verificar la efectividad de su proceso de auditor√≠a.")
        with st.expander("Equidad Interseccional"):
            st.write("Consideraci√≥n expl√≠cita de la equidad interseccional en cada componente del playbook.")
    elif selection == "Toolkit Causal":
        causal_fairness_toolkit()
    elif selection == "Toolkit de Pre-procesamiento":
        preprocessing_fairness_toolkit()
    elif selection == "Toolkit de In-procesamiento":
        inprocessing_fairness_toolkit()
    elif selection == "Toolkit de Post-procesamiento":
        postprocessing_fairness_toolkit()

#======================================================================
# --- FAIRNESS AUDIT PLAYBOOK ---
#======================================================================

def audit_playbook():
    st.sidebar.title("Navegaci√≥n del Playbook de Auditor√≠a")
    page = st.sidebar.radio("Ir a", [
        "C√≥mo Navegar este Playbook",
        "Evaluaci√≥n del Contexto Hist√≥rico",
        "Selecci√≥n de Definici√≥n de Equidad",
        "Identificaci√≥n de Fuentes de Sesgo",
        "M√©tricas Comprensivas de Equidad"
    ], key="audit_nav")

    if page == "C√≥mo Navegar este Playbook":
        st.header("C√≥mo Navegar Este Playbook")
        st.markdown("""
        **El Marco de Cuatro Componentes** ‚Äì Sigue secuencialmente a trav√©s de:
        
        1. **Evaluaci√≥n del Contexto Hist√≥rico (HCA)** ‚Äì Descubre sesgos sist√©micos y desequilibrios de poder en tu dominio.
        
        2. **Selecci√≥n de Definici√≥n de Equidad (FDS)**
         ‚Äì Elige las definiciones de equidad apropiadas basadas en tu contexto y objetivos.
        
        3. **Identificaci√≥n de Fuentes de Sesgo (BSI)** ‚Äì Identifica y prioriza las formas en que el sesgo puede entrar en tu sistema.
        
        4. **M√©tricas Comprensivas de Equidad (CFM)**
         ‚Äì Implementa m√©tricas cuantitativas para el monitoreo y la presentaci√≥n de informes.

        **Consejos:**
        - Avanza por las secciones en orden, pero si√©ntete libre de retroceder si surgen nuevas ideas.
        - Usa los botones de **Guardar Resumen** en cada herramienta para registrar tus hallazgos.
        - Consulta los ejemplos incrustados en cada secci√≥n para ver c√≥mo otros han aplicado estas herramientas.
        """)
    elif page == "Evaluaci√≥n del Contexto Hist√≥rico":
        st.header("Herramienta de Evaluaci√≥n del Contexto Hist√≥rico")
        st.subheader("1. Cuestionario Estructurado")
        st.markdown("Esta secci√≥n te ayuda a descubrir patrones relevantes de discriminaci√≥n hist√≥rica.")
        
        q1 = st.text_area("¬øEn qu√© dominio espec√≠fico operar√° este sistema (ej. pr√©stamos, contrataci√≥n, salud)?")
        q2 = st.text_area("¬øCu√°l es la funci√≥n espec√≠fica del sistema o caso de uso dentro de ese dominio?")
        q3 = st.text_area("¬øCu√°les son los patrones de discriminaci√≥n hist√≥rica documentados en este dominio?")
        q4 = st.text_area("¬øQu√© fuentes de datos hist√≥ricos se utilizan o se referencian en este sistema?")
        q5 = st.text_area("¬øC√≥mo se definieron hist√≥ricamente las categor√≠as clave (ej. g√©nero, riesgo crediticio) y han evolucionado?")
        q6 = st.text_area("¬øC√≥mo se midieron hist√≥ricamente las variables (ej. ingresos, educaci√≥n)? ¬øPodr√≠an codificar sesgos?")
        q7 = st.text_area("¬øHan servido otras tecnolog√≠as para roles similares en este dominio? ¬øDesafiaron o reforzaron las desigualdades?")
        q8 = st.text_area("¬øC√≥mo podr√≠a la automatizaci√≥n amplificar los sesgos pasados o introducir nuevos riesgos en este dominio?")

        st.subheader("2. Matriz de Clasificaci√≥n de Riesgos")
        st.markdown("""
        Para cada patr√≥n hist√≥rico identificado, estima:
        - **Severidad**: Alto = impacta derechos/resultados de vida, Medio = afecta oportunidades/acceso a recursos, Bajo = impacto material limitado.
        - **Probabilidad**: Alta = probable que aparezca en sistemas similares, Media = posible, Baja = raro.
        - **Relevancia**: Alta = directamente relacionado con tu sistema, Media = afecta partes, Baja = perif√©rico.
        """)
        matrix = st.text_area("Matriz de Clasificaci√≥n de Riesgos (tabla Markdown)", height=200, placeholder="| Patr√≥n | Severidad | Probabilidad | Relevancia | Puntuaci√≥n (S√óP√óR) | Prioridad |\n|---|---|---|---|---|---|")

        if st.button("Guardar Resumen HCA"):
            summary = {
                "Cuestionario Estructurado": {
                    "Dominio": q1, "Funci√≥n": q2, "Patrones Hist√≥ricos": q3, "Fuentes de Datos": q4,
                    "Definiciones de Categor√≠a": q5, "Riesgos de Medici√≥n": q6, "Sistemas Anteriores": q7, "Riesgos de Automatizaci√≥n": q8
                },
                "Matriz de Riesgos": matrix
            }
            summary_md = "# Resumen de Evaluaci√≥n del Contexto Hist√≥rico\n"
            for section, answers in summary.items():
                summary_md += f"## {section}\n"
                if isinstance(answers, dict):
                    for k, v in answers.items():
                        summary_md += f"**{k}:** {v}\n\n"
                else:
                    summary_md += f"{answers}\n"
            
            st.subheader("Vista Previa del Resumen HCA")
            st.markdown(summary_md)
            st.download_button("Descargar Resumen HCA", summary_md, "HCA_summary.md", "text/markdown")
            st.success("Resumen de Evaluaci√≥n del Contexto Hist√≥rico guardado.")

    elif page == "Selecci√≥n de Definici√≥n de Equidad":
        st.header("Herramienta de Selecci√≥n de Definici√≥n de Equidad")
        st.subheader("1. Cat√°logo de Definiciones de Equidad")
        st.markdown("""
        | Definici√≥n | F√≥rmula | Cu√°ndo Usar | Ejemplo |
        |---|---|---|---|
        | Paridad Demogr√°fica | P(≈∂=1|A=a) = P(≈∂=1|A=b) | Asegurar tasas de positivos iguales entre grupos. | Anuncios de universidad mostrados por igual a todos los g√©neros. |
        | Igualdad de Oportunidades | P(≈∂=1|Y=1,A=a) = P(≈∂=1|Y=1,A=b) | Minimizar falsos negativos entre individuos calificados. | Sensibilidad de prueba m√©dica igual entre razas. |
        | Probabilidades Igualadas | P(≈∂=1|Y=y,A=a) = P(≈∂=1|Y=y,A=b) ‚àÄ y | Equilibrar falsos positivos y negativos entre grupos. | Predicciones de reincidencia con tasas de error iguales. |
        | Calibraci√≥n | P(Y=1|≈ù=s,A=a) = s | Cuando las puntuaciones predichas se exponen a los usuarios. | Puntuaciones de cr√©dito calibradas para diferentes demograf√≠as. |
        | Equidad Contrafactual | ≈∂(x) = ≈∂(x') si A cambia | Requerir eliminaci√≥n de sesgo causal relativo a rasgos sensibles. | Resultado sin cambios si solo cambia la raza en el perfil. |
        """)
        st.subheader("2. √Årbol de Decisi√≥n para Selecci√≥n")
        exclusion = st.radio("¬øEl HCA revel√≥ exclusi√≥n sist√©mica de grupos protegidos?", ("S√≠", "No"), key="fds1")
        error_harm = st.radio("¬øQu√© tipo de error es m√°s da√±ino en tu contexto?", ("Falsos Negativos", "Falsos Positivos", "Ambos por igual"), key="fds2")
        score_usage = st.checkbox("¬øSe usar√°n las salidas como puntuaciones (ej. riesgo, ranking)?", key="fds3")
        
        st.subheader("Definiciones Recomendadas")
        definitions = []
        if exclusion == "S√≠": definitions.append("Paridad Demogr√°fica")
        if error_harm == "Falsos Negativos": definitions.append("Igualdad de Oportunidades")
        elif error_harm == "Falsos Positivos": definitions.append("Igualdad Predictiva")
        elif error_harm == "Ambos por igual": definitions.append("Probabilidades Igualadas")
        if score_usage: definitions.append("Calibraci√≥n")
        
        for d in definitions: st.markdown(f"- **{d}**")

    # ... (El resto de las secciones del Audit Playbook se pueden a√±adir aqu√≠ de manera similar) ...


# --- NAVEGACI√ìN PRINCIPAL ---
st.sidebar.title("Selecci√≥n de Playbook")
playbook_choice = st.sidebar.selectbox(
    "Elige el playbook que quieres usar:",
    ["Fairness Audit Playbook", "Fairness Intervention Playbook"]
)

st.title(playbook_choice)

if playbook_choice == "Fairness Audit Playbook":
    audit_playbook()
else:
    intervention_playbook()

=======
import streamlit as st
import json

# --- Configuraci√≥n de la P√°gina ---
st.set_page_config(
    page_title="AI Fairness Playbooks",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

#======================================================================
# --- FAIRNESS INTERVENTION PLAYBOOK ---
#======================================================================

def causal_fairness_toolkit():
    st.header("üõ°Ô∏è Toolkit de Equidad Causal")
    
    tab1, tab2, tab3, tab4 = st.tabs(["Identificaci√≥n", "An√°lisis Contrafactual", "Diagrama Causal", "Inferencia Causal"])

    with tab1:
        st.subheader("Marco de Identificaci√≥n de Mecanismos de Discriminaci√≥n")
        st.info("Identifica las posibles causas ra√≠z del sesgo en tu aplicaci√≥n.")
        st.text_area("1. Discriminaci√≥n Directa: ¬øEl atributo protegido influye directamente en la decisi√≥n?", placeholder="Ej: ¬øSe utiliza expl√≠citamente el 'g√©nero' como una caracter√≠stica en el modelo?", key="c1")
        st.text_area("2. Discriminaci√≥n Indirecta: ¬øEl atributo protegido afecta a factores intermedios leg√≠timos?", placeholder="Ej: ¬øEl 'g√©nero' afecta a los 'a√±os de experiencia' debido a pausas en la carrera?", key="c2")
        st.text_area("3. Discriminaci√≥n por Proxy: ¬øLas decisiones dependen de variables correlacionadas con atributos protegidos?", placeholder="Ej: ¬øEl 'c√≥digo postal' se correlaciona con la 'raza' y se utiliza para predecir el riesgo?", key="c3")

    with tab2:
        st.subheader("Metodolog√≠a Pr√°ctica de Equidad Contrafactual")
        st.info("Analiza, cuantifica y mitiga el sesgo contrafactual en tu modelo.")
        with st.container(border=True):
            st.markdown("##### Paso 1: An√°lisis de Equidad Contrafactual")
            st.text_area("1.1 Formular Consultas Contrafactuales", placeholder="Ej: Para un solicitante rechazado, ¬øcu√°l habr√≠a sido el resultado si su raza fuera diferente, manteniendo constantes los ingresos?", key="c4")
            st.text_area("1.2 Identificar Rutas Causales (Justas vs. Injustas)", placeholder="Ej: La ruta Raza -> C√≥digo Postal -> Decisi√≥n es injusta.", key="c5")
            st.text_area("1.3 Medir Disparidades y Documentar", placeholder="Ej: El 15% de los solicitantes del grupo desfavorecido habr√≠an sido aprobados en el escenario contrafactual.", key="c6")
        with st.container(border=True):
            st.markdown("##### Paso 2: An√°lisis Espec√≠fico de Rutas")
            st.text_area("2.1 Descomponer y Clasificar Rutas", placeholder="Ej: Ruta 1 (proxy de c√≥digo postal) clasificada como INJUSTA.", key="c7")
            st.text_area("2.2 Cuantificar Contribuci√≥n y Documentar", placeholder="Ej: La ruta del c√≥digo postal representa el 60% de la disparidad observada.", key="c8")
        with st.container(border=True):
            st.markdown("##### Paso 3: Dise√±o de Intervenci√≥n")
            st.selectbox("3.1 Seleccionar Enfoque de Intervenci√≥n", ["Nivel de Datos", "Nivel de Modelo", "Post-procesamiento"], key="c9")
            st.text_area("3.2 Implementar y Monitorear", placeholder="Ej: Se aplic√≥ una transformaci√≥n a la caracter√≠stica de c√≥digo postal. La disparidad se redujo en un 50%.", key="c10")

    with tab3:
        st.subheader("Enfoque de Diagrama Causal Inicial")
        st.info("Esboza diagramas para visualizar las relaciones causales y documentar tus supuestos.")
        st.markdown("""
        **Convenciones de Anotaci√≥n:**
        - **Nodos (variables):** Atributos Protegidos, Caracter√≠sticas, Resultados.
        - **Flechas Causales (‚Üí):** Relaci√≥n causal asumida.
        - **Flechas de Correlaci√≥n (<-->):** Correlaci√≥n sin causalidad directa conocida.
        - **Incertidumbre (?):** Relaci√≥n causal hipot√©tica o d√©bil.
        - **Ruta Problem√°tica (!):** Ruta que consideras una fuente de inequidad.
        """)
        st.text_area("Documentaci√≥n de Supuestos y Rutas", placeholder="Ruta (!): Raza -> Nivel de Ingresos -> Decisi√≥n.\nSupuesto: Las disparidades hist√≥ricas de ingresos vinculadas a la raza afectan la capacidad de pr√©stamo.", height=200, key="c11")

    with tab4:
        st.subheader("Inferencia Causal con Datos Limitados")
        st.info("M√©todos pr√°cticos para estimar efectos causales cuando los datos son imperfectos.")
        st.markdown("""
        **M√©todos de Inferencia Observacional:**
        - **Matching (Emparejamiento):** Compara individuos similares de diferentes grupos.
        - **Variables Instrumentales (IV):** Usa una variable externa para aislar el efecto causal.
        - **Regresi√≥n por Discontinuidad:** Aprovecha umbrales naturales en los datos.
        - **Diferencia en Diferencias:** Compara cambios en el tiempo entre grupos.
        """)
        st.text_area("An√°lisis de Sensibilidad", placeholder="¬øQu√© tan fuerte tendr√≠a que ser una variable de confusi√≥n no medida para anular el efecto de sesgo que has encontrado?", key="c12")

def preprocessing_fairness_toolkit():
    st.header("üß™ Toolkit de Equidad en Pre-procesamiento")
    
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["An√°lisis de Representaci√≥n", "Detecci√≥n de Correlaci√≥n", "Calidad de Etiquetas", "Re-ponderaci√≥n y Re-muestreo", "Transformaci√≥n", "Generaci√≥n de Datos"])

    with tab1:
        st.subheader("An√°lisis de Representaci√≥n Multidimensional")
        st.info("Examina las distribuciones demogr√°ficas para identificar brechas de representaci√≥n.")
        st.text_area("1. Comparaci√≥n con Poblaci√≥n de Referencia", placeholder="Ej: Nuestro conjunto de datos tiene un 20% de mujeres en roles t√©cnicos, mientras que el mercado laboral es del 35%.", key="p1")
        st.text_area("2. An√°lisis de Representaci√≥n Interseccional", placeholder="Ej: Las mujeres de minor√≠as raciales constituyen solo el 3% de los datos.", key="p2")
        st.text_area("3. Representaci√≥n a trav√©s de Categor√≠as de Resultados", placeholder="Ej: El grupo A constituye el 30% de las solicitudes pero solo el 10% de las aprobadas.", key="p3")

    with tab2:
        st.subheader("Detecci√≥n de Patrones de Correlaci√≥n")
        st.info("Identifica asociaciones problem√°ticas que podr√≠an permitir la discriminaci√≥n por proxy.")
        st.text_area("1. Correlaciones Directas (Atributo Protegido ‚Üî Resultado)", placeholder="Ej: El g√©nero tiene una correlaci√≥n de 0.3 con la decisi√≥n de contrataci√≥n.", key="p4")
        st.text_area("2. Identificaci√≥n de Variables Proxy (Atributo Protegido ‚Üî Caracter√≠stica)", placeholder="Ej: La caracter√≠stica 'asistencia a un club de ajedrez' est√° altamente correlacionada con el g√©nero masculino.", key="p5")

    with tab3:
        st.subheader("Evaluaci√≥n de la Calidad de las Etiquetas")
        st.info("Eval√∫a los sesgos potenciales en las etiquetas de entrenamiento.")
        st.text_area("1. Sesgo Hist√≥rico en las Decisiones", placeholder="Ej: Las etiquetas de 'promocionado' provienen de un per√≠odo con pol√≠ticas de promoci√≥n sesgadas.", key="p6")
        st.text_area("2. Sesgo del Anotador", placeholder="Ej: Los anotadores masculinos calificaron los mismos comentarios como 't√≥xicos' con menos frecuencia que las anotadoras femeninas.", key="p7")
    
    with tab4:
        st.subheader("T√©cnicas de Re-ponderaci√≥n y Re-muestreo")
        st.info("Aborda las disparidades de representaci√≥n ajustando la influencia de las instancias de entrenamiento.")
        st.markdown("**Re-ponderaci√≥n:** Asigna pesos a las muestras para dar m√°s importancia a los grupos subrepresentados.")
        st.markdown("**Re-muestreo:** Modifica f√≠sicamente el conjunto de datos (sobre-muestreo o sub-muestreo).")
        st.text_area("Criterios de Decisi√≥n: ¬øRe-ponderar o Re-muestrear?", placeholder="Basado en mi auditor√≠a y mi modelo, la mejor estrategia es...", key="p8")
        st.text_area("Consideraci√≥n de Interseccionalidad", placeholder="Mi plan para la interseccionalidad es...", key="p9")

    with tab5:
        st.subheader("Enfoques de Transformaci√≥n de Distribuci√≥n")
        st.info("Modifica el espacio de caracter√≠sticas para mitigar el sesgo.")
        st.text_area("1. Eliminaci√≥n de Impacto Dispar", placeholder="Ej: 'Reparar' la caracter√≠stica 'c√≥digo postal' para que su distribuci√≥n sea la misma en todos los grupos raciales.", key="p10")
        st.text_area("2. Representaciones Justas (LFR, LAFTR)", placeholder="Ej: Usar un autoencoder adversario para aprender una representaci√≥n que no contenga informaci√≥n de g√©nero.", key="p11")
        st.text_area("3. Consideraciones de Interseccionalidad", placeholder="Mi estrategia de transformaci√≥n se centrar√° en las intersecciones de g√©nero y etnia...", key="p12")

    with tab6:
        st.subheader("Generaci√≥n de Datos con Conciencia de Equidad")
        st.info("Crea datos sint√©ticos para mitigar patrones de sesgo.")
        st.markdown("**¬øCu√°ndo Generar Datos?:** Cuando hay subrepresentaci√≥n severa o se necesitan ejemplos contrafactuales.")
        st.markdown("**Estrategias:** Generaci√≥n Condicional, Aumentaci√≥n Contrafactual.")
        st.text_area("Consideraciones de Interseccionalidad", placeholder="Mi modelo generativo ser√° condicionado en la intersecci√≥n de edad y g√©nero para...", key="p13")

def inprocessing_fairness_toolkit():
    st.header("‚öôÔ∏è Toolkit de Equidad en In-procesamiento")
    
    tab1, tab2, tab3, tab4 = st.tabs(["Objetivos y Restricciones", "Debiasing Adversario", "Optimizaci√≥n Multiobjetivo", "Patrones de C√≥digo"])

    with tab1:
        st.subheader("Objetivos y Restricciones de Equidad")
        st.info("Incorpora la equidad directamente en la optimizaci√≥n del modelo.")
        st.markdown("**M√©todos Lagrangianos:** Transforma restricciones duras en penalizaciones suaves en la funci√≥n de p√©rdida.")
        st.latex(r''' \mathcal{L}(\theta, \lambda) = L(\theta) + \sum_{i=1}^{k} \lambda_i C_i(\theta) ''')
        st.markdown("**Viabilidad y Compensaciones:** Entiende la tensi√≥n entre equidad y rendimiento.")
        st.markdown("**Interseccionalidad:** Las restricciones deben considerar combinaciones de atributos.")

    with tab2:
        st.subheader("Enfoques de Debiasing Adversario")
        st.info("Usa aprendizaje adversario para que los modelos 'desaprendan' patrones discriminatorios.")
        st.markdown("**Arquitectura:** Un **Predictor** compite contra un **Adversario**. El predictor aprende a enga√±ar al adversario, creando representaciones sin informaci√≥n del atributo protegido.")
        st.markdown("**Optimizaci√≥n:** El entrenamiento puede ser inestable. Requiere equilibrio de componentes, inversi√≥n de gradiente y entrenamiento progresivo.")
    
    with tab3:
        st.subheader("Optimizaci√≥n Multiobjetivo para la Equidad")
        st.info("Navega sistem√°ticamente las tensiones entre equidad y rendimiento.")
        st.markdown("**Optimalidad de Pareto:** Identifica soluciones donde no se puede mejorar un objetivo sin degradar otro (la 'frontera de Pareto').")
        st.markdown("**M√©todos de Escalarizaci√≥n:** Combina objetivos en una sola funci√≥n ponderada para explorar la frontera de Pareto.")
        st.text_area("An√°lisis y Definici√≥n de Objetivos", placeholder="Define tus m√©tricas de rendimiento y criterios de equidad aqu√≠.", key="i1")

    with tab4:
        st.subheader("Cat√°logo de Patrones de Implementaci√≥n")
        st.code("""
def fairness_regularized_loss(original_loss, predictions, protected_attribute):
  fairness_penalty = calculate_disparity(predictions, protected_attribute)
  return original_loss + lambda * fairness_penalty
        """, language="python")

def postprocessing_fairness_toolkit():
    st.header("üìä Toolkit de Equidad en Post-procesamiento")
    
    tab1, tab2, tab3, tab4 = st.tabs(["Optimizaci√≥n de Umbrales", "Calibraci√≥n", "Transformaci√≥n de Predicci√≥n", "Clasificaci√≥n con Rechazo"])

    with tab1:
        st.subheader("T√©cnicas de Optimizaci√≥n de Umbrales")
        st.info("Ajusta los umbrales de clasificaci√≥n despu√©s del entrenamiento para satisfacer definiciones de equidad espec√≠ficas.")
        st.markdown("**Fundamentos:** El ajuste de umbrales espec√≠ficos por grupo influye directamente en las tasas de error y, por lo tanto, en las m√©tricas de equidad.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Seleccionar Criterio de Equidad (ej. igualdad de oportunidades)\n2. Calcular Umbrales en datos de validaci√≥n\n3. Analizar Compensaciones y Desplegar", key="po1")

    with tab2:
        st.subheader("Gu√≠a Pr√°ctica de Calibraci√≥n para la Equidad")
        st.info("Garantiza que las probabilidades predichas tengan un significado consistente en todos los grupos.")
        st.markdown("**Fundamentos:** Una mala calibraci√≥n significa que la misma puntuaci√≥n de riesgo representa diferentes niveles de riesgo real para diferentes grupos.")
        st.markdown("**T√©cnicas:** Platt Scaling, Regresi√≥n Isot√≥nica.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Evaluar Calibraci√≥n (con ECE, MCE)\n2. Seleccionar M√©todo\n3. Implementar y Validar", key="po2")

    with tab3:
        st.subheader("M√©todos de Transformaci√≥n de Predicci√≥n")
        st.info("Modifica las salidas del modelo para satisfacer restricciones de equidad complejas.")
        st.markdown("**Conceptos Clave:** Funciones de Transformaci√≥n Aprendidas, Alineaci√≥n de Distribuci√≥n, Transformaciones de Puntuaci√≥n Justas.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Dise√±ar Transformaci√≥n\n2. Aprender y Evaluar\n3. Considerar Interseccionalidad", key="po3")

    with tab4:
        st.subheader("Clasificaci√≥n con Opci√≥n de Rechazo")
        st.info("Identifica predicciones inciertas y las difiere a juicio humano.")
        st.markdown("**Fundamentos:** Umbrales de rechazo basados en confianza, clasificaci√≥n selectiva, modelos de colaboraci√≥n Humano-IA.")
        st.text_area("Metodolog√≠a de Implementaci√≥n", placeholder="1. Estimar Confianza\n2. Optimizar Umbral de Rechazo\n3. Dise√±ar Flujo de Trabajo Humano-IA", key="po4")

def intervention_playbook():
    st.sidebar.title("Navegaci√≥n del Playbook de Intervenci√≥n")
    selection = st.sidebar.radio(
        "Ir a:",
        ["Playbook Principal", "Toolkit Causal", "Toolkit de Pre-procesamiento", "Toolkit de In-procesamiento", "Toolkit de Post-procesamiento"],
        key="intervention_nav"
    )
    
    if selection == "Playbook Principal":
        st.header("üìñ Playbook de Intervenci√≥n de Equidad")
        st.info("Este playbook integra los cuatro toolkits en un flujo de trabajo cohesivo, guiando a los desarrolladores desde la identificaci√≥n del sesgo hasta la implementaci√≥n de soluciones efectivas.")
        with st.expander("Gu√≠a de Implementaci√≥n"):
            st.write("Explica c√≥mo usar el playbook, con comentarios sobre puntos de decisi√≥n clave, evidencia de apoyo y riesgos identificados.")
        with st.expander("Estudio de Caso"):
            st.write("Demuestra la aplicaci√≥n del playbook a un problema de equidad t√≠pico, mostrando c√≥mo los resultados de cada componente informan al siguiente.")
        with st.expander("Marco de Validaci√≥n"):
            st.write("Proporciona orientaci√≥n sobre c√≥mo los equipos de implementaci√≥n pueden verificar la efectividad de su proceso de auditor√≠a.")
        with st.expander("Equidad Interseccional"):
            st.write("Consideraci√≥n expl√≠cita de la equidad interseccional en cada componente del playbook.")
    elif selection == "Toolkit Causal":
        causal_fairness_toolkit()
    elif selection == "Toolkit de Pre-procesamiento":
        preprocessing_fairness_toolkit()
    elif selection == "Toolkit de In-procesamiento":
        inprocessing_fairness_toolkit()
    elif selection == "Toolkit de Post-procesamiento":
        postprocessing_fairness_toolkit()

#======================================================================
# --- FAIRNESS AUDIT PLAYBOOK ---
#======================================================================

def audit_playbook():
    st.sidebar.title("Navegaci√≥n del Playbook de Auditor√≠a")
    page = st.sidebar.radio("Ir a", [
        "C√≥mo Navegar este Playbook",
        "Evaluaci√≥n del Contexto Hist√≥rico",
        "Selecci√≥n de Definici√≥n de Equidad",
        "Identificaci√≥n de Fuentes de Sesgo",
        "M√©tricas Comprensivas de Equidad"
    ], key="audit_nav")

    if page == "C√≥mo Navegar este Playbook":
        st.header("C√≥mo Navegar Este Playbook")
        st.markdown("""
        **El Marco de Cuatro Componentes** ‚Äì Sigue secuencialmente a trav√©s de:
        
        1. **Evaluaci√≥n del Contexto Hist√≥rico (HCA)** ‚Äì Descubre sesgos sist√©micos y desequilibrios de poder en tu dominio.
        
        2. **Selecci√≥n de Definici√≥n de Equidad (FDS)**
         ‚Äì Elige las definiciones de equidad apropiadas basadas en tu contexto y objetivos.
        
        3. **Identificaci√≥n de Fuentes de Sesgo (BSI)** ‚Äì Identifica y prioriza las formas en que el sesgo puede entrar en tu sistema.
        
        4. **M√©tricas Comprensivas de Equidad (CFM)**
         ‚Äì Implementa m√©tricas cuantitativas para el monitoreo y la presentaci√≥n de informes.

        **Consejos:**
        - Avanza por las secciones en orden, pero si√©ntete libre de retroceder si surgen nuevas ideas.
        - Usa los botones de **Guardar Resumen** en cada herramienta para registrar tus hallazgos.
        - Consulta los ejemplos incrustados en cada secci√≥n para ver c√≥mo otros han aplicado estas herramientas.
        """)
    elif page == "Evaluaci√≥n del Contexto Hist√≥rico":
        st.header("Herramienta de Evaluaci√≥n del Contexto Hist√≥rico")
        st.subheader("1. Cuestionario Estructurado")
        st.markdown("Esta secci√≥n te ayuda a descubrir patrones relevantes de discriminaci√≥n hist√≥rica.")
        
        q1 = st.text_area("¬øEn qu√© dominio espec√≠fico operar√° este sistema (ej. pr√©stamos, contrataci√≥n, salud)?")
        q2 = st.text_area("¬øCu√°l es la funci√≥n espec√≠fica del sistema o caso de uso dentro de ese dominio?")
        q3 = st.text_area("¬øCu√°les son los patrones de discriminaci√≥n hist√≥rica documentados en este dominio?")
        q4 = st.text_area("¬øQu√© fuentes de datos hist√≥ricos se utilizan o se referencian en este sistema?")
        q5 = st.text_area("¬øC√≥mo se definieron hist√≥ricamente las categor√≠as clave (ej. g√©nero, riesgo crediticio) y han evolucionado?")
        q6 = st.text_area("¬øC√≥mo se midieron hist√≥ricamente las variables (ej. ingresos, educaci√≥n)? ¬øPodr√≠an codificar sesgos?")
        q7 = st.text_area("¬øHan servido otras tecnolog√≠as para roles similares en este dominio? ¬øDesafiaron o reforzaron las desigualdades?")
        q8 = st.text_area("¬øC√≥mo podr√≠a la automatizaci√≥n amplificar los sesgos pasados o introducir nuevos riesgos en este dominio?")

        st.subheader("2. Matriz de Clasificaci√≥n de Riesgos")
        st.markdown("""
        Para cada patr√≥n hist√≥rico identificado, estima:
        - **Severidad**: Alto = impacta derechos/resultados de vida, Medio = afecta oportunidades/acceso a recursos, Bajo = impacto material limitado.
        - **Probabilidad**: Alta = probable que aparezca en sistemas similares, Media = posible, Baja = raro.
        - **Relevancia**: Alta = directamente relacionado con tu sistema, Media = afecta partes, Baja = perif√©rico.
        """)
        matrix = st.text_area("Matriz de Clasificaci√≥n de Riesgos (tabla Markdown)", height=200, placeholder="| Patr√≥n | Severidad | Probabilidad | Relevancia | Puntuaci√≥n (S√óP√óR) | Prioridad |\n|---|---|---|---|---|---|")

        if st.button("Guardar Resumen HCA"):
            summary = {
                "Cuestionario Estructurado": {
                    "Dominio": q1, "Funci√≥n": q2, "Patrones Hist√≥ricos": q3, "Fuentes de Datos": q4,
                    "Definiciones de Categor√≠a": q5, "Riesgos de Medici√≥n": q6, "Sistemas Anteriores": q7, "Riesgos de Automatizaci√≥n": q8
                },
                "Matriz de Riesgos": matrix
            }
            summary_md = "# Resumen de Evaluaci√≥n del Contexto Hist√≥rico\n"
            for section, answers in summary.items():
                summary_md += f"## {section}\n"
                if isinstance(answers, dict):
                    for k, v in answers.items():
                        summary_md += f"**{k}:** {v}\n\n"
                else:
                    summary_md += f"{answers}\n"
            
            st.subheader("Vista Previa del Resumen HCA")
            st.markdown(summary_md)
            st.download_button("Descargar Resumen HCA", summary_md, "HCA_summary.md", "text/markdown")
            st.success("Resumen de Evaluaci√≥n del Contexto Hist√≥rico guardado.")

    elif page == "Selecci√≥n de Definici√≥n de Equidad":
        st.header("Herramienta de Selecci√≥n de Definici√≥n de Equidad")
        st.subheader("1. Cat√°logo de Definiciones de Equidad")
        st.markdown("""
        | Definici√≥n | F√≥rmula | Cu√°ndo Usar | Ejemplo |
        |---|---|---|---|
        | Paridad Demogr√°fica | P(≈∂=1|A=a) = P(≈∂=1|A=b) | Asegurar tasas de positivos iguales entre grupos. | Anuncios de universidad mostrados por igual a todos los g√©neros. |
        | Igualdad de Oportunidades | P(≈∂=1|Y=1,A=a) = P(≈∂=1|Y=1,A=b) | Minimizar falsos negativos entre individuos calificados. | Sensibilidad de prueba m√©dica igual entre razas. |
        | Probabilidades Igualadas | P(≈∂=1|Y=y,A=a) = P(≈∂=1|Y=y,A=b) ‚àÄ y | Equilibrar falsos positivos y negativos entre grupos. | Predicciones de reincidencia con tasas de error iguales. |
        | Calibraci√≥n | P(Y=1|≈ù=s,A=a) = s | Cuando las puntuaciones predichas se exponen a los usuarios. | Puntuaciones de cr√©dito calibradas para diferentes demograf√≠as. |
        | Equidad Contrafactual | ≈∂(x) = ≈∂(x') si A cambia | Requerir eliminaci√≥n de sesgo causal relativo a rasgos sensibles. | Resultado sin cambios si solo cambia la raza en el perfil. |
        """)
        st.subheader("2. √Årbol de Decisi√≥n para Selecci√≥n")
        exclusion = st.radio("¬øEl HCA revel√≥ exclusi√≥n sist√©mica de grupos protegidos?", ("S√≠", "No"), key="fds1")
        error_harm = st.radio("¬øQu√© tipo de error es m√°s da√±ino en tu contexto?", ("Falsos Negativos", "Falsos Positivos", "Ambos por igual"), key="fds2")
        score_usage = st.checkbox("¬øSe usar√°n las salidas como puntuaciones (ej. riesgo, ranking)?", key="fds3")
        
        st.subheader("Definiciones Recomendadas")
        definitions = []
        if exclusion == "S√≠": definitions.append("Paridad Demogr√°fica")
        if error_harm == "Falsos Negativos": definitions.append("Igualdad de Oportunidades")
        elif error_harm == "Falsos Positivos": definitions.append("Igualdad Predictiva")
        elif error_harm == "Ambos por igual": definitions.append("Probabilidades Igualadas")
        if score_usage: definitions.append("Calibraci√≥n")
        
        for d in definitions: st.markdown(f"- **{d}**")

    # ... (El resto de las secciones del Audit Playbook se pueden a√±adir aqu√≠ de manera similar) ...


# --- NAVEGACI√ìN PRINCIPAL ---
st.sidebar.title("Selecci√≥n de Playbook")
playbook_choice = st.sidebar.selectbox(
    "Elige el playbook que quieres usar:",
    ["Fairness Audit Playbook", "Fairness Intervention Playbook"]
)

st.title(playbook_choice)

if playbook_choice == "Fairness Audit Playbook":
    audit_playbook()
else:
    intervention_playbook()

>>>>>>> 3cc2312d2af3ff4ae50fac5ea04d94c8c19f7890
